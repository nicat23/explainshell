{"traceEvents": [{"ph": "M", "pid": 229331, "tid": 229331, "name": "process_name", "args": {"name": "MainProcess"}}, {"ph": "M", "pid": 229331, "tid": 229331, "name": "thread_name", "args": {"name": "MainThread"}}, {"pid": 229331, "tid": 229331, "ts": 59115828645.541, "ph": "X", "cat": "fee", "dur": 5.026, "name": "get_load_dotenv (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/helpers.py:35)"}, {"pid": 229331, "tid": 229331, "ts": 59115828654.705, "ph": "X", "cat": "fee", "dur": 189.651, "name": "load_dotenv (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/cli.py:706)"}, {"pid": 229331, "tid": 229331, "ts": 59115828863.042, "ph": "X", "cat": "fee", "dur": 1.098, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115828866.624, "ph": "X", "cat": "fee", "dur": 0.197, "name": "dict.get"}, {"pid": 229331, "tid": 229331, "ts": 59115828874.327, "ph": "X", "cat": "fee", "dur": 0.413, "name": "App.debug (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:549)"}, {"pid": 229331, "tid": 229331, "ts": 59115828885.489, "ph": "X", "cat": "fee", "dur": 0.786, "name": "DispatchingJinjaLoader.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/templating.py:57)"}, {"pid": 229331, "tid": 229331, "ts": 59115828881.36, "ph": "X", "cat": "fee", "dur": 5.393, "name": "App.create_global_jinja_loader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:523)"}, {"pid": 229331, "tid": 229331, "ts": 59115828899.825, "ph": "X", "cat": "fee", "dur": 3.072, "name": "dict.copy"}, {"pid": 229331, "tid": 229331, "ts": 59115828903.791, "ph": "X", "cat": "fee", "dur": 1.48, "name": "dict.copy"}, {"pid": 229331, "tid": 229331, "ts": 59115828906.189, "ph": "X", "cat": "fee", "dur": 1.148, "name": "dict.copy"}, {"pid": 229331, "tid": 229331, "ts": 59115828921.765, "ph": "X", "cat": "fee", "dur": 0.57, "name": "_thread.allocate_lock"}, {"pid": 229331, "tid": 229331, "ts": 59115828916.848, "ph": "X", "cat": "fee", "dur": 7.234, "name": "LRUCache._postinit (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/utils.py:445)"}, {"pid": 229331, "tid": 229331, "ts": 59115828912.566, "ph": "X", "cat": "fee", "dur": 11.804, "name": "LRUCache.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/utils.py:439)"}, {"pid": 229331, "tid": 229331, "ts": 59115828909.285, "ph": "X", "cat": "fee", "dur": 15.518, "name": "create_cache (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:82)"}, {"pid": 229331, "tid": 229331, "ts": 59115828926.107, "ph": "X", "cat": "fee", "dur": 0.6, "name": "dict.copy"}, {"pid": 229331, "tid": 229331, "ts": 59115828929.048, "ph": "X", "cat": "fee", "dur": 0.425, "name": "load_extensions (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:108)"}, {"pid": 229331, "tid": 229331, "ts": 59115828932.619, "ph": "X", "cat": "fee", "dur": 0.202, "name": "builtins.issubclass"}, {"pid": 229331, "tid": 229331, "ts": 59115828932.15, "ph": "X", "cat": "fee", "dur": 1.861, "name": "_environment_config_check (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:126)"}, {"pid": 229331, "tid": 229331, "ts": 59115828893.236, "ph": "X", "cat": "fee", "dur": 41.278, "name": "Environment.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:294)"}, {"pid": 229331, "tid": 229331, "ts": 59115828880.077, "ph": "X", "cat": "fee", "dur": 55.498, "name": "Environment.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/templating.py:45)"}, {"pid": 229331, "tid": 229331, "ts": 59115828938.614, "ph": "X", "cat": "fee", "dur": 2.244, "name": "dict.update"}, {"pid": 229331, "tid": 229331, "ts": 59115828871.085, "ph": "X", "cat": "fee", "dur": 72.991, "name": "Flask.create_jinja_environment (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/app.py:385)"}, {"pid": 229331, "tid": 229331, "ts": 59115828868.86, "ph": "X", "cat": "fee", "dur": 75.676, "name": "App.jinja_env (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:469)"}, {"pid": 229331, "tid": 229331, "ts": 59115828861.4, "ph": "X", "cat": "fee", "dur": 84.624, "name": "cached_property.__get__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/utils.py:95)"}, {"pid": 229331, "tid": 229331, "ts": 59115828856.449, "ph": "X", "cat": "fee", "dur": 90.235, "name": "App.debug (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:562)"}, {"pid": 229331, "tid": 229331, "ts": 59115828947.829, "ph": "X", "cat": "fee", "dur": 0.293, "name": "Config.get"}, {"pid": 229331, "tid": 229331, "ts": 59115828950.114, "ph": "X", "cat": "fee", "dur": 0.517, "name": "App.debug (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:549)"}, {"pid": 229331, "tid": 229331, "ts": 59115828951.067, "ph": "X", "cat": "fee", "dur": 0.321, "name": "dict.setdefault"}, {"pid": 229331, "tid": 229331, "ts": 59115828951.91, "ph": "X", "cat": "fee", "dur": 0.138, "name": "App.debug (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:549)"}, {"pid": 229331, "tid": 229331, "ts": 59115828952.331, "ph": "X", "cat": "fee", "dur": 0.331, "name": "dict.setdefault"}, {"pid": 229331, "tid": 229331, "ts": 59115828953.045, "ph": "X", "cat": "fee", "dur": 0.197, "name": "dict.setdefault"}, {"pid": 229331, "tid": 229331, "ts": 59115828954.276, "ph": "X", "cat": "fee", "dur": 0.122, "name": "App.debug (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:549)"}, {"pid": 229331, "tid": 229331, "ts": 59115828955.541, "ph": "X", "cat": "fee", "dur": 0.242, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115828956.536, "ph": "X", "cat": "fee", "dur": 0.215, "name": "dict.get"}, {"pid": 229331, "tid": 229331, "ts": 59115828955.361, "ph": "X", "cat": "fee", "dur": 1.807, "name": "cached_property.__get__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/utils.py:95)"}, {"pid": 229331, "tid": 229331, "ts": 59115828960.337, "ph": "X", "cat": "fee", "dur": 7.099, "name": "is_running_from_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:951)"}, {"pid": 229331, "tid": 229331, "ts": 59115828977.691, "ph": "X", "cat": "fee", "dur": 1.591, "name": "<lambda> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:608)"}, {"pid": 229331, "tid": 229331, "ts": 59115828987.429, "ph": "X", "cat": "fee", "dur": 0.075, "name": "_get_windows_console_stream (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:562)"}, {"pid": 229331, "tid": 229331, "ts": 59115829026.695, "ph": "X", "cat": "fee", "dur": 6.652, "name": "_io.TextIOWrapper.write"}, {"pid": 229331, "tid": 229331, "ts": 59115829035.573, "ph": "X", "cat": "fee", "dur": 1.11, "name": "_io.TextIOWrapper.write"}, {"pid": 229331, "tid": 229331, "ts": 59115828994.035, "ph": "X", "cat": "fee", "dur": 43.333, "name": "_is_binary_writer (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:160)"}, {"pid": 229331, "tid": 229331, "ts": 59115829045.846, "ph": "X", "cat": "fee", "dur": 1.22, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115829045.289, "ph": "X", "cat": "fee", "dur": 2.515, "name": "_is_compat_stream_attr (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:218)"}, {"pid": 229331, "tid": 229331, "ts": 59115829048.642, "ph": "X", "cat": "fee", "dur": 0.655, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115829048.32, "ph": "X", "cat": "fee", "dur": 1.467, "name": "_is_compat_stream_attr (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:218)"}, {"pid": 229331, "tid": 229331, "ts": 59115829043.698, "ph": "X", "cat": "fee", "dur": 6.335, "name": "_is_compatible_text_stream (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:227)"}, {"pid": 229331, "tid": 229331, "ts": 59115829051.951, "ph": "X", "cat": "fee", "dur": 0.124, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115829067.173, "ph": "X", "cat": "fee", "dur": 2.797, "name": "_codecs.lookup"}, {"pid": 229331, "tid": 229331, "ts": 59115829065.718, "ph": "X", "cat": "fee", "dur": 5.103, "name": "is_ascii_encoding (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:40)"}, {"pid": 229331, "tid": 229331, "ts": 59115829051.447, "ph": "X", "cat": "fee", "dur": 19.509, "name": "_stream_is_misconfigured (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:209)"}, {"pid": 229331, "tid": 229331, "ts": 59115828992.725, "ph": "X", "cat": "fee", "dur": 78.341, "name": "_force_correct_text_stream (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:238)"}, {"pid": 229331, "tid": 229331, "ts": 59115828989.967, "ph": "X", "cat": "fee", "dur": 81.335, "name": "_force_correct_text_writer (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:300)"}, {"pid": 229331, "tid": 229331, "ts": 59115828986.223, "ph": "X", "cat": "fee", "dur": 85.246, "name": "get_text_stdout (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:344)"}, {"pid": 229331, "tid": 229331, "ts": 59115828976.84, "ph": "X", "cat": "fee", "dur": 100.208, "name": "_make_cached_stream_func.<locals>.func (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:585)"}, {"pid": 229331, "tid": 229331, "ts": 59115829078.1, "ph": "X", "cat": "fee", "dur": 0.248, "name": "builtins.isinstance"}, {"pid": 229331, "tid": 229331, "ts": 59115829078.764, "ph": "X", "cat": "fee", "dur": 0.065, "name": "builtins.isinstance"}, {"pid": 229331, "tid": 229331, "ts": 59115829079.821, "ph": "X", "cat": "fee", "dur": 0.513, "name": "builtins.isinstance"}, {"pid": 229331, "tid": 229331, "ts": 59115829084.459, "ph": "X", "cat": "fee", "dur": 6.817, "name": "get_current_context (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py:20)"}, {"pid": 229331, "tid": 229331, "ts": 59115829081.939, "ph": "X", "cat": "fee", "dur": 9.591, "name": "resolve_color_default (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py:54)"}, {"pid": 229331, "tid": 229331, "ts": 59115829095.84, "ph": "X", "cat": "fee", "dur": 12.12, "name": "_io.TextIOWrapper.isatty"}, {"pid": 229331, "tid": 229331, "ts": 59115829094.948, "ph": "X", "cat": "fee", "dur": 13.25, "name": "isatty (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:572)"}, {"pid": 229331, "tid": 229331, "ts": 59115829093.436, "ph": "X", "cat": "fee", "dur": 14.956, "name": "should_strip_ansi (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:499)"}, {"pid": 229331, "tid": 229331, "ts": 59115829108.773, "ph": "X", "cat": "fee", "dur": 56.534, "name": "_io.TextIOWrapper.write"}, {"pid": 229331, "tid": 229331, "ts": 59115829166.135, "ph": "X", "cat": "fee", "dur": 0.723, "name": "_io.TextIOWrapper.flush"}, {"pid": 229331, "tid": 229331, "ts": 59115828973.725, "ph": "X", "cat": "fee", "dur": 193.59, "name": "echo (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/utils.py:222)"}, {"pid": 229331, "tid": 229331, "ts": 59115829171.089, "ph": "X", "cat": "fee", "dur": 0.622, "name": "<lambda> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:608)"}, {"pid": 229331, "tid": 229331, "ts": 59115829170.828, "ph": "X", "cat": "fee", "dur": 3.804, "name": "_make_cached_stream_func.<locals>.func (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:585)"}, {"pid": 229331, "tid": 229331, "ts": 59115829175.381, "ph": "X", "cat": "fee", "dur": 0.273, "name": "builtins.isinstance"}, {"pid": 229331, "tid": 229331, "ts": 59115829176.132, "ph": "X", "cat": "fee", "dur": 0.065, "name": "builtins.isinstance"}, {"pid": 229331, "tid": 229331, "ts": 59115829177.022, "ph": "X", "cat": "fee", "dur": 0.448, "name": "builtins.isinstance"}, {"pid": 229331, "tid": 229331, "ts": 59115829178.491, "ph": "X", "cat": "fee", "dur": 4.24, "name": "get_current_context (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py:20)"}, {"pid": 229331, "tid": 229331, "ts": 59115829177.966, "ph": "X", "cat": "fee", "dur": 5.004, "name": "resolve_color_default (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py:54)"}, {"pid": 229331, "tid": 229331, "ts": 59115829184.245, "ph": "X", "cat": "fee", "dur": 3.648, "name": "_io.TextIOWrapper.isatty"}, {"pid": 229331, "tid": 229331, "ts": 59115829183.866, "ph": "X", "cat": "fee", "dur": 4.235, "name": "isatty (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:572)"}, {"pid": 229331, "tid": 229331, "ts": 59115829183.48, "ph": "X", "cat": "fee", "dur": 4.75, "name": "should_strip_ansi (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:499)"}, {"pid": 229331, "tid": 229331, "ts": 59115829188.622, "ph": "X", "cat": "fee", "dur": 6.151, "name": "_io.TextIOWrapper.write"}, {"pid": 229331, "tid": 229331, "ts": 59115829195.234, "ph": "X", "cat": "fee", "dur": 0.376, "name": "_io.TextIOWrapper.flush"}, {"pid": 229331, "tid": 229331, "ts": 59115829170.168, "ph": "X", "cat": "fee", "dur": 25.663, "name": "echo (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/utils.py:222)"}, {"pid": 229331, "tid": 229331, "ts": 59115828958.846, "ph": "X", "cat": "fee", "dur": 237.265, "name": "show_server_banner (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/cli.py:774)"}, {"pid": 229331, "tid": 229331, "ts": 59115829208.006, "ph": "X", "cat": "fee", "dur": 0.225, "name": "builtins.isinstance"}, {"pid": 229331, "tid": 229331, "ts": 59115833194.253, "ph": "X", "cat": "fee", "dur": 21.058, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833215.754, "ph": "X", "cat": "fee", "dur": 5.751, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833221.776, "ph": "X", "cat": "fee", "dur": 3.734, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833225.743, "ph": "X", "cat": "fee", "dur": 3.852, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833229.807, "ph": "X", "cat": "fee", "dur": 3.529, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833233.539, "ph": "X", "cat": "fee", "dur": 3.346, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833237.114, "ph": "X", "cat": "fee", "dur": 3.36, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833240.672, "ph": "X", "cat": "fee", "dur": 3.315, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833244.189, "ph": "X", "cat": "fee", "dur": 3.306, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833248.068, "ph": "X", "cat": "fee", "dur": 3.375, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833251.659, "ph": "X", "cat": "fee", "dur": 5.491, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833257.367, "ph": "X", "cat": "fee", "dur": 3.49, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833261.062, "ph": "X", "cat": "fee", "dur": 3.381, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833264.631, "ph": "X", "cat": "fee", "dur": 3.281, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833281.937, "ph": "X", "cat": "fee", "dur": 7.917, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833290.091, "ph": "X", "cat": "fee", "dur": 3.433, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833293.723, "ph": "X", "cat": "fee", "dur": 3.321, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833297.572, "ph": "X", "cat": "fee", "dur": 3.403, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833301.176, "ph": "X", "cat": "fee", "dur": 3.346, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833304.734, "ph": "X", "cat": "fee", "dur": 3.303, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833308.236, "ph": "X", "cat": "fee", "dur": 0.148, "name": "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)"}, {"pid": 229331, "tid": 229331, "ts": 59115833193.007, "ph": "X", "cat": "fee", "dur": 116.715, "name": "str.join"}, {"pid": 229331, "tid": 229331, "ts": 59115833189.551, "ph": "X", "cat": "fee", "dur": 120.576, "name": "gen_salt (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:17)"}, {"pid": 229331, "tid": 229331, "ts": 59115833184.476, "ph": "X", "cat": "fee", "dur": 5902.436, "name": "DebuggedApplication.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/debug/__init__.py:269)"}, {"pid": 229331, "tid": 229331, "ts": 59115839088.542, "ph": "X", "cat": "fee", "dur": 0.402, "name": "list.append"}, {"pid": 229331, "tid": 229331, "ts": 59115839090.413, "ph": "X", "cat": "fee", "dur": 4.217, "name": "is_running_from_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:951)"}, {"pid": 229331, "tid": 229331, "ts": 59115839122.52, "ph": "X", "cat": "fee", "dur": 1.114, "name": "builtins.vars"}, {"pid": 229331, "tid": 229331, "ts": 59115839141.568, "ph": "X", "cat": "fee", "dur": 0.858, "name": "str.startswith"}, {"pid": 229331, "tid": 229331, "ts": 59115839140.724, "ph": "X", "cat": "fee", "dur": 3.607, "name": "select_address_family (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:655)"}, {"pid": 229331, "tid": 229331, "ts": 59115839147.308, "ph": "X", "cat": "fee", "dur": 74.522, "name": "get_sockaddr (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:665)"}, {"pid": 229331, "tid": 229331, "ts": 59115839120.778, "ph": "X", "cat": "fee", "dur": 3278.714, "name": "BaseWSGIServer.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:711)"}, {"pid": 229331, "tid": 229331, "ts": 59115839097.348, "ph": "X", "cat": "fee", "dur": 3303.758, "name": "make_server (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:906)"}, {"pid": 229331, "tid": 229331, "ts": 59115842432.114, "ph": "X", "cat": "fee", "dur": 5.846, "name": "is_running_from_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:951)"}, {"pid": 229331, "tid": 229331, "ts": 59115842443.785, "ph": "X", "cat": "fee", "dur": 4.584, "name": "_ansi_style (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:485)"}, {"pid": 229331, "tid": 229331, "ts": 59115842452.003, "ph": "X", "cat": "fee", "dur": 0.426, "name": "list.append"}, {"pid": 229331, "tid": 229331, "ts": 59115842453.087, "ph": "X", "cat": "fee", "dur": 0.358, "name": "str.join"}, {"pid": 229331, "tid": 229331, "ts": 59115842491.414, "ph": "X", "cat": "fee", "dur": 0.161, "name": "_has_level_handler.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:53)"}, {"pid": 229331, "tid": 229331, "ts": 59115842490.537, "ph": "X", "cat": "fee", "dur": 1.612, "name": "builtins.any"}, {"pid": 229331, "tid": 229331, "ts": 59115842494.023, "ph": "X", "cat": "fee", "dur": 0.172, "name": "_has_level_handler.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:53)"}, {"pid": 229331, "tid": 229331, "ts": 59115842493.786, "ph": "X", "cat": "fee", "dur": 0.713, "name": "builtins.any"}, {"pid": 229331, "tid": 229331, "ts": 59115842486.725, "ph": "X", "cat": "fee", "dur": 8.594, "name": "_has_level_handler (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:45)"}, {"pid": 229331, "tid": 229331, "ts": 59115842499.002, "ph": "X", "cat": "fee", "dur": 196.512, "name": "_ColorStreamHandler.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:67)"}, {"pid": 229331, "tid": 229331, "ts": 59115842699.176, "ph": "X", "cat": "fee", "dur": 0.636, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115842700.179, "ph": "X", "cat": "fee", "dur": 0.286, "name": "str.rstrip"}, {"pid": 229331, "tid": 229331, "ts": 59115842455.921, "ph": "X", "cat": "fee", "dur": 426.356, "name": "_log (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:78)"}, {"pid": 229331, "tid": 229331, "ts": 59115842441.443, "ph": "X", "cat": "fee", "dur": 441.22, "name": "BaseWSGIServer.log_startup (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:833)"}, {"pid": 229331, "tid": 229331, "ts": 59115842884.819, "ph": "X", "cat": "fee", "dur": 2.43, "name": "_ansi_style (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:485)"}, {"pid": 229331, "tid": 229331, "ts": 59115842888.385, "ph": "X", "cat": "fee", "dur": 0.377, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115842889.114, "ph": "X", "cat": "fee", "dur": 0.355, "name": "str.rstrip"}, {"pid": 229331, "tid": 229331, "ts": 59115842887.951, "ph": "X", "cat": "fee", "dur": 74.658, "name": "_log (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:78)"}, {"pid": 229331, "tid": 229331, "ts": 59115843688.762, "ph": "X", "cat": "fee", "dur": 2.092, "name": "ReloaderLoop.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:231)"}, {"pid": 229331, "tid": 229331, "ts": 59115843701.37, "ph": "X", "cat": "fee", "dur": 0.512, "name": "builtins.getattr"}, {"pid": 229331, "tid": 229331, "ts": 59115843702.124, "ph": "X", "cat": "fee", "dur": 0.308, "name": "str.rstrip"}, {"pid": 229331, "tid": 229331, "ts": 59115843701.074, "ph": "X", "cat": "fee", "dur": 80.694, "name": "_log (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:78)"}, {"pid": 229331, "tid": 229331, "ts": 59115843785.75, "ph": "X", "cat": "fee", "dur": 4.393, "name": "_get_args_for_reloading (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:169)"}, {"pid": 229331, "tid": 229331, "ts": 59115843700.057, "ph": "X", "cat": "fee", "dur": 22532746.823, "name": "ReloaderLoop.restart_with_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:266)"}, {"pid": 229331, "tid": 229331, "ts": 59115843662.285, "ph": "X", "cat": "fee", "dur": 22532908.833, "name": "run_with_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:442)"}, {"pid": 229331, "tid": 229331, "ts": 59115829207.015, "ph": "X", "cat": "fee", "dur": 22547433.722, "name": "run_simple (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:960)"}, {"pid": 229331, "tid": 229331, "ts": 59115828634.855, "ph": "X", "cat": "fee", "dur": 22548313.531, "name": "Flask.run (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/app.py:546)"}, {"pid": 229331, "tid": 229331, "ts": 59114629764.946, "ph": "X", "cat": "fee", "dur": 23747187.074, "name": "<module> (/home/justin/explainshell/runserver.py:1)"}, {"pid": 229331, "tid": 229331, "ts": 59114629753.786, "ph": "X", "cat": "fee", "dur": 23747228.358, "name": "builtins.exec"}], "viztracer_metadata": {"overflow": false, "version": "1.0.4"}, "file_info": {"files": {"/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/helpers.py": ["from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr],\n) -> t.Iterator[t.AnyStr]: ...\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]: ...\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path. This *must not*\n        be a value provided by the client, otherwise it becomes insecure.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)  # pyright: ignore\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@cache\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n", 634], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/cli.py": ["from __future__ import annotations\n\nimport ast\nimport collections.abc as cabc\nimport importlib.metadata\nimport inspect\nimport os\nimport platform\nimport re\nimport sys\nimport traceback\nimport typing as t\nfrom functools import update_wrapper\nfrom operator import itemgetter\nfrom types import ModuleType\n\nimport click\nfrom click.core import ParameterSource\nfrom werkzeug import run_simple\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.utils import import_string\n\nfrom .globals import current_app\nfrom .helpers import get_debug_flag\nfrom .helpers import get_load_dotenv\n\nif t.TYPE_CHECKING:\n    import ssl\n\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .app import Flask\n\n\nclass NoAppException(click.UsageError):\n    \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n\n\ndef find_best_app(module: ModuleType) -> Flask:\n    \"\"\"Given a module instance this tries to find the best possible\n    application in the module or raises an exception.\n    \"\"\"\n    from . import Flask\n\n    # Search for the most common names first.\n    for attr_name in (\"app\", \"application\"):\n        app = getattr(module, attr_name, None)\n\n        if isinstance(app, Flask):\n            return app\n\n    # Otherwise find the only object that is a Flask instance.\n    matches = [v for v in module.__dict__.values() if isinstance(v, Flask)]\n\n    if len(matches) == 1:\n        return matches[0]\n    elif len(matches) > 1:\n        raise NoAppException(\n            \"Detected multiple Flask applications in module\"\n            f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n            \" to specify the correct one.\"\n        )\n\n    # Search for app factory functions.\n    for attr_name in (\"create_app\", \"make_app\"):\n        app_factory = getattr(module, attr_name, None)\n\n        if inspect.isfunction(app_factory):\n            try:\n                app = app_factory()\n\n                if isinstance(app, Flask):\n                    return app\n            except TypeError as e:\n                if not _called_with_wrong_args(app_factory):\n                    raise\n\n                raise NoAppException(\n                    f\"Detected factory '{attr_name}' in module '{module.__name__}',\"\n                    \" but could not call it without arguments. Use\"\n                    f\" '{module.__name__}:{attr_name}(args)'\"\n                    \" to specify arguments.\"\n                ) from e\n\n    raise NoAppException(\n        \"Failed to find Flask application or factory in module\"\n        f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n        \" to specify one.\"\n    )\n\n\ndef _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n    \"\"\"Check whether calling a function raised a ``TypeError`` because\n    the call failed or because something in the factory raised the\n    error.\n\n    :param f: The function that was called.\n    :return: ``True`` if the call failed.\n    \"\"\"\n    tb = sys.exc_info()[2]\n\n    try:\n        while tb is not None:\n            if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully.\n                return False\n\n            tb = tb.tb_next\n\n        # Didn't reach the function.\n        return True\n    finally:\n        # Delete tb to break a circular reference.\n        # https://docs.python.org/2/library/sys.html#sys.exc_info\n        del tb\n\n\ndef find_app_by_string(module: ModuleType, app_name: str) -> Flask:\n    \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.\n    \"\"\"\n    from . import Flask\n\n    # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) from None\n\n    if isinstance(expr, ast.Name):\n        name = expr.id\n        args = []\n        kwargs = {}\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {\n                kw.arg: ast.literal_eval(kw.value)\n                for kw in expr.keywords\n                if kw.arg is not None\n            }\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            ) from None\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        )\n\n    try:\n        attr = getattr(module, name)\n    except AttributeError as e:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) from e\n\n    # If the attribute is a function, call it with any args and kwargs\n    # to get the real application.\n    if inspect.isfunction(attr):\n        try:\n            app = attr(*args, **kwargs)\n        except TypeError as e:\n            if not _called_with_wrong_args(attr):\n                raise\n\n            raise NoAppException(\n                f\"The factory {app_name!r} in module\"\n                f\" {module.__name__!r} could not be called with the\"\n                \" specified arguments.\"\n            ) from e\n    else:\n        app = attr\n\n    if isinstance(app, Flask):\n        return app\n\n    raise NoAppException(\n        \"A valid Flask application was not obtained from\"\n        f\" '{module.__name__}:{app_name}'.\"\n    )\n\n\ndef prepare_import(path: str) -> str:\n    \"\"\"Given a filename this will try to calculate the python path, add it\n    to the search path and return the actual module name that is expected.\n    \"\"\"\n    path = os.path.realpath(path)\n\n    fname, ext = os.path.splitext(path)\n    if ext == \".py\":\n        path = fname\n\n    if os.path.basename(path) == \"__init__\":\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, \"__init__.py\")):\n            break\n\n    if sys.path[0] != path:\n        sys.path.insert(0, path)\n\n    return \".\".join(module_name[::-1])\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[True] = True\n) -> Flask: ...\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[False] = ...\n) -> Flask | None: ...\n\n\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: bool = True\n) -> Flask | None:\n    try:\n        __import__(module_name)\n    except ImportError:\n        # Reraise the ImportError if it occurred within the imported module.\n        # Determine this by checking whether the trace has a depth > 1.\n        if sys.exc_info()[2].tb_next:  # type: ignore[union-attr]\n            raise NoAppException(\n                f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None\n        elif raise_if_not_found:\n            raise NoAppException(f\"Could not import {module_name!r}.\") from None\n        else:\n            return None\n\n    module = sys.modules[module_name]\n\n    if app_name is None:\n        return find_best_app(module)\n    else:\n        return find_app_by_string(module, app_name)\n\n\ndef get_version(ctx: click.Context, param: click.Parameter, value: t.Any) -> None:\n    if not value or ctx.resilient_parsing:\n        return\n\n    flask_version = importlib.metadata.version(\"flask\")\n    werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    click.echo(\n        f\"Python {platform.python_version()}\\n\"\n        f\"Flask {flask_version}\\n\"\n        f\"Werkzeug {werkzeug_version}\",\n        color=ctx.color,\n    )\n    ctx.exit()\n\n\nversion_option = click.Option(\n    [\"--version\"],\n    help=\"Show the Flask version.\",\n    expose_value=False,\n    callback=get_version,\n    is_flag=True,\n    is_eager=True,\n)\n\n\nclass ScriptInfo:\n    \"\"\"Helper object to deal with Flask applications.  This is usually not\n    necessary to interface with as it's used internally in the dispatching\n    to click.  In future versions of Flask this object will most likely play\n    a bigger role.  Typically it's created automatically by the\n    :class:`FlaskGroup` but you can also manually create it and pass it\n    onwards as click object.\n\n    .. versionchanged:: 3.1\n        Added the ``load_dotenv_defaults`` parameter and attribute.\n    \"\"\"\n\n    def __init__(\n        self,\n        app_import_path: str | None = None,\n        create_app: t.Callable[..., Flask] | None = None,\n        set_debug_flag: bool = True,\n        load_dotenv_defaults: bool = True,\n    ) -> None:\n        #: Optionally the import path for the Flask application.\n        self.app_import_path = app_import_path\n        #: Optionally a function that is passed the script info to create\n        #: the instance of the application.\n        self.create_app = create_app\n        #: A dictionary with arbitrary data that can be associated with\n        #: this script info.\n        self.data: dict[t.Any, t.Any] = {}\n        self.set_debug_flag = set_debug_flag\n\n        self.load_dotenv_defaults = get_load_dotenv(load_dotenv_defaults)\n        \"\"\"Whether default ``.flaskenv`` and ``.env`` files should be loaded.\n\n        ``ScriptInfo`` doesn't load anything, this is for reference when doing\n        the load elsewhere during processing.\n\n        .. versionadded:: 3.1\n        \"\"\"\n\n        self._loaded_app: Flask | None = None\n\n    def load_app(self) -> Flask:\n        \"\"\"Loads the Flask app (if not yet loaded) and returns it.  Calling\n        this multiple times will just result in the already loaded app to\n        be returned.\n        \"\"\"\n        if self._loaded_app is not None:\n            return self._loaded_app\n        app: Flask | None = None\n        if self.create_app is not None:\n            app = self.create_app()\n        else:\n            if self.app_import_path:\n                path, name = (\n                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                )[:2]\n                import_name = prepare_import(path)\n                app = locate_app(import_name, name)\n            else:\n                for path in (\"wsgi.py\", \"app.py\"):\n                    import_name = prepare_import(path)\n                    app = locate_app(import_name, None, raise_if_not_found=False)\n\n                    if app is not None:\n                        break\n\n        if app is None:\n            raise NoAppException(\n                \"Could not locate a Flask application. Use the\"\n                \" 'flask --app' option, 'FLASK_APP' environment\"\n                \" variable, or a 'wsgi.py' or 'app.py' file in the\"\n                \" current directory.\"\n            )\n\n        if self.set_debug_flag:\n            # Update the app's debug flag through the descriptor so that\n            # other values repopulate as well.\n            app.debug = get_debug_flag()\n\n        self._loaded_app = app\n        return app\n\n\npass_script_info = click.make_pass_decorator(ScriptInfo, ensure=True)\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef with_appcontext(f: F) -> F:\n    \"\"\"Wraps a callback so that it's guaranteed to be executed with the\n    script's application context.\n\n    Custom commands (and their options) registered under ``app.cli`` or\n    ``blueprint.cli`` will always have an app context available, this\n    decorator is not required in that case.\n\n    .. versionchanged:: 2.2\n        The app context is active for subcommands as well as the\n        decorated callback. The app context is always available to\n        ``app.cli`` command and parameter callbacks.\n    \"\"\"\n\n    @click.pass_context\n    def decorator(ctx: click.Context, /, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        if not current_app:\n            app = ctx.ensure_object(ScriptInfo).load_app()\n            ctx.with_resource(app.app_context())\n\n        return ctx.invoke(f, *args, **kwargs)\n\n    return update_wrapper(decorator, f)  # type: ignore[return-value]\n\n\nclass AppGroup(click.Group):\n    \"\"\"This works similar to a regular click :class:`~click.Group` but it\n    changes the behavior of the :meth:`command` decorator so that it\n    automatically wraps the functions in :func:`with_appcontext`.\n\n    Not to be confused with :class:`FlaskGroup`.\n    \"\"\"\n\n    def command(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Command]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it wraps callbacks in :func:`with_appcontext`\n        unless it's disabled by passing ``with_appcontext=False``.\n        \"\"\"\n        wrap_for_ctx = kwargs.pop(\"with_appcontext\", True)\n\n        def decorator(f: t.Callable[..., t.Any]) -> click.Command:\n            if wrap_for_ctx:\n                f = with_appcontext(f)\n            return super(AppGroup, self).command(*args, **kwargs)(f)  # type: ignore[no-any-return]\n\n        return decorator\n\n    def group(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Group]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it defaults the group class to\n        :class:`AppGroup`.\n        \"\"\"\n        kwargs.setdefault(\"cls\", AppGroup)\n        return super().group(*args, **kwargs)  # type: ignore[no-any-return]\n\n\ndef _set_app(ctx: click.Context, param: click.Option, value: str | None) -> str | None:\n    if value is None:\n        return None\n\n    info = ctx.ensure_object(ScriptInfo)\n    info.app_import_path = value\n    return value\n\n\n# This option is eager so the app will be available if --help is given.\n# --help is also eager, so --app must be before it in the param list.\n# no_args_is_help bypasses eager processing, so this option must be\n# processed manually in that case to ensure FLASK_APP gets picked up.\n_app_option = click.Option(\n    [\"-A\", \"--app\"],\n    metavar=\"IMPORT\",\n    help=(\n        \"The Flask application or factory function to load, in the form 'module:name'.\"\n        \" Module can be a dotted import or file path. Name is not required if it is\"\n        \" 'app', 'application', 'create_app', or 'make_app', and can be 'name(args)' to\"\n        \" pass arguments.\"\n    ),\n    is_eager=True,\n    expose_value=False,\n    callback=_set_app,\n)\n\n\ndef _set_debug(ctx: click.Context, param: click.Option, value: bool) -> bool | None:\n    # If the flag isn't provided, it will default to False. Don't use\n    # that, let debug be set by env in that case.\n    source = ctx.get_parameter_source(param.name)  # type: ignore[arg-type]\n\n    if source is not None and source in (\n        ParameterSource.DEFAULT,\n        ParameterSource.DEFAULT_MAP,\n    ):\n        return None\n\n    # Set with env var instead of ScriptInfo.load so that it can be\n    # accessed early during a factory function.\n    os.environ[\"FLASK_DEBUG\"] = \"1\" if value else \"0\"\n    return value\n\n\n_debug_option = click.Option(\n    [\"--debug/--no-debug\"],\n    help=\"Set debug mode.\",\n    expose_value=False,\n    callback=_set_debug,\n)\n\n\ndef _env_file_callback(\n    ctx: click.Context, param: click.Option, value: str | None\n) -> str | None:\n    try:\n        import dotenv  # noqa: F401\n    except ImportError:\n        # Only show an error if a value was passed, otherwise we still want to\n        # call load_dotenv and show a message without exiting.\n        if value is not None:\n            raise click.BadParameter(\n                \"python-dotenv must be installed to load an env file.\",\n                ctx=ctx,\n                param=param,\n            ) from None\n\n    # Load if a value was passed, or we want to load default files, or both.\n    if value is not None or ctx.obj.load_dotenv_defaults:\n        load_dotenv(value, load_defaults=ctx.obj.load_dotenv_defaults)\n\n    return value\n\n\n# This option is eager so env vars are loaded as early as possible to be\n# used by other options.\n_env_file_option = click.Option(\n    [\"-e\", \"--env-file\"],\n    type=click.Path(exists=True, dir_okay=False),\n    help=(\n        \"Load environment variables from this file, taking precedence over\"\n        \" those set by '.env' and '.flaskenv'. Variables set directly in the\"\n        \" environment take highest precedence. python-dotenv must be installed.\"\n    ),\n    is_eager=True,\n    expose_value=False,\n    callback=_env_file_callback,\n)\n\n\nclass FlaskGroup(AppGroup):\n    \"\"\"Special subclass of the :class:`AppGroup` group that supports\n    loading more commands from the configured Flask app.  Normally a\n    developer does not have to interface with this class but there are\n    some very advanced use cases for which it makes sense to create an\n    instance of this. see :ref:`custom-scripts`.\n\n    :param add_default_commands: if this is True then the default run and\n        shell commands will be added.\n    :param add_version_option: adds the ``--version`` option.\n    :param create_app: an optional callback that is passed the script info and\n        returns the loaded app.\n    :param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n        files to set environment variables. Will also change the working\n        directory to the directory containing the first file found.\n    :param set_debug_flag: Set the app's debug flag.\n\n    .. versionchanged:: 3.1\n        ``-e path`` takes precedence over default ``.env`` and ``.flaskenv`` files.\n\n    .. versionchanged:: 2.2\n        Added the ``-A/--app``, ``--debug/--no-debug``, ``-e/--env-file`` options.\n\n    .. versionchanged:: 2.2\n        An app context is pushed when running ``app.cli`` commands, so\n        ``@with_appcontext`` is no longer required for those commands.\n\n    .. versionchanged:: 1.0\n        If installed, python-dotenv will be used to load environment variables\n        from :file:`.env` and :file:`.flaskenv` files.\n    \"\"\"\n\n    def __init__(\n        self,\n        add_default_commands: bool = True,\n        create_app: t.Callable[..., Flask] | None = None,\n        add_version_option: bool = True,\n        load_dotenv: bool = True,\n        set_debug_flag: bool = True,\n        **extra: t.Any,\n    ) -> None:\n        params: list[click.Parameter] = list(extra.pop(\"params\", None) or ())\n        # Processing is done with option callbacks instead of a group\n        # callback. This allows users to make a custom group callback\n        # without losing the behavior. --env-file must come first so\n        # that it is eagerly evaluated before --app.\n        params.extend((_env_file_option, _app_option, _debug_option))\n\n        if add_version_option:\n            params.append(version_option)\n\n        if \"context_settings\" not in extra:\n            extra[\"context_settings\"] = {}\n\n        extra[\"context_settings\"].setdefault(\"auto_envvar_prefix\", \"FLASK\")\n\n        super().__init__(params=params, **extra)\n\n        self.create_app = create_app\n        self.load_dotenv = load_dotenv\n        self.set_debug_flag = set_debug_flag\n\n        if add_default_commands:\n            self.add_command(run_command)\n            self.add_command(shell_command)\n            self.add_command(routes_command)\n\n        self._loaded_plugin_commands = False\n\n    def _load_plugin_commands(self) -> None:\n        if self._loaded_plugin_commands:\n            return\n\n        if sys.version_info >= (3, 10):\n            from importlib import metadata\n        else:\n            # Use a backport on Python < 3.10. We technically have\n            # importlib.metadata on 3.8+, but the API changed in 3.10,\n            # so use the backport for consistency.\n            import importlib_metadata as metadata  # pyright: ignore\n\n        for ep in metadata.entry_points(group=\"flask.commands\"):\n            self.add_command(ep.load(), ep.name)\n\n        self._loaded_plugin_commands = True\n\n    def get_command(self, ctx: click.Context, name: str) -> click.Command | None:\n        self._load_plugin_commands()\n        # Look up built-in and plugin commands, which should be\n        # available even if the app fails to load.\n        rv = super().get_command(ctx, name)\n\n        if rv is not None:\n            return rv\n\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Look up commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            app = info.load_app()\n        except NoAppException as e:\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n            return None\n\n        # Push an app context for the loaded app unless it is already\n        # active somehow. This makes the context available to parameter\n        # and command callbacks without needing @with_appcontext.\n        if not current_app or current_app._get_current_object() is not app:  # type: ignore[attr-defined]\n            ctx.with_resource(app.app_context())\n\n        return app.cli.get_command(ctx, name)\n\n    def list_commands(self, ctx: click.Context) -> list[str]:\n        self._load_plugin_commands()\n        # Start with the built-in and plugin commands.\n        rv = set(super().list_commands(ctx))\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Add commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            rv.update(info.load_app().cli.list_commands(ctx))\n        except NoAppException as e:\n            # When an app couldn't be loaded, show the error message\n            # without the traceback.\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n        except Exception:\n            # When any other errors occurred during loading, show the\n            # full traceback.\n            click.secho(f\"{traceback.format_exc()}\\n\", err=True, fg=\"red\")\n\n        return sorted(rv)\n\n    def make_context(\n        self,\n        info_name: str | None,\n        args: list[str],\n        parent: click.Context | None = None,\n        **extra: t.Any,\n    ) -> click.Context:\n        # Set a flag to tell app.run to become a no-op. If app.run was\n        # not in a __name__ == __main__ guard, it would start the server\n        # when importing, blocking whatever command is being called.\n        os.environ[\"FLASK_RUN_FROM_CLI\"] = \"true\"\n\n        if \"obj\" not in extra and \"obj\" not in self.context_settings:\n            extra[\"obj\"] = ScriptInfo(\n                create_app=self.create_app,\n                set_debug_flag=self.set_debug_flag,\n                load_dotenv_defaults=self.load_dotenv,\n            )\n\n        return super().make_context(info_name, args, parent=parent, **extra)\n\n    def parse_args(self, ctx: click.Context, args: list[str]) -> list[str]:\n        if (not args and self.no_args_is_help) or (\n            len(args) == 1 and args[0] in self.get_help_option_names(ctx)\n        ):\n            # Attempt to load --env-file and --app early in case they\n            # were given as env vars. Otherwise no_args_is_help will not\n            # see commands from app.cli.\n            _env_file_option.handle_parse_result(ctx, {}, [])\n            _app_option.handle_parse_result(ctx, {}, [])\n\n        return super().parse_args(ctx, args)\n\n\ndef _path_is_ancestor(path: str, other: str) -> bool:\n    \"\"\"Take ``other`` and remove the length of ``path`` from it. Then join it\n    to ``path``. If it is the original value, ``path`` is an ancestor of\n    ``other``.\"\"\"\n    return os.path.join(path, other[len(path) :].lstrip(os.sep)) == other\n\n\ndef load_dotenv(\n    path: str | os.PathLike[str] | None = None, load_defaults: bool = True\n) -> bool:\n    \"\"\"Load \"dotenv\" files to set environment variables. A given path takes\n    precedence over ``.env``, which takes precedence over ``.flaskenv``. After\n    loading and combining these files, values are only set if the key is not\n    already set in ``os.environ``.\n\n    This is a no-op if `python-dotenv`_ is not installed.\n\n    .. _python-dotenv: https://github.com/theskumar/python-dotenv#readme\n\n    :param path: Load the file at this location.\n    :param load_defaults: Search for and load the default ``.flaskenv`` and\n        ``.env`` files.\n    :return: ``True`` if at least one env var was loaded.\n\n    .. versionchanged:: 3.1\n        Added the ``load_defaults`` parameter. A given path takes precedence\n        over default files.\n\n    .. versionchanged:: 2.0\n        The current directory is not changed to the location of the\n        loaded file.\n\n    .. versionchanged:: 2.0\n        When loading the env files, set the default encoding to UTF-8.\n\n    .. versionchanged:: 1.1.0\n        Returns ``False`` when python-dotenv is not installed, or when\n        the given path isn't a file.\n\n    .. versionadded:: 1.0\n    \"\"\"\n    try:\n        import dotenv\n    except ImportError:\n        if path or os.path.isfile(\".env\") or os.path.isfile(\".flaskenv\"):\n            click.secho(\n                \" * Tip: There are .env files present. Install python-dotenv\"\n                \" to use them.\",\n                fg=\"yellow\",\n                err=True,\n            )\n\n        return False\n\n    data: dict[str, str | None] = {}\n\n    if load_defaults:\n        for default_name in (\".flaskenv\", \".env\"):\n            if not (default_path := dotenv.find_dotenv(default_name, usecwd=True)):\n                continue\n\n            data |= dotenv.dotenv_values(default_path, encoding=\"utf-8\")\n\n    if path is not None and os.path.isfile(path):\n        data |= dotenv.dotenv_values(path, encoding=\"utf-8\")\n\n    for key, value in data.items():\n        if key in os.environ or value is None:\n            continue\n\n        os.environ[key] = value\n\n    return bool(data)  # True if at least one env var was loaded.\n\n\ndef show_server_banner(debug: bool, app_import_path: str | None) -> None:\n    \"\"\"Show extra startup messages the first time the server is run,\n    ignoring the reloader.\n    \"\"\"\n    if is_running_from_reloader():\n        return\n\n    if app_import_path is not None:\n        click.echo(f\" * Serving Flask app '{app_import_path}'\")\n\n    if debug is not None:\n        click.echo(f\" * Debug mode: {'on' if debug else 'off'}\")\n\n\nclass CertParamType(click.ParamType):\n    \"\"\"Click option type for the ``--cert`` option. Allows either an\n    existing file, the string ``'adhoc'``, or an import for a\n    :class:`~ssl.SSLContext` object.\n    \"\"\"\n\n    name = \"path\"\n\n    def __init__(self) -> None:\n        self.path_type = click.Path(exists=True, dir_okay=False, resolve_path=True)\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        try:\n            import ssl\n        except ImportError:\n            raise click.BadParameter(\n                'Using \"--cert\" requires Python to be compiled with SSL support.',\n                ctx,\n                param,\n            ) from None\n\n        try:\n            return self.path_type(value, param, ctx)\n        except click.BadParameter:\n            value = click.STRING(value, param, ctx).lower()\n\n            if value == \"adhoc\":\n                try:\n                    import cryptography  # noqa: F401\n                except ImportError:\n                    raise click.BadParameter(\n                        \"Using ad-hoc certificates requires the cryptography library.\",\n                        ctx,\n                        param,\n                    ) from None\n\n                return value\n\n            obj = import_string(value, silent=True)\n\n            if isinstance(obj, ssl.SSLContext):\n                return obj\n\n            raise\n\n\ndef _validate_key(ctx: click.Context, param: click.Parameter, value: t.Any) -> t.Any:\n    \"\"\"The ``--key`` option must be specified when ``--cert`` is a file.\n    Modifies the ``cert`` param to be a ``(cert, key)`` pair if needed.\n    \"\"\"\n    cert = ctx.params.get(\"cert\")\n    is_adhoc = cert == \"adhoc\"\n\n    try:\n        import ssl\n    except ImportError:\n        is_context = False\n    else:\n        is_context = isinstance(cert, ssl.SSLContext)\n\n    if value is not None:\n        if is_adhoc:\n            raise click.BadParameter(\n                'When \"--cert\" is \"adhoc\", \"--key\" is not used.', ctx, param\n            )\n\n        if is_context:\n            raise click.BadParameter(\n                'When \"--cert\" is an SSLContext object, \"--key\" is not used.',\n                ctx,\n                param,\n            )\n\n        if not cert:\n            raise click.BadParameter('\"--cert\" must also be specified.', ctx, param)\n\n        ctx.params[\"cert\"] = cert, value\n\n    else:\n        if cert and not (is_adhoc or is_context):\n            raise click.BadParameter('Required when using \"--cert\".', ctx, param)\n\n    return value\n\n\nclass SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        items = self.split_envvar_value(value)\n        # can't call no-arg super() inside list comprehension until Python 3.12\n        super_convert = super().convert\n        return [super_convert(item, param, ctx) for item in items]\n\n\n@click.command(\"run\", short_help=\"Run a development server.\")\n@click.option(\"--host\", \"-h\", default=\"127.0.0.1\", help=\"The interface to bind to.\")\n@click.option(\"--port\", \"-p\", default=5000, help=\"The port to bind to.\")\n@click.option(\n    \"--cert\",\n    type=CertParamType(),\n    help=\"Specify a certificate file to use HTTPS.\",\n    is_eager=True,\n)\n@click.option(\n    \"--key\",\n    type=click.Path(exists=True, dir_okay=False, resolve_path=True),\n    callback=_validate_key,\n    expose_value=False,\n    help=\"The key file to use when specifying a certificate.\",\n)\n@click.option(\n    \"--reload/--no-reload\",\n    default=None,\n    help=\"Enable or disable the reloader. By default the reloader \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--debugger/--no-debugger\",\n    default=None,\n    help=\"Enable or disable the debugger. By default the debugger \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--with-threads/--without-threads\",\n    default=True,\n    help=\"Enable or disable multithreading.\",\n)\n@click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        f\" are separated by {os.path.pathsep!r}.\"\n    ),\n)\n@click.option(\n    \"--exclude-patterns\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Files matching these fnmatch patterns will not trigger a reload\"\n        \" on change. Multiple patterns are separated by\"\n        f\" {os.path.pathsep!r}.\"\n    ),\n)\n@pass_script_info\ndef run_command(\n    info: ScriptInfo,\n    host: str,\n    port: int,\n    reload: bool,\n    debugger: bool,\n    with_threads: bool,\n    cert: ssl.SSLContext | tuple[str, str | None] | t.Literal[\"adhoc\"] | None,\n    extra_files: list[str] | None,\n    exclude_patterns: list[str] | None,\n) -> None:\n    \"\"\"Run a local development server.\n\n    This server is for development purposes only. It does not provide\n    the stability, security, or performance of production WSGI servers.\n\n    The reloader and debugger are enabled by default with the '--debug'\n    option.\n    \"\"\"\n    try:\n        app: WSGIApplication = info.load_app()  # pyright: ignore\n    except Exception as e:\n        if is_running_from_reloader():\n            # When reloading, print out the error immediately, but raise\n            # it later so the debugger or server can handle it.\n            traceback.print_exc()\n            err = e\n\n            def app(\n                environ: WSGIEnvironment, start_response: StartResponse\n            ) -> cabc.Iterable[bytes]:\n                raise err from None\n\n        else:\n            # When not reloading, raise the error immediately so the\n            # command fails.\n            raise e from None\n\n    debug = get_debug_flag()\n\n    if reload is None:\n        reload = debug\n\n    if debugger is None:\n        debugger = debug\n\n    show_server_banner(debug, info.app_import_path)\n\n    run_simple(\n        host,\n        port,\n        app,\n        use_reloader=reload,\n        use_debugger=debugger,\n        threaded=with_threads,\n        ssl_context=cert,\n        extra_files=extra_files,\n        exclude_patterns=exclude_patterns,\n    )\n\n\nrun_command.params.insert(0, _debug_option)\n\n\n@click.command(\"shell\", short_help=\"Run a shell in the app context.\")\n@with_appcontext\ndef shell_command() -> None:\n    \"\"\"Run an interactive Python shell in the context of a given\n    Flask application.  The application will populate the default\n    namespace of this shell according to its configuration.\n\n    This is useful for executing small snippets of management code\n    without having to manually configure the application.\n    \"\"\"\n    import code\n\n    banner = (\n        f\"Python {sys.version} on {sys.platform}\\n\"\n        f\"App: {current_app.import_name}\\n\"\n        f\"Instance: {current_app.instance_path}\"\n    )\n    ctx: dict[str, t.Any] = {}\n\n    # Support the regular Python interpreter startup script if someone\n    # is using it.\n    startup = os.environ.get(\"PYTHONSTARTUP\")\n    if startup and os.path.isfile(startup):\n        with open(startup) as f:\n            eval(compile(f.read(), startup, \"exec\"), ctx)\n\n    ctx.update(current_app.make_shell_context())\n\n    # Site, customize, or startup script can set a hook to call when\n    # entering interactive mode. The default one sets up readline with\n    # tab and history completion.\n    interactive_hook = getattr(sys, \"__interactivehook__\", None)\n\n    if interactive_hook is not None:\n        try:\n            import readline\n            from rlcompleter import Completer\n        except ImportError:\n            pass\n        else:\n            # rlcompleter uses __main__.__dict__ by default, which is\n            # flask.__main__. Use the shell context instead.\n            readline.set_completer(Completer(ctx).complete)\n\n        interactive_hook()\n\n    code.interact(banner=banner, local=ctx)\n\n\n@click.command(\"routes\", short_help=\"Show the routes for the app.\")\n@click.option(\n    \"--sort\",\n    \"-s\",\n    type=click.Choice((\"endpoint\", \"methods\", \"domain\", \"rule\", \"match\")),\n    default=\"endpoint\",\n    help=(\n        \"Method to sort routes by. 'match' is the order that Flask will match routes\"\n        \" when dispatching a request.\"\n    ),\n)\n@click.option(\"--all-methods\", is_flag=True, help=\"Show HEAD and OPTIONS methods.\")\n@with_appcontext\ndef routes_command(sort: str, all_methods: bool) -> None:\n    \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n    rules = list(current_app.url_map.iter_rules())\n\n    if not rules:\n        click.echo(\"No routes were registered.\")\n        return\n\n    ignored_methods = set() if all_methods else {\"HEAD\", \"OPTIONS\"}\n    host_matching = current_app.url_map.host_matching\n    has_domain = any(rule.host if host_matching else rule.subdomain for rule in rules)\n    rows = []\n\n    for rule in rules:\n        row = [\n            rule.endpoint,\n            \", \".join(sorted((rule.methods or set()) - ignored_methods)),\n        ]\n\n        if has_domain:\n            row.append((rule.host if host_matching else rule.subdomain) or \"\")\n\n        row.append(rule.rule)\n        rows.append(row)\n\n    headers = [\"Endpoint\", \"Methods\"]\n    sorts = [\"endpoint\", \"methods\"]\n\n    if has_domain:\n        headers.append(\"Host\" if host_matching else \"Subdomain\")\n        sorts.append(\"domain\")\n\n    headers.append(\"Rule\")\n    sorts.append(\"rule\")\n\n    try:\n        rows.sort(key=itemgetter(sorts.index(sort)))\n    except ValueError:\n        pass\n\n    rows.insert(0, headers)\n    widths = [max(len(row[i]) for row in rows) for i in range(len(headers))]\n    rows.insert(1, [\"-\" * w for w in widths])\n    template = \"  \".join(f\"{{{i}:<{w}}}\" for i, w in enumerate(widths))\n\n    for row in rows:\n        click.echo(template.format(*row))\n\n\ncli = FlaskGroup(\n    name=\"flask\",\n    help=\"\"\"\\\nA general utility script for Flask applications.\n\nAn application to load must be given with the '--app' option,\n'FLASK_APP' environment variable, or with a 'wsgi.py' or 'app.py' file\nin the current directory.\n\"\"\",\n)\n\n\ndef main() -> None:\n    cli.main()\n\n\nif __name__ == \"__main__\":\n    main()\n", 1135], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py": ["from __future__ import annotations\n\nimport logging\nimport os\nimport sys\nimport typing as t\nfrom datetime import timedelta\nfrom itertools import chain\n\nfrom werkzeug.exceptions import Aborter\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.sansio.response import Response\nfrom werkzeug.utils import cached_property\nfrom werkzeug.utils import redirect as _wz_redirect\n\nfrom .. import typing as ft\nfrom ..config import Config\nfrom ..config import ConfigAttribute\nfrom ..ctx import _AppCtxGlobals\nfrom ..helpers import _split_blueprint_path\nfrom ..helpers import get_debug_flag\nfrom ..json.provider import DefaultJSONProvider\nfrom ..json.provider import JSONProvider\nfrom ..logging import create_logger\nfrom ..templating import DispatchingJinjaLoader\nfrom ..templating import Environment\nfrom .scaffold import _endpoint_from_view_func\nfrom .scaffold import find_package\nfrom .scaffold import Scaffold\nfrom .scaffold import setupmethod\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.wrappers import Response as BaseResponse\n\n    from ..testing import FlaskClient\n    from ..testing import FlaskCliRunner\n    from .blueprints import Blueprint\n\nT_shell_context_processor = t.TypeVar(\n    \"T_shell_context_processor\", bound=ft.ShellContextProcessorCallable\n)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_filter = t.TypeVar(\"T_template_filter\", bound=ft.TemplateFilterCallable)\nT_template_global = t.TypeVar(\"T_template_global\", bound=ft.TemplateGlobalCallable)\nT_template_test = t.TypeVar(\"T_template_test\", bound=ft.TemplateTestCallable)\n\n\ndef _make_timedelta(value: timedelta | int | None) -> timedelta | None:\n    if value is None or isinstance(value, timedelta):\n        return value\n\n    return timedelta(seconds=value)\n\n\nclass App(Scaffold):\n    \"\"\"The flask object implements a WSGI application and acts as the central\n    object.  It is passed the name of the module or package of the\n    application.  Once it is created it will act as a central registry for\n    the view functions, the URL rules, template configuration and much more.\n\n    The name of the package is used to resolve resources from inside the\n    package or the folder the module is contained in depending on if the\n    package parameter resolves to an actual python package (a folder with\n    an :file:`__init__.py` file inside) or a standard module (just a ``.py`` file).\n\n    For more information about resource loading, see :func:`open_resource`.\n\n    Usually you create a :class:`Flask` instance in your main module or\n    in the :file:`__init__.py` file of your package like this::\n\n        from flask import Flask\n        app = Flask(__name__)\n\n    .. admonition:: About the First Parameter\n\n        The idea of the first parameter is to give Flask an idea of what\n        belongs to your application.  This name is used to find resources\n        on the filesystem, can be used by extensions to improve debugging\n        information and a lot more.\n\n        So it's important what you provide there.  If you are using a single\n        module, `__name__` is always the correct value.  If you however are\n        using a package, it's usually recommended to hardcode the name of\n        your package there.\n\n        For example if your application is defined in :file:`yourapplication/app.py`\n        you should create it with one of the two versions below::\n\n            app = Flask('yourapplication')\n            app = Flask(__name__.split('.')[0])\n\n        Why is that?  The application will work even with `__name__`, thanks\n        to how resources are looked up.  However it will make debugging more\n        painful.  Certain extensions can make assumptions based on the\n        import name of your application.  For example the Flask-SQLAlchemy\n        extension will look for the code in your application that triggered\n        an SQL query in debug mode.  If the import name is not properly set\n        up, that debugging information is lost.  (For example it would only\n        pick up SQL queries in `yourapplication.app` and not\n        `yourapplication.views.frontend`)\n\n    .. versionadded:: 0.7\n       The `static_url_path`, `static_folder`, and `template_folder`\n       parameters were added.\n\n    .. versionadded:: 0.8\n       The `instance_path` and `instance_relative_config` parameters were\n       added.\n\n    .. versionadded:: 0.11\n       The `root_path` parameter was added.\n\n    .. versionadded:: 1.0\n       The ``host_matching`` and ``static_host`` parameters were added.\n\n    .. versionadded:: 1.0\n       The ``subdomain_matching`` parameter was added. Subdomain\n       matching needs to be enabled manually now. Setting\n       :data:`SERVER_NAME` does not implicitly enable it.\n\n    :param import_name: the name of the application package\n    :param static_url_path: can be used to specify a different path for the\n                            static files on the web.  Defaults to the name\n                            of the `static_folder` folder.\n    :param static_folder: The folder with static files that is served at\n        ``static_url_path``. Relative to the application ``root_path``\n        or an absolute path. Defaults to ``'static'``.\n    :param static_host: the host to use when adding the static route.\n        Defaults to None. Required when using ``host_matching=True``\n        with a ``static_folder`` configured.\n    :param host_matching: set ``url_map.host_matching`` attribute.\n        Defaults to False.\n    :param subdomain_matching: consider the subdomain relative to\n        :data:`SERVER_NAME` when matching routes. Defaults to False.\n    :param template_folder: the folder that contains the templates that should\n                            be used by the application.  Defaults to\n                            ``'templates'`` folder in the root path of the\n                            application.\n    :param instance_path: An alternative instance path for the application.\n                          By default the folder ``'instance'`` next to the\n                          package or module is assumed to be the instance\n                          path.\n    :param instance_relative_config: if set to ``True`` relative filenames\n                                     for loading the config are assumed to\n                                     be relative to the instance path instead\n                                     of the application root.\n    :param root_path: The path to the root of the application files.\n        This should only be set manually when it can't be detected\n        automatically, such as for namespace packages.\n    \"\"\"\n\n    #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n\n    #: The class that is used for the Jinja environment.\n    #:\n    #: .. versionadded:: 0.11\n    jinja_environment = Environment\n\n    #: The class that is used for the :data:`~flask.g` instance.\n    #:\n    #: Example use cases for a custom class:\n    #:\n    #: 1. Store arbitrary attributes on flask.g.\n    #: 2. Add a property for lazy per-request database connectors.\n    #: 3. Return None instead of AttributeError on unexpected attributes.\n    #: 4. Raise exception if an unexpected attr is set, a \"controlled\" flask.g.\n    #:\n    #: In Flask 0.9 this property was called `request_globals_class` but it\n    #: was changed in 0.10 to :attr:`app_ctx_globals_class` because the\n    #: flask.g object is now application context scoped.\n    #:\n    #: .. versionadded:: 0.10\n    app_ctx_globals_class = _AppCtxGlobals\n\n    #: The class that is used for the ``config`` attribute of this app.\n    #: Defaults to :class:`~flask.Config`.\n    #:\n    #: Example use cases for a custom class:\n    #:\n    #: 1. Default values for certain config options.\n    #: 2. Access to config values through attributes in addition to keys.\n    #:\n    #: .. versionadded:: 0.11\n    config_class = Config\n\n    #: The testing flag.  Set this to ``True`` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate test helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: If this is enabled and PROPAGATE_EXCEPTIONS is not changed from the\n    #: default it's implicitly enabled.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: ``TESTING`` configuration key.  Defaults to ``False``.\n    testing = ConfigAttribute[bool](\"TESTING\")\n\n    #: If a secret key is set, cryptographic components can use this to\n    #: sign cookies and other things. Set this to a complex random value\n    #: when you want to use the secure cookie for instance.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: :data:`SECRET_KEY` configuration key. Defaults to ``None``.\n    secret_key = ConfigAttribute[t.Union[str, bytes, None]](\"SECRET_KEY\")\n\n    #: A :class:`~datetime.timedelta` which is used to set the expiration\n    #: date of a permanent session.  The default is 31 days which makes a\n    #: permanent session survive for roughly one month.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: ``PERMANENT_SESSION_LIFETIME`` configuration key.  Defaults to\n    #: ``timedelta(days=31)``\n    permanent_session_lifetime = ConfigAttribute[timedelta](\n        \"PERMANENT_SESSION_LIFETIME\",\n        get_converter=_make_timedelta,  # type: ignore[arg-type]\n    )\n\n    json_provider_class: type[JSONProvider] = DefaultJSONProvider\n    \"\"\"A subclass of :class:`~flask.json.provider.JSONProvider`. An\n    instance is created and assigned to :attr:`app.json` when creating\n    the app.\n\n    The default, :class:`~flask.json.provider.DefaultJSONProvider`, uses\n    Python's built-in :mod:`json` library. A different provider can use\n    a different JSON library.\n\n    .. versionadded:: 2.2\n    \"\"\"\n\n    #: Options that are passed to the Jinja environment in\n    #: :meth:`create_jinja_environment`. Changing these options after\n    #: the environment is created (accessing :attr:`jinja_env`) will\n    #: have no effect.\n    #:\n    #: .. versionchanged:: 1.1.0\n    #:     This is a ``dict`` instead of an ``ImmutableDict`` to allow\n    #:     easier configuration.\n    #:\n    jinja_options: dict[str, t.Any] = {}\n\n    #: The rule object to use for URL rules created.  This is used by\n    #: :meth:`add_url_rule`.  Defaults to :class:`werkzeug.routing.Rule`.\n    #:\n    #: .. versionadded:: 0.7\n    url_rule_class = Rule\n\n    #: The map object to use for storing the URL rules and routing\n    #: configuration parameters. Defaults to :class:`werkzeug.routing.Map`.\n    #:\n    #: .. versionadded:: 1.1.0\n    url_map_class = Map\n\n    #: The :meth:`test_client` method creates an instance of this test\n    #: client class. Defaults to :class:`~flask.testing.FlaskClient`.\n    #:\n    #: .. versionadded:: 0.7\n    test_client_class: type[FlaskClient] | None = None\n\n    #: The :class:`~click.testing.CliRunner` subclass, by default\n    #: :class:`~flask.testing.FlaskCliRunner` that is used by\n    #: :meth:`test_cli_runner`. Its ``__init__`` method should take a\n    #: Flask app object as the first argument.\n    #:\n    #: .. versionadded:: 1.0\n    test_cli_runner_class: type[FlaskCliRunner] | None = None\n\n    default_config: dict[str, t.Any]\n    response_class: type[Response]\n\n    def __init__(\n        self,\n        import_name: str,\n        static_url_path: str | None = None,\n        static_folder: str | os.PathLike[str] | None = \"static\",\n        static_host: str | None = None,\n        host_matching: bool = False,\n        subdomain_matching: bool = False,\n        template_folder: str | os.PathLike[str] | None = \"templates\",\n        instance_path: str | None = None,\n        instance_relative_config: bool = False,\n        root_path: str | None = None,\n    ) -> None:\n        super().__init__(\n            import_name=import_name,\n            static_folder=static_folder,\n            static_url_path=static_url_path,\n            template_folder=template_folder,\n            root_path=root_path,\n        )\n\n        if instance_path is None:\n            instance_path = self.auto_find_instance_path()\n        elif not os.path.isabs(instance_path):\n            raise ValueError(\n                \"If an instance path is provided it must be absolute.\"\n                \" A relative path was given instead.\"\n            )\n\n        #: Holds the path to the instance folder.\n        #:\n        #: .. versionadded:: 0.8\n        self.instance_path = instance_path\n\n        #: The configuration dictionary as :class:`Config`.  This behaves\n        #: exactly like a regular dictionary but supports additional methods\n        #: to load a config from files.\n        self.config = self.make_config(instance_relative_config)\n\n        #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        #:     Moved from ``flask.abort``, which calls this object.\n        self.aborter = self.make_aborter()\n\n        self.json: JSONProvider = self.json_provider_class(self)\n        \"\"\"Provides access to JSON methods. Functions in ``flask.json``\n        will call methods on this provider when the application context\n        is active. Used for handling JSON requests and responses.\n\n        An instance of :attr:`json_provider_class`. Can be customized by\n        changing that attribute on a subclass, or by assigning to this\n        attribute afterwards.\n\n        The default, :class:`~flask.json.provider.DefaultJSONProvider`,\n        uses Python's built-in :mod:`json` library. A different provider\n        can use a different JSON library.\n\n        .. versionadded:: 2.2\n        \"\"\"\n\n        #: A list of functions that are called by\n        #: :meth:`handle_url_build_error` when :meth:`.url_for` raises a\n        #: :exc:`~werkzeug.routing.BuildError`. Each function is called\n        #: with ``error``, ``endpoint`` and ``values``. If a function\n        #: returns ``None`` or raises a ``BuildError``, it is skipped.\n        #: Otherwise, its return value is returned by ``url_for``.\n        #:\n        #: .. versionadded:: 0.9\n        self.url_build_error_handlers: list[\n            t.Callable[[Exception, str, dict[str, t.Any]], str]\n        ] = []\n\n        #: A list of functions that are called when the application context\n        #: is destroyed.  Since the application context is also torn down\n        #: if the request ends this is the place to store code that disconnects\n        #: from databases.\n        #:\n        #: .. versionadded:: 0.9\n        self.teardown_appcontext_funcs: list[ft.TeardownCallable] = []\n\n        #: A list of shell context processor functions that should be run\n        #: when a shell context is created.\n        #:\n        #: .. versionadded:: 0.11\n        self.shell_context_processors: list[ft.ShellContextProcessorCallable] = []\n\n        #: Maps registered blueprint names to blueprint objects. The\n        #: dict retains the order the blueprints were registered in.\n        #: Blueprints can be registered multiple times, this dict does\n        #: not track how often they were attached.\n        #:\n        #: .. versionadded:: 0.7\n        self.blueprints: dict[str, Blueprint] = {}\n\n        #: a place where extensions can store application specific state.  For\n        #: example this is where an extension could store database engines and\n        #: similar things.\n        #:\n        #: The key must match the name of the extension module. For example in\n        #: case of a \"Flask-Foo\" extension in `flask_foo`, the key would be\n        #: ``'foo'``.\n        #:\n        #: .. versionadded:: 0.7\n        self.extensions: dict[str, t.Any] = {}\n\n        #: The :class:`~werkzeug.routing.Map` for this instance.  You can use\n        #: this to change the routing converters after the class was created\n        #: but before any routes are connected.  Example::\n        #:\n        #:    from werkzeug.routing import BaseConverter\n        #:\n        #:    class ListConverter(BaseConverter):\n        #:        def to_python(self, value):\n        #:            return value.split(',')\n        #:        def to_url(self, values):\n        #:            return ','.join(super(ListConverter, self).to_url(value)\n        #:                            for value in values)\n        #:\n        #:    app = Flask(__name__)\n        #:    app.url_map.converters['list'] = ListConverter\n        self.url_map = self.url_map_class(host_matching=host_matching)\n\n        self.subdomain_matching = subdomain_matching\n\n        # tracks internally if the application already handled at least one\n        # request.\n        self._got_first_request = False\n\n    def _check_setup_finished(self, f_name: str) -> None:\n        if self._got_first_request:\n            raise AssertionError(\n                f\"The setup method '{f_name}' can no longer be called\"\n                \" on the application. It has already handled its first\"\n                \" request, any changes will not be applied\"\n                \" consistently.\\n\"\n                \"Make sure all imports, decorators, functions, etc.\"\n                \" needed to set up the application are done before\"\n                \" running it.\"\n            )\n\n    @cached_property\n    def name(self) -> str:  # type: ignore\n        \"\"\"The name of the application.  This is usually the import name\n        with the difference that it's guessed from the run file if the\n        import name is main.  This name is used as a display name when\n        Flask needs the name of the application.  It can be set and overridden\n        to change the value.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if self.import_name == \"__main__\":\n            fn: str | None = getattr(sys.modules[\"__main__\"], \"__file__\", None)\n            if fn is None:\n                return \"__main__\"\n            return os.path.splitext(os.path.basename(fn))[0]\n        return self.import_name\n\n    @cached_property\n    def logger(self) -> logging.Logger:\n        \"\"\"A standard Python :class:`~logging.Logger` for the app, with\n        the same name as :attr:`name`.\n\n        In debug mode, the logger's :attr:`~logging.Logger.level` will\n        be set to :data:`~logging.DEBUG`.\n\n        If there are no handlers configured, a default handler will be\n        added. See :doc:`/logging` for more information.\n\n        .. versionchanged:: 1.1.0\n            The logger takes the same name as :attr:`name` rather than\n            hard-coding ``\"flask.app\"``.\n\n        .. versionchanged:: 1.0.0\n            Behavior was simplified. The logger is always named\n            ``\"flask.app\"``. The level is only set during configuration,\n            it doesn't check ``app.debug`` each time. Only one format is\n            used, not different ones depending on ``app.debug``. No\n            handlers are removed, and a handler is only added if no\n            handlers are already configured.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        return create_logger(self)\n\n    @cached_property\n    def jinja_env(self) -> Environment:\n        \"\"\"The Jinja environment used to load templates.\n\n        The environment is created the first time this property is\n        accessed. Changing :attr:`jinja_options` after that will have no\n        effect.\n        \"\"\"\n        return self.create_jinja_environment()\n\n    def create_jinja_environment(self) -> Environment:\n        raise NotImplementedError()\n\n    def make_config(self, instance_relative: bool = False) -> Config:\n        \"\"\"Used to create the config attribute by the Flask constructor.\n        The `instance_relative` parameter is passed in from the constructor\n        of Flask (there named `instance_relative_config`) and indicates if\n        the config should be relative to the instance path or the root path\n        of the application.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        root_path = self.root_path\n        if instance_relative:\n            root_path = self.instance_path\n        defaults = dict(self.default_config)\n        defaults[\"DEBUG\"] = get_debug_flag()\n        return self.config_class(root_path, defaults)\n\n    def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n\n    def auto_find_instance_path(self) -> str:\n        \"\"\"Tries to locate the instance path if it was not provided to the\n        constructor of the application class.  It will basically calculate\n        the path to a folder named ``instance`` next to your main file or\n        the package.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        prefix, package_path = find_package(self.import_name)\n        if prefix is None:\n            return os.path.join(package_path, \"instance\")\n        return os.path.join(prefix, \"var\", f\"{self.name}-instance\")\n\n    def create_global_jinja_loader(self) -> DispatchingJinjaLoader:\n        \"\"\"Creates the loader for the Jinja2 environment.  Can be used to\n        override just the loader and keeping the rest unchanged.  It's\n        discouraged to override this function.  Instead one should override\n        the :meth:`jinja_loader` function instead.\n\n        The global loader dispatches between the loaders of the application\n        and the individual blueprints.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        return DispatchingJinjaLoader(self)\n\n    def select_jinja_autoescape(self, filename: str) -> bool:\n        \"\"\"Returns ``True`` if autoescaping should be active for the given\n        template name. If no template name is given, returns `True`.\n\n        .. versionchanged:: 2.2\n            Autoescaping is now enabled by default for ``.svg`` files.\n\n        .. versionadded:: 0.5\n        \"\"\"\n        if filename is None:\n            return True\n        return filename.endswith((\".html\", \".htm\", \".xml\", \".xhtml\", \".svg\"))\n\n    @property\n    def debug(self) -> bool:\n        \"\"\"Whether debug mode is enabled. When using ``flask run`` to start the\n        development server, an interactive debugger will be shown for unhandled\n        exceptions, and the server will be reloaded when code changes. This maps to the\n        :data:`DEBUG` config key. It may not behave as expected if set late.\n\n        **Do not enable debug mode when deploying in production.**\n\n        Default: ``False``\n        \"\"\"\n        return self.config[\"DEBUG\"]  # type: ignore[no-any-return]\n\n    @debug.setter\n    def debug(self, value: bool) -> None:\n        self.config[\"DEBUG\"] = value\n\n        if self.config[\"TEMPLATES_AUTO_RELOAD\"] is None:\n            self.jinja_env.auto_reload = value\n\n    @setupmethod\n    def register_blueprint(self, blueprint: Blueprint, **options: t.Any) -> None:\n        \"\"\"Register a :class:`~flask.Blueprint` on the application. Keyword\n        arguments passed to this method will override the defaults set on the\n        blueprint.\n\n        Calls the blueprint's :meth:`~flask.Blueprint.register` method after\n        recording the blueprint in the application's :attr:`blueprints`.\n\n        :param blueprint: The blueprint to register.\n        :param url_prefix: Blueprint routes will be prefixed with this.\n        :param subdomain: Blueprint routes will match on this subdomain.\n        :param url_defaults: Blueprint routes will use these default values for\n            view arguments.\n        :param options: Additional keyword arguments are passed to\n            :class:`~flask.blueprints.BlueprintSetupState`. They can be\n            accessed in :meth:`~flask.Blueprint.record` callbacks.\n\n        .. versionchanged:: 2.0.1\n            The ``name`` option can be used to change the (pre-dotted)\n            name the blueprint is registered with. This allows the same\n            blueprint to be registered multiple times with unique names\n            for ``url_for``.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        blueprint.register(self, options)\n\n    def iter_blueprints(self) -> t.ValuesView[Blueprint]:\n        \"\"\"Iterates over all blueprints by the order they were registered.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        return self.blueprints.values()\n\n    @setupmethod\n    def add_url_rule(\n        self,\n        rule: str,\n        endpoint: str | None = None,\n        view_func: ft.RouteCallable | None = None,\n        provide_automatic_options: bool | None = None,\n        **options: t.Any,\n    ) -> None:\n        if endpoint is None:\n            endpoint = _endpoint_from_view_func(view_func)  # type: ignore\n        options[\"endpoint\"] = endpoint\n        methods = options.pop(\"methods\", None)\n\n        # if the methods are not given and the view_func object knows its\n        # methods we can use that instead.  If neither exists, we go with\n        # a tuple of only ``GET`` as default.\n        if methods is None:\n            methods = getattr(view_func, \"methods\", None) or (\"GET\",)\n        if isinstance(methods, str):\n            raise TypeError(\n                \"Allowed methods must be a list of strings, for\"\n                ' example: @app.route(..., methods=[\"POST\"])'\n            )\n        methods = {item.upper() for item in methods}\n\n        # Methods that should always be added\n        required_methods: set[str] = set(getattr(view_func, \"required_methods\", ()))\n\n        # starting with Flask 0.8 the view_func object can disable and\n        # force-enable the automatic options handling.\n        if provide_automatic_options is None:\n            provide_automatic_options = getattr(\n                view_func, \"provide_automatic_options\", None\n            )\n\n        if provide_automatic_options is None:\n            if \"OPTIONS\" not in methods and self.config[\"PROVIDE_AUTOMATIC_OPTIONS\"]:\n                provide_automatic_options = True\n                required_methods.add(\"OPTIONS\")\n            else:\n                provide_automatic_options = False\n\n        # Add the required methods now.\n        methods |= required_methods\n\n        rule_obj = self.url_rule_class(rule, methods=methods, **options)\n        rule_obj.provide_automatic_options = provide_automatic_options  # type: ignore[attr-defined]\n\n        self.url_map.add(rule_obj)\n        if view_func is not None:\n            old_func = self.view_functions.get(endpoint)\n            if old_func is not None and old_func != view_func:\n                raise AssertionError(\n                    \"View function mapping is overwriting an existing\"\n                    f\" endpoint function: {endpoint}\"\n                )\n            self.view_functions[endpoint] = view_func\n\n    @setupmethod\n    def template_filter(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_filter], T_template_filter]:\n        \"\"\"A decorator that is used to register custom template filter.\n        You can specify a name for the filter, otherwise the function\n        name will be used. Example::\n\n          @app.template_filter()\n          def reverse(s):\n              return s[::-1]\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_filter) -> T_template_filter:\n            self.add_template_filter(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_filter(\n        self, f: ft.TemplateFilterCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template filter.  Works exactly like the\n        :meth:`template_filter` decorator.\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.filters[name or f.__name__] = f\n\n    @setupmethod\n    def template_test(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_test], T_template_test]:\n        \"\"\"A decorator that is used to register custom template test.\n        You can specify a name for the test, otherwise the function\n        name will be used. Example::\n\n          @app.template_test()\n          def is_prime(n):\n              if n == 2:\n                  return True\n              for i in range(2, int(math.ceil(math.sqrt(n))) + 1):\n                  if n % i == 0:\n                      return False\n              return True\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the test, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_test) -> T_template_test:\n            self.add_template_test(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_test(\n        self, f: ft.TemplateTestCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template test.  Works exactly like the\n        :meth:`template_test` decorator.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the test, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.tests[name or f.__name__] = f\n\n    @setupmethod\n    def template_global(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_global], T_template_global]:\n        \"\"\"A decorator that is used to register a custom template global function.\n        You can specify a name for the global function, otherwise the function\n        name will be used. Example::\n\n            @app.template_global()\n            def double(n):\n                return 2 * n\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global function, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_global) -> T_template_global:\n            self.add_template_global(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_global(\n        self, f: ft.TemplateGlobalCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template global function. Works exactly like the\n        :meth:`template_global` decorator.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global function, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.globals[name or f.__name__] = f\n\n    @setupmethod\n    def teardown_appcontext(self, f: T_teardown) -> T_teardown:\n        \"\"\"Registers a function to be called when the application\n        context is popped. The application context is typically popped\n        after the request context for each request, at the end of CLI\n        commands, or after a manually pushed context ends.\n\n        .. code-block:: python\n\n            with app.app_context():\n                ...\n\n        When the ``with`` block exits (or ``ctx.pop()`` is called), the\n        teardown functions are called just before the app context is\n        made inactive. Since a request context typically also manages an\n        application context it would also be called when you pop a\n        request context.\n\n        When a teardown function was called because of an unhandled\n        exception it will be passed an error object. If an\n        :meth:`errorhandler` is registered, it will handle the exception\n        and the teardown will not receive it.\n\n        Teardown functions must avoid raising exceptions. If they\n        execute code that might fail they must surround that code with a\n        ``try``/``except`` block and log any errors.\n\n        The return values of teardown functions are ignored.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        self.teardown_appcontext_funcs.append(f)\n        return f\n\n    @setupmethod\n    def shell_context_processor(\n        self, f: T_shell_context_processor\n    ) -> T_shell_context_processor:\n        \"\"\"Registers a shell context processor function.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        self.shell_context_processors.append(f)\n        return f\n\n    def _find_error_handler(\n        self, e: Exception, blueprints: list[str]\n    ) -> ft.ErrorHandlerCallable | None:\n        \"\"\"Return a registered error handler for an exception in this order:\n        blueprint handler for a specific code, app handler for a specific code,\n        blueprint handler for an exception class, app handler for an exception\n        class, or ``None`` if a suitable handler is not found.\n        \"\"\"\n        exc_class, code = self._get_exc_class_and_code(type(e))\n        names = (*blueprints, None)\n\n        for c in (code, None) if code is not None else (None,):\n            for name in names:\n                handler_map = self.error_handler_spec[name][c]\n\n                if not handler_map:\n                    continue\n\n                for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls)\n\n                    if handler is not None:\n                        return handler\n        return None\n\n    def trap_http_exception(self, e: Exception) -> bool:\n        \"\"\"Checks if an HTTP exception should be trapped or not.  By default\n        this will return ``False`` for all exceptions except for a bad request\n        key error if ``TRAP_BAD_REQUEST_ERRORS`` is set to ``True``.  It\n        also returns ``True`` if ``TRAP_HTTP_EXCEPTIONS`` is set to ``True``.\n\n        This is called for all HTTP exceptions raised by a view function.\n        If it returns ``True`` for any exception the error handler for this\n        exception is not called and it shows up as regular exception in the\n        traceback.  This is helpful for debugging implicitly raised HTTP\n        exceptions.\n\n        .. versionchanged:: 1.0\n            Bad request errors are not trapped by default in debug mode.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if self.config[\"TRAP_HTTP_EXCEPTIONS\"]:\n            return True\n\n        trap_bad_request = self.config[\"TRAP_BAD_REQUEST_ERRORS\"]\n\n        # if unset, trap key errors in debug mode\n        if (\n            trap_bad_request is None\n            and self.debug\n            and isinstance(e, BadRequestKeyError)\n        ):\n            return True\n\n        if trap_bad_request:\n            return isinstance(e, BadRequest)\n\n        return False\n\n    def should_ignore_error(self, error: BaseException | None) -> bool:\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns ``True`` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False\n\n    def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        This is called by :func:`flask.redirect`, and can be called\n        directly as well.\n\n        :param location: The URL to redirect to.\n        :param code: The status code for the redirect.\n\n        .. versionadded:: 2.2\n            Moved from ``flask.redirect``, which calls this method.\n        \"\"\"\n        return _wz_redirect(\n            location,\n            code=code,\n            Response=self.response_class,  # type: ignore[arg-type]\n        )\n\n    def inject_url_defaults(self, endpoint: str, values: dict[str, t.Any]) -> None:\n        \"\"\"Injects the URL defaults for the given endpoint directly into\n        the values dictionary passed.  This is used internally and\n        automatically called on URL building.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        names: t.Iterable[str | None] = (None,)\n\n        # url_for may be called outside a request context, parse the\n        # passed endpoint instead of using request.blueprints.\n        if \".\" in endpoint:\n            names = chain(\n                names, reversed(_split_blueprint_path(endpoint.rpartition(\".\")[0]))\n            )\n\n        for name in names:\n            if name in self.url_default_functions:\n                for func in self.url_default_functions[name]:\n                    func(endpoint, values)\n\n    def handle_url_build_error(\n        self, error: BuildError, endpoint: str, values: dict[str, t.Any]\n    ) -> str:\n        \"\"\"Called by :meth:`.url_for` if a\n        :exc:`~werkzeug.routing.BuildError` was raised. If this returns\n        a value, it will be returned by ``url_for``, otherwise the error\n        will be re-raised.\n\n        Each function in :attr:`url_build_error_handlers` is called with\n        ``error``, ``endpoint`` and ``values``. If a function returns\n        ``None`` or raises a ``BuildError``, it is skipped. Otherwise,\n        its return value is returned by ``url_for``.\n\n        :param error: The active ``BuildError`` being handled.\n        :param endpoint: The endpoint being built.\n        :param values: The keyword arguments passed to ``url_for``.\n        \"\"\"\n        for handler in self.url_build_error_handlers:\n            try:\n                rv = handler(error, endpoint, values)\n            except BuildError as e:\n                # make error available outside except block\n                error = e\n            else:\n                if rv is not None:\n                    return rv\n\n        # Re-raise if called with an active exception, otherwise raise\n        # the passed in exception.\n        if error is sys.exc_info()[1]:\n            raise\n\n        raise error\n", 964], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/templating.py": ["from __future__ import annotations\n\nimport typing as t\n\nfrom jinja2 import BaseLoader\nfrom jinja2 import Environment as BaseEnvironment\nfrom jinja2 import Template\nfrom jinja2 import TemplateNotFound\n\nfrom .globals import _cv_app\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .helpers import stream_with_context\nfrom .signals import before_render_template\nfrom .signals import template_rendered\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .app import Flask\n    from .sansio.app import App\n    from .sansio.scaffold import Scaffold\n\n\ndef _default_template_ctx_processor() -> dict[str, t.Any]:\n    \"\"\"Default template context processor.  Injects `request`,\n    `session` and `g`.\n    \"\"\"\n    appctx = _cv_app.get(None)\n    reqctx = _cv_request.get(None)\n    rv: dict[str, t.Any] = {}\n    if appctx is not None:\n        rv[\"g\"] = appctx.g\n    if reqctx is not None:\n        rv[\"request\"] = reqctx.request\n        rv[\"session\"] = reqctx.session\n    return rv\n\n\nclass Environment(BaseEnvironment):\n    \"\"\"Works like a regular Jinja2 environment but has some additional\n    knowledge of how Flask's blueprint works so that it can prepend the\n    name of the blueprint to referenced templates if necessary.\n    \"\"\"\n\n    def __init__(self, app: App, **options: t.Any) -> None:\n        if \"loader\" not in options:\n            options[\"loader\"] = app.create_global_jinja_loader()\n        BaseEnvironment.__init__(self, **options)\n        self.app = app\n\n\nclass DispatchingJinjaLoader(BaseLoader):\n    \"\"\"A loader that looks for templates in the application and all\n    the blueprint folders.\n    \"\"\"\n\n    def __init__(self, app: App) -> None:\n        self.app = app\n\n    def get_source(\n        self, environment: BaseEnvironment, template: str\n    ) -> tuple[str, str | None, t.Callable[[], bool] | None]:\n        if self.app.config[\"EXPLAIN_TEMPLATE_LOADING\"]:\n            return self._get_source_explained(environment, template)\n        return self._get_source_fast(environment, template)\n\n    def _get_source_explained(\n        self, environment: BaseEnvironment, template: str\n    ) -> tuple[str, str | None, t.Callable[[], bool] | None]:\n        attempts = []\n        rv: tuple[str, str | None, t.Callable[[], bool] | None] | None\n        trv: None | (tuple[str, str | None, t.Callable[[], bool] | None]) = None\n\n        for srcobj, loader in self._iter_loaders(template):\n            try:\n                rv = loader.get_source(environment, template)\n                if trv is None:\n                    trv = rv\n            except TemplateNotFound:\n                rv = None\n            attempts.append((loader, srcobj, rv))\n\n        from .debughelpers import explain_template_loading_attempts\n\n        explain_template_loading_attempts(self.app, template, attempts)\n\n        if trv is not None:\n            return trv\n        raise TemplateNotFound(template)\n\n    def _get_source_fast(\n        self, environment: BaseEnvironment, template: str\n    ) -> tuple[str, str | None, t.Callable[[], bool] | None]:\n        for _srcobj, loader in self._iter_loaders(template):\n            try:\n                return loader.get_source(environment, template)\n            except TemplateNotFound:\n                continue\n        raise TemplateNotFound(template)\n\n    def _iter_loaders(self, template: str) -> t.Iterator[tuple[Scaffold, BaseLoader]]:\n        loader = self.app.jinja_loader\n        if loader is not None:\n            yield self.app, loader\n\n        for blueprint in self.app.iter_blueprints():\n            loader = blueprint.jinja_loader\n            if loader is not None:\n                yield blueprint, loader\n\n    def list_templates(self) -> list[str]:\n        result = set()\n        loader = self.app.jinja_loader\n        if loader is not None:\n            result.update(loader.list_templates())\n\n        for blueprint in self.app.iter_blueprints():\n            loader = blueprint.jinja_loader\n            if loader is not None:\n                for template in loader.list_templates():\n                    result.add(template)\n\n        return list(result)\n\n\ndef _render(app: Flask, template: Template, context: dict[str, t.Any]) -> str:\n    app.update_template_context(context)\n    before_render_template.send(\n        app, _async_wrapper=app.ensure_sync, template=template, context=context\n    )\n    rv = template.render(context)\n    template_rendered.send(\n        app, _async_wrapper=app.ensure_sync, template=template, context=context\n    )\n    return rv\n\n\ndef render_template(\n    template_name_or_list: str | Template | list[str | Template],\n    **context: t.Any,\n) -> str:\n    \"\"\"Render a template by name with the given context.\n\n    :param template_name_or_list: The name of the template to render. If\n        a list is given, the first name to exist will be rendered.\n    :param context: The variables to make available in the template.\n    \"\"\"\n    app = current_app._get_current_object()  # type: ignore[attr-defined]\n    template = app.jinja_env.get_or_select_template(template_name_or_list)\n    return _render(app, template, context)\n\n\ndef render_template_string(source: str, **context: t.Any) -> str:\n    \"\"\"Render a template from the given source string with the given\n    context.\n\n    :param source: The source code of the template to render.\n    :param context: The variables to make available in the template.\n    \"\"\"\n    app = current_app._get_current_object()  # type: ignore[attr-defined]\n    template = app.jinja_env.from_string(source)\n    return _render(app, template, context)\n\n\ndef _stream(\n    app: Flask, template: Template, context: dict[str, t.Any]\n) -> t.Iterator[str]:\n    app.update_template_context(context)\n    before_render_template.send(\n        app, _async_wrapper=app.ensure_sync, template=template, context=context\n    )\n\n    def generate() -> t.Iterator[str]:\n        yield from template.generate(context)\n        template_rendered.send(\n            app, _async_wrapper=app.ensure_sync, template=template, context=context\n        )\n\n    rv = generate()\n\n    # If a request context is active, keep it while generating.\n    if request:\n        rv = stream_with_context(rv)\n\n    return rv\n\n\ndef stream_template(\n    template_name_or_list: str | Template | list[str | Template],\n    **context: t.Any,\n) -> t.Iterator[str]:\n    \"\"\"Render a template by name with the given context as a stream.\n    This returns an iterator of strings, which can be used as a\n    streaming response from a view.\n\n    :param template_name_or_list: The name of the template to render. If\n        a list is given, the first name to exist will be rendered.\n    :param context: The variables to make available in the template.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    app = current_app._get_current_object()  # type: ignore[attr-defined]\n    template = app.jinja_env.get_or_select_template(template_name_or_list)\n    return _stream(app, template, context)\n\n\ndef stream_template_string(source: str, **context: t.Any) -> t.Iterator[str]:\n    \"\"\"Render a template from the given source string with the given\n    context as a stream. This returns an iterator of strings, which can\n    be used as a streaming response from a view.\n\n    :param source: The source code of the template to render.\n    :param context: The variables to make available in the template.\n\n    .. versionadded:: 2.2\n    \"\"\"\n    app = current_app._get_current_object()  # type: ignore[attr-defined]\n    template = app.jinja_env.from_string(source)\n    return _stream(app, template, context)\n", 219], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/utils.py": ["import enum\nimport json\nimport os\nimport re\nimport typing as t\nfrom collections import abc\nfrom collections import deque\nfrom random import choice\nfrom random import randrange\nfrom threading import Lock\nfrom types import CodeType\nfrom urllib.parse import quote_from_bytes\n\nimport markupsafe\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\nclass _MissingType:\n    def __repr__(self) -> str:\n        return \"missing\"\n\n    def __reduce__(self) -> str:\n        return \"missing\"\n\n\nmissing: t.Any = _MissingType()\n\"\"\"Special singleton representing missing values for the runtime.\"\"\"\n\ninternal_code: t.MutableSet[CodeType] = set()\n\nconcat = \"\".join\n\n\ndef pass_context(f: F) -> F:\n    \"\"\"Pass the :class:`~jinja2.runtime.Context` as the first argument\n    to the decorated function when called while rendering a template.\n\n    Can be used on functions, filters, and tests.\n\n    If only ``Context.eval_context`` is needed, use\n    :func:`pass_eval_context`. If only ``Context.environment`` is\n    needed, use :func:`pass_environment`.\n\n    .. versionadded:: 3.0.0\n        Replaces ``contextfunction`` and ``contextfilter``.\n    \"\"\"\n    f.jinja_pass_arg = _PassArg.context  # type: ignore\n    return f\n\n\ndef pass_eval_context(f: F) -> F:\n    \"\"\"Pass the :class:`~jinja2.nodes.EvalContext` as the first argument\n    to the decorated function when called while rendering a template.\n    See :ref:`eval-context`.\n\n    Can be used on functions, filters, and tests.\n\n    If only ``EvalContext.environment`` is needed, use\n    :func:`pass_environment`.\n\n    .. versionadded:: 3.0.0\n        Replaces ``evalcontextfunction`` and ``evalcontextfilter``.\n    \"\"\"\n    f.jinja_pass_arg = _PassArg.eval_context  # type: ignore\n    return f\n\n\ndef pass_environment(f: F) -> F:\n    \"\"\"Pass the :class:`~jinja2.Environment` as the first argument to\n    the decorated function when called while rendering a template.\n\n    Can be used on functions, filters, and tests.\n\n    .. versionadded:: 3.0.0\n        Replaces ``environmentfunction`` and ``environmentfilter``.\n    \"\"\"\n    f.jinja_pass_arg = _PassArg.environment  # type: ignore\n    return f\n\n\nclass _PassArg(enum.Enum):\n    context = enum.auto()\n    eval_context = enum.auto()\n    environment = enum.auto()\n\n    @classmethod\n    def from_obj(cls, obj: F) -> t.Optional[\"_PassArg\"]:\n        if hasattr(obj, \"jinja_pass_arg\"):\n            return obj.jinja_pass_arg  # type: ignore\n\n        return None\n\n\ndef internalcode(f: F) -> F:\n    \"\"\"Marks the function as internally used\"\"\"\n    internal_code.add(f.__code__)\n    return f\n\n\ndef is_undefined(obj: t.Any) -> bool:\n    \"\"\"Check if the object passed is undefined.  This does nothing more than\n    performing an instance check against :class:`Undefined` but looks nicer.\n    This can be used for custom filters or tests that want to react to\n    undefined variables.  For example a custom default filter can look like\n    this::\n\n        def default(var, default=''):\n            if is_undefined(var):\n                return default\n            return var\n    \"\"\"\n    from .runtime import Undefined\n\n    return isinstance(obj, Undefined)\n\n\ndef consume(iterable: t.Iterable[t.Any]) -> None:\n    \"\"\"Consumes an iterable without doing anything with it.\"\"\"\n    for _ in iterable:\n        pass\n\n\ndef clear_caches() -> None:\n    \"\"\"Jinja keeps internal caches for environments and lexers.  These are\n    used so that Jinja doesn't have to recreate environments and lexers all\n    the time.  Normally you don't have to care about that but if you are\n    measuring memory consumption you may want to clean the caches.\n    \"\"\"\n    from .environment import get_spontaneous_environment\n    from .lexer import _lexer_cache\n\n    get_spontaneous_environment.cache_clear()\n    _lexer_cache.clear()\n\n\ndef import_string(import_name: str, silent: bool = False) -> t.Any:\n    \"\"\"Imports an object based on a string.  This is useful if you want to\n    use import paths as endpoints or something similar.  An import path can\n    be specified either in dotted notation (``xml.sax.saxutils.escape``)\n    or with a colon as object delimiter (``xml.sax.saxutils:escape``).\n\n    If the `silent` is True the return value will be `None` if the import\n    fails.\n\n    :return: imported object\n    \"\"\"\n    try:\n        if \":\" in import_name:\n            module, obj = import_name.split(\":\", 1)\n        elif \".\" in import_name:\n            module, _, obj = import_name.rpartition(\".\")\n        else:\n            return __import__(import_name)\n        return getattr(__import__(module, None, None, [obj]), obj)\n    except (ImportError, AttributeError):\n        if not silent:\n            raise\n\n\ndef open_if_exists(filename: str, mode: str = \"rb\") -> t.Optional[t.IO[t.Any]]:\n    \"\"\"Returns a file descriptor for the filename if that file exists,\n    otherwise ``None``.\n    \"\"\"\n    if not os.path.isfile(filename):\n        return None\n\n    return open(filename, mode)\n\n\ndef object_type_repr(obj: t.Any) -> str:\n    \"\"\"Returns the name of the object's type.  For some recognized\n    singletons the name of the object is returned instead. (For\n    example for `None` and `Ellipsis`).\n    \"\"\"\n    if obj is None:\n        return \"None\"\n    elif obj is Ellipsis:\n        return \"Ellipsis\"\n\n    cls = type(obj)\n\n    if cls.__module__ == \"builtins\":\n        return f\"{cls.__name__} object\"\n\n    return f\"{cls.__module__}.{cls.__name__} object\"\n\n\ndef pformat(obj: t.Any) -> str:\n    \"\"\"Format an object using :func:`pprint.pformat`.\"\"\"\n    from pprint import pformat\n\n    return pformat(obj)\n\n\n_http_re = re.compile(\n    r\"\"\"\n    ^\n    (\n        (https?://|www\\.)  # scheme or www\n        (([\\w%-]+\\.)+)?  # subdomain\n        (\n            [a-z]{2,63}  # basic tld\n        |\n            xn--[\\w%]{2,59}  # idna tld\n        )\n    |\n        ([\\w%-]{2,63}\\.)+  # basic domain\n        (com|net|int|edu|gov|org|info|mil)  # basic tld\n    |\n        (https?://)  # scheme\n        (\n            (([\\d]{1,3})(\\.[\\d]{1,3}){3})  # IPv4\n        |\n            (\\[([\\da-f]{0,4}:){2}([\\da-f]{0,4}:?){1,6}])  # IPv6\n        )\n    )\n    (?::[\\d]{1,5})?  # port\n    (?:[/?#]\\S*)?  # path, query, and fragment\n    $\n    \"\"\",\n    re.IGNORECASE | re.VERBOSE,\n)\n_email_re = re.compile(r\"^\\S+@\\w[\\w.-]*\\.\\w+$\")\n\n\ndef urlize(\n    text: str,\n    trim_url_limit: t.Optional[int] = None,\n    rel: t.Optional[str] = None,\n    target: t.Optional[str] = None,\n    extra_schemes: t.Optional[t.Iterable[str]] = None,\n) -> str:\n    \"\"\"Convert URLs in text into clickable links.\n\n    This may not recognize links in some situations. Usually, a more\n    comprehensive formatter, such as a Markdown library, is a better\n    choice.\n\n    Works on ``http://``, ``https://``, ``www.``, ``mailto:``, and email\n    addresses. Links with trailing punctuation (periods, commas, closing\n    parentheses) and leading punctuation (opening parentheses) are\n    recognized excluding the punctuation. Email addresses that include\n    header fields are not recognized (for example,\n    ``mailto:address@example.com?cc=copy@example.com``).\n\n    :param text: Original text containing URLs to link.\n    :param trim_url_limit: Shorten displayed URL values to this length.\n    :param target: Add the ``target`` attribute to links.\n    :param rel: Add the ``rel`` attribute to links.\n    :param extra_schemes: Recognize URLs that start with these schemes\n        in addition to the default behavior.\n\n    .. versionchanged:: 3.0\n        The ``extra_schemes`` parameter was added.\n\n    .. versionchanged:: 3.0\n        Generate ``https://`` links for URLs without a scheme.\n\n    .. versionchanged:: 3.0\n        The parsing rules were updated. Recognize email addresses with\n        or without the ``mailto:`` scheme. Validate IP addresses. Ignore\n        parentheses and brackets in more cases.\n    \"\"\"\n    if trim_url_limit is not None:\n\n        def trim_url(x: str) -> str:\n            if len(x) > trim_url_limit:\n                return f\"{x[:trim_url_limit]}...\"\n\n            return x\n\n    else:\n\n        def trim_url(x: str) -> str:\n            return x\n\n    words = re.split(r\"(\\s+)\", str(markupsafe.escape(text)))\n    rel_attr = f' rel=\"{markupsafe.escape(rel)}\"' if rel else \"\"\n    target_attr = f' target=\"{markupsafe.escape(target)}\"' if target else \"\"\n\n    for i, word in enumerate(words):\n        head, middle, tail = \"\", word, \"\"\n        match = re.match(r\"^([(<]|&lt;)+\", middle)\n\n        if match:\n            head = match.group()\n            middle = middle[match.end() :]\n\n        # Unlike lead, which is anchored to the start of the string,\n        # need to check that the string ends with any of the characters\n        # before trying to match all of them, to avoid backtracking.\n        if middle.endswith((\")\", \">\", \".\", \",\", \"\\n\", \"&gt;\")):\n            match = re.search(r\"([)>.,\\n]|&gt;)+$\", middle)\n\n            if match:\n                tail = match.group()\n                middle = middle[: match.start()]\n\n        # Prefer balancing parentheses in URLs instead of ignoring a\n        # trailing character.\n        for start_char, end_char in (\"(\", \")\"), (\"<\", \">\"), (\"&lt;\", \"&gt;\"):\n            start_count = middle.count(start_char)\n\n            if start_count <= middle.count(end_char):\n                # Balanced, or lighter on the left\n                continue\n\n            # Move as many as possible from the tail to balance\n            for _ in range(min(start_count, tail.count(end_char))):\n                end_index = tail.index(end_char) + len(end_char)\n                # Move anything in the tail before the end char too\n                middle += tail[:end_index]\n                tail = tail[end_index:]\n\n        if _http_re.match(middle):\n            if middle.startswith(\"https://\") or middle.startswith(\"http://\"):\n                middle = (\n                    f'<a href=\"{middle}\"{rel_attr}{target_attr}>{trim_url(middle)}</a>'\n                )\n            else:\n                middle = (\n                    f'<a href=\"https://{middle}\"{rel_attr}{target_attr}>'\n                    f\"{trim_url(middle)}</a>\"\n                )\n\n        elif middle.startswith(\"mailto:\") and _email_re.match(middle[7:]):\n            middle = f'<a href=\"{middle}\">{middle[7:]}</a>'\n\n        elif (\n            \"@\" in middle\n            and not middle.startswith(\"www.\")\n            # ignore values like `@a@b`\n            and not middle.startswith(\"@\")\n            and \":\" not in middle\n            and _email_re.match(middle)\n        ):\n            middle = f'<a href=\"mailto:{middle}\">{middle}</a>'\n\n        elif extra_schemes is not None:\n            for scheme in extra_schemes:\n                if middle != scheme and middle.startswith(scheme):\n                    middle = f'<a href=\"{middle}\"{rel_attr}{target_attr}>{middle}</a>'\n\n        words[i] = f\"{head}{middle}{tail}\"\n\n    return \"\".join(words)\n\n\ndef generate_lorem_ipsum(\n    n: int = 5, html: bool = True, min: int = 20, max: int = 100\n) -> str:\n    \"\"\"Generate some lorem ipsum for the template.\"\"\"\n    from .constants import LOREM_IPSUM_WORDS\n\n    words = LOREM_IPSUM_WORDS.split()\n    result = []\n\n    for _ in range(n):\n        next_capitalized = True\n        last_comma = last_fullstop = 0\n        word = None\n        last = None\n        p = []\n\n        # each paragraph contains out of 20 to 100 words.\n        for idx, _ in enumerate(range(randrange(min, max))):\n            while True:\n                word = choice(words)\n                if word != last:\n                    last = word\n                    break\n            if next_capitalized:\n                word = word.capitalize()\n                next_capitalized = False\n            # add commas\n            if idx - randrange(3, 8) > last_comma:\n                last_comma = idx\n                last_fullstop += 2\n                word += \",\"\n            # add end of sentences\n            if idx - randrange(10, 20) > last_fullstop:\n                last_comma = last_fullstop = idx\n                word += \".\"\n                next_capitalized = True\n            p.append(word)\n\n        # ensure that the paragraph ends with a dot.\n        p_str = \" \".join(p)\n\n        if p_str.endswith(\",\"):\n            p_str = p_str[:-1] + \".\"\n        elif not p_str.endswith(\".\"):\n            p_str += \".\"\n\n        result.append(p_str)\n\n    if not html:\n        return \"\\n\\n\".join(result)\n    return markupsafe.Markup(\n        \"\\n\".join(f\"<p>{markupsafe.escape(x)}</p>\" for x in result)\n    )\n\n\ndef url_quote(obj: t.Any, charset: str = \"utf-8\", for_qs: bool = False) -> str:\n    \"\"\"Quote a string for use in a URL using the given charset.\n\n    :param obj: String or bytes to quote. Other types are converted to\n        string then encoded to bytes using the given charset.\n    :param charset: Encode text to bytes using this charset.\n    :param for_qs: Quote \"/\" and use \"+\" for spaces.\n    \"\"\"\n    if not isinstance(obj, bytes):\n        if not isinstance(obj, str):\n            obj = str(obj)\n\n        obj = obj.encode(charset)\n\n    safe = b\"\" if for_qs else b\"/\"\n    rv = quote_from_bytes(obj, safe)\n\n    if for_qs:\n        rv = rv.replace(\"%20\", \"+\")\n\n    return rv\n\n\n@abc.MutableMapping.register\nclass LRUCache:\n    \"\"\"A simple LRU Cache implementation.\"\"\"\n\n    # this is fast for small capacities (something below 1000) but doesn't\n    # scale.  But as long as it's only used as storage for templates this\n    # won't do any harm.\n\n    def __init__(self, capacity: int) -> None:\n        self.capacity = capacity\n        self._mapping: t.Dict[t.Any, t.Any] = {}\n        self._queue: te.Deque[t.Any] = deque()\n        self._postinit()\n\n    def _postinit(self) -> None:\n        # alias all queue methods for faster lookup\n        self._popleft = self._queue.popleft\n        self._pop = self._queue.pop\n        self._remove = self._queue.remove\n        self._wlock = Lock()\n        self._append = self._queue.append\n\n    def __getstate__(self) -> t.Mapping[str, t.Any]:\n        return {\n            \"capacity\": self.capacity,\n            \"_mapping\": self._mapping,\n            \"_queue\": self._queue,\n        }\n\n    def __setstate__(self, d: t.Mapping[str, t.Any]) -> None:\n        self.__dict__.update(d)\n        self._postinit()\n\n    def __getnewargs__(self) -> t.Tuple[t.Any, ...]:\n        return (self.capacity,)\n\n    def copy(self) -> \"te.Self\":\n        \"\"\"Return a shallow copy of the instance.\"\"\"\n        rv = self.__class__(self.capacity)\n        rv._mapping.update(self._mapping)\n        rv._queue.extend(self._queue)\n        return rv\n\n    def get(self, key: t.Any, default: t.Any = None) -> t.Any:\n        \"\"\"Return an item from the cache dict or `default`\"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def setdefault(self, key: t.Any, default: t.Any = None) -> t.Any:\n        \"\"\"Set `default` if the key is not in the cache otherwise\n        leave unchanged. Return the value of this key.\n        \"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n            return default\n\n    def clear(self) -> None:\n        \"\"\"Clear the cache.\"\"\"\n        with self._wlock:\n            self._mapping.clear()\n            self._queue.clear()\n\n    def __contains__(self, key: t.Any) -> bool:\n        \"\"\"Check if a key exists in this cache.\"\"\"\n        return key in self._mapping\n\n    def __len__(self) -> int:\n        \"\"\"Return the current size of the cache.\"\"\"\n        return len(self._mapping)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self._mapping!r}>\"\n\n    def __getitem__(self, key: t.Any) -> t.Any:\n        \"\"\"Get an item from the cache. Moves the item up so that it has the\n        highest priority then.\n\n        Raise a `KeyError` if it does not exist.\n        \"\"\"\n        with self._wlock:\n            rv = self._mapping[key]\n\n            if self._queue[-1] != key:\n                try:\n                    self._remove(key)\n                except ValueError:\n                    # if something removed the key from the container\n                    # when we read, ignore the ValueError that we would\n                    # get otherwise.\n                    pass\n\n                self._append(key)\n\n            return rv\n\n    def __setitem__(self, key: t.Any, value: t.Any) -> None:\n        \"\"\"Sets the value for an item. Moves the item up so that it\n        has the highest priority then.\n        \"\"\"\n        with self._wlock:\n            if key in self._mapping:\n                self._remove(key)\n            elif len(self._mapping) == self.capacity:\n                del self._mapping[self._popleft()]\n\n            self._append(key)\n            self._mapping[key] = value\n\n    def __delitem__(self, key: t.Any) -> None:\n        \"\"\"Remove an item from the cache dict.\n        Raise a `KeyError` if it does not exist.\n        \"\"\"\n        with self._wlock:\n            del self._mapping[key]\n\n            try:\n                self._remove(key)\n            except ValueError:\n                pass\n\n    def items(self) -> t.Iterable[t.Tuple[t.Any, t.Any]]:\n        \"\"\"Return a list of items.\"\"\"\n        result = [(key, self._mapping[key]) for key in list(self._queue)]\n        result.reverse()\n        return result\n\n    def values(self) -> t.Iterable[t.Any]:\n        \"\"\"Return a list of all values.\"\"\"\n        return [x[1] for x in self.items()]\n\n    def keys(self) -> t.Iterable[t.Any]:\n        \"\"\"Return a list of all keys ordered by most recent usage.\"\"\"\n        return list(self)\n\n    def __iter__(self) -> t.Iterator[t.Any]:\n        return reversed(tuple(self._queue))\n\n    def __reversed__(self) -> t.Iterator[t.Any]:\n        \"\"\"Iterate over the keys in the cache dict, oldest items\n        coming first.\n        \"\"\"\n        return iter(tuple(self._queue))\n\n    __copy__ = copy\n\n\ndef select_autoescape(\n    enabled_extensions: t.Collection[str] = (\"html\", \"htm\", \"xml\"),\n    disabled_extensions: t.Collection[str] = (),\n    default_for_string: bool = True,\n    default: bool = False,\n) -> t.Callable[[t.Optional[str]], bool]:\n    \"\"\"Intelligently sets the initial value of autoescaping based on the\n    filename of the template.  This is the recommended way to configure\n    autoescaping if you do not want to write a custom function yourself.\n\n    If you want to enable it for all templates created from strings or\n    for all templates with `.html` and `.xml` extensions::\n\n        from jinja2 import Environment, select_autoescape\n        env = Environment(autoescape=select_autoescape(\n            enabled_extensions=('html', 'xml'),\n            default_for_string=True,\n        ))\n\n    Example configuration to turn it on at all times except if the template\n    ends with `.txt`::\n\n        from jinja2 import Environment, select_autoescape\n        env = Environment(autoescape=select_autoescape(\n            disabled_extensions=('txt',),\n            default_for_string=True,\n            default=True,\n        ))\n\n    The `enabled_extensions` is an iterable of all the extensions that\n    autoescaping should be enabled for.  Likewise `disabled_extensions` is\n    a list of all templates it should be disabled for.  If a template is\n    loaded from a string then the default from `default_for_string` is used.\n    If nothing matches then the initial value of autoescaping is set to the\n    value of `default`.\n\n    For security reasons this function operates case insensitive.\n\n    .. versionadded:: 2.9\n    \"\"\"\n    enabled_patterns = tuple(f\".{x.lstrip('.').lower()}\" for x in enabled_extensions)\n    disabled_patterns = tuple(f\".{x.lstrip('.').lower()}\" for x in disabled_extensions)\n\n    def autoescape(template_name: t.Optional[str]) -> bool:\n        if template_name is None:\n            return default_for_string\n        template_name = template_name.lower()\n        if template_name.endswith(enabled_patterns):\n            return True\n        if template_name.endswith(disabled_patterns):\n            return False\n        return default\n\n    return autoescape\n\n\ndef htmlsafe_json_dumps(\n    obj: t.Any, dumps: t.Optional[t.Callable[..., str]] = None, **kwargs: t.Any\n) -> markupsafe.Markup:\n    \"\"\"Serialize an object to a string of JSON with :func:`json.dumps`,\n    then replace HTML-unsafe characters with Unicode escapes and mark\n    the result safe with :class:`~markupsafe.Markup`.\n\n    This is available in templates as the ``|tojson`` filter.\n\n    The following characters are escaped: ``<``, ``>``, ``&``, ``'``.\n\n    The returned string is safe to render in HTML documents and\n    ``<script>`` tags. The exception is in HTML attributes that are\n    double quoted; either use single quotes or the ``|forceescape``\n    filter.\n\n    :param obj: The object to serialize to JSON.\n    :param dumps: The ``dumps`` function to use. Defaults to\n        ``env.policies[\"json.dumps_function\"]``, which defaults to\n        :func:`json.dumps`.\n    :param kwargs: Extra arguments to pass to ``dumps``. Merged onto\n        ``env.policies[\"json.dumps_kwargs\"]``.\n\n    .. versionchanged:: 3.0\n        The ``dumper`` parameter is renamed to ``dumps``.\n\n    .. versionadded:: 2.9\n    \"\"\"\n    if dumps is None:\n        dumps = json.dumps\n\n    return markupsafe.Markup(\n        dumps(obj, **kwargs)\n        .replace(\"<\", \"\\\\u003c\")\n        .replace(\">\", \"\\\\u003e\")\n        .replace(\"&\", \"\\\\u0026\")\n        .replace(\"'\", \"\\\\u0027\")\n    )\n\n\nclass Cycler:\n    \"\"\"Cycle through values by yield them one at a time, then restarting\n    once the end is reached. Available as ``cycler`` in templates.\n\n    Similar to ``loop.cycle``, but can be used outside loops or across\n    multiple loops. For example, render a list of folders and files in a\n    list, alternating giving them \"odd\" and \"even\" classes.\n\n    .. code-block:: html+jinja\n\n        {% set row_class = cycler(\"odd\", \"even\") %}\n        <ul class=\"browser\">\n        {% for folder in folders %}\n          <li class=\"folder {{ row_class.next() }}\">{{ folder }}\n        {% endfor %}\n        {% for file in files %}\n          <li class=\"file {{ row_class.next() }}\">{{ file }}\n        {% endfor %}\n        </ul>\n\n    :param items: Each positional argument will be yielded in the order\n        given for each cycle.\n\n    .. versionadded:: 2.1\n    \"\"\"\n\n    def __init__(self, *items: t.Any) -> None:\n        if not items:\n            raise RuntimeError(\"at least one item has to be provided\")\n        self.items = items\n        self.pos = 0\n\n    def reset(self) -> None:\n        \"\"\"Resets the current item to the first item.\"\"\"\n        self.pos = 0\n\n    @property\n    def current(self) -> t.Any:\n        \"\"\"Return the current item. Equivalent to the item that will be\n        returned next time :meth:`next` is called.\n        \"\"\"\n        return self.items[self.pos]\n\n    def next(self) -> t.Any:\n        \"\"\"Return the current item, then advance :attr:`current` to the\n        next item.\n        \"\"\"\n        rv = self.current\n        self.pos = (self.pos + 1) % len(self.items)\n        return rv\n\n    __next__ = next\n\n\nclass Joiner:\n    \"\"\"A joining helper for templates.\"\"\"\n\n    def __init__(self, sep: str = \", \") -> None:\n        self.sep = sep\n        self.used = False\n\n    def __call__(self) -> str:\n        if not self.used:\n            self.used = True\n            return \"\"\n        return self.sep\n\n\nclass Namespace:\n    \"\"\"A namespace object that can hold arbitrary attributes.  It may be\n    initialized from a dictionary or with keyword arguments.\"\"\"\n\n    def __init__(*args: t.Any, **kwargs: t.Any) -> None:  # noqa: B902\n        self, args = args[0], args[1:]\n        self.__attrs = dict(*args, **kwargs)\n\n    def __getattribute__(self, name: str) -> t.Any:\n        # __class__ is needed for the awaitable check in async mode\n        if name in {\"_Namespace__attrs\", \"__class__\"}:\n            return object.__getattribute__(self, name)\n        try:\n            return self.__attrs[name]\n        except KeyError:\n            raise AttributeError(name) from None\n\n    def __setitem__(self, name: str, value: t.Any) -> None:\n        self.__attrs[name] = value\n\n    def __repr__(self) -> str:\n        return f\"<Namespace {self.__attrs!r}>\"\n", 766], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py": ["\"\"\"Classes for managing templates and their runtime and compile time\noptions.\n\"\"\"\n\nimport os\nimport typing\nimport typing as t\nimport weakref\nfrom collections import ChainMap\nfrom functools import lru_cache\nfrom functools import partial\nfrom functools import reduce\nfrom types import CodeType\n\nfrom markupsafe import Markup\n\nfrom . import nodes\nfrom .compiler import CodeGenerator\nfrom .compiler import generate\nfrom .defaults import BLOCK_END_STRING\nfrom .defaults import BLOCK_START_STRING\nfrom .defaults import COMMENT_END_STRING\nfrom .defaults import COMMENT_START_STRING\nfrom .defaults import DEFAULT_FILTERS  # type: ignore[attr-defined]\nfrom .defaults import DEFAULT_NAMESPACE\nfrom .defaults import DEFAULT_POLICIES\nfrom .defaults import DEFAULT_TESTS  # type: ignore[attr-defined]\nfrom .defaults import KEEP_TRAILING_NEWLINE\nfrom .defaults import LINE_COMMENT_PREFIX\nfrom .defaults import LINE_STATEMENT_PREFIX\nfrom .defaults import LSTRIP_BLOCKS\nfrom .defaults import NEWLINE_SEQUENCE\nfrom .defaults import TRIM_BLOCKS\nfrom .defaults import VARIABLE_END_STRING\nfrom .defaults import VARIABLE_START_STRING\nfrom .exceptions import TemplateNotFound\nfrom .exceptions import TemplateRuntimeError\nfrom .exceptions import TemplatesNotFound\nfrom .exceptions import TemplateSyntaxError\nfrom .exceptions import UndefinedError\nfrom .lexer import get_lexer\nfrom .lexer import Lexer\nfrom .lexer import TokenStream\nfrom .nodes import EvalContext\nfrom .parser import Parser\nfrom .runtime import Context\nfrom .runtime import new_context\nfrom .runtime import Undefined\nfrom .utils import _PassArg\nfrom .utils import concat\nfrom .utils import consume\nfrom .utils import import_string\nfrom .utils import internalcode\nfrom .utils import LRUCache\nfrom .utils import missing\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .bccache import BytecodeCache\n    from .ext import Extension\n    from .loaders import BaseLoader\n\n_env_bound = t.TypeVar(\"_env_bound\", bound=\"Environment\")\n\n\n# for direct template usage we have up to ten living environments\n@lru_cache(maxsize=10)\ndef get_spontaneous_environment(cls: t.Type[_env_bound], *args: t.Any) -> _env_bound:\n    \"\"\"Return a new spontaneous environment. A spontaneous environment\n    is used for templates created directly rather than through an\n    existing environment.\n\n    :param cls: Environment class to create.\n    :param args: Positional arguments passed to environment.\n    \"\"\"\n    env = cls(*args)\n    env.shared = True\n    return env\n\n\ndef create_cache(\n    size: int,\n) -> t.Optional[t.MutableMapping[t.Tuple[\"weakref.ref[t.Any]\", str], \"Template\"]]:\n    \"\"\"Return the cache class for the given size.\"\"\"\n    if size == 0:\n        return None\n\n    if size < 0:\n        return {}\n\n    return LRUCache(size)  # type: ignore\n\n\ndef copy_cache(\n    cache: t.Optional[t.MutableMapping[t.Any, t.Any]],\n) -> t.Optional[t.MutableMapping[t.Tuple[\"weakref.ref[t.Any]\", str], \"Template\"]]:\n    \"\"\"Create an empty copy of the given cache.\"\"\"\n    if cache is None:\n        return None\n\n    if type(cache) is dict:  # noqa E721\n        return {}\n\n    return LRUCache(cache.capacity)  # type: ignore\n\n\ndef load_extensions(\n    environment: \"Environment\",\n    extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]],\n) -> t.Dict[str, \"Extension\"]:\n    \"\"\"Load the extensions from the list and bind it to the environment.\n    Returns a dict of instantiated extensions.\n    \"\"\"\n    result = {}\n\n    for extension in extensions:\n        if isinstance(extension, str):\n            extension = t.cast(t.Type[\"Extension\"], import_string(extension))\n\n        result[extension.identifier] = extension(environment)\n\n    return result\n\n\ndef _environment_config_check(environment: _env_bound) -> _env_bound:\n    \"\"\"Perform a sanity check on the environment.\"\"\"\n    assert issubclass(\n        environment.undefined, Undefined\n    ), \"'undefined' must be a subclass of 'jinja2.Undefined'.\"\n    assert (\n        environment.block_start_string\n        != environment.variable_start_string\n        != environment.comment_start_string\n    ), \"block, variable and comment start strings must be different.\"\n    assert environment.newline_sequence in {\n        \"\\r\",\n        \"\\r\\n\",\n        \"\\n\",\n    }, \"'newline_sequence' must be one of '\\\\n', '\\\\r\\\\n', or '\\\\r'.\"\n    return environment\n\n\nclass Environment:\n    r\"\"\"The core component of Jinja is the `Environment`.  It contains\n    important shared variables like configuration, filters, tests,\n    globals and others.  Instances of this class may be modified if\n    they are not shared and if no template was loaded so far.\n    Modifications on environments after the first template was loaded\n    will lead to surprising effects and undefined behavior.\n\n    Here are the possible initialization parameters:\n\n        `block_start_string`\n            The string marking the beginning of a block.  Defaults to ``'{%'``.\n\n        `block_end_string`\n            The string marking the end of a block.  Defaults to ``'%}'``.\n\n        `variable_start_string`\n            The string marking the beginning of a print statement.\n            Defaults to ``'{{'``.\n\n        `variable_end_string`\n            The string marking the end of a print statement.  Defaults to\n            ``'}}'``.\n\n        `comment_start_string`\n            The string marking the beginning of a comment.  Defaults to ``'{#'``.\n\n        `comment_end_string`\n            The string marking the end of a comment.  Defaults to ``'#}'``.\n\n        `line_statement_prefix`\n            If given and a string, this will be used as prefix for line based\n            statements.  See also :ref:`line-statements`.\n\n        `line_comment_prefix`\n            If given and a string, this will be used as prefix for line based\n            comments.  See also :ref:`line-statements`.\n\n            .. versionadded:: 2.2\n\n        `trim_blocks`\n            If this is set to ``True`` the first newline after a block is\n            removed (block, not variable tag!).  Defaults to `False`.\n\n        `lstrip_blocks`\n            If this is set to ``True`` leading spaces and tabs are stripped\n            from the start of a line to a block.  Defaults to `False`.\n\n        `newline_sequence`\n            The sequence that starts a newline.  Must be one of ``'\\r'``,\n            ``'\\n'`` or ``'\\r\\n'``.  The default is ``'\\n'`` which is a\n            useful default for Linux and OS X systems as well as web\n            applications.\n\n        `keep_trailing_newline`\n            Preserve the trailing newline when rendering templates.\n            The default is ``False``, which causes a single newline,\n            if present, to be stripped from the end of the template.\n\n            .. versionadded:: 2.7\n\n        `extensions`\n            List of Jinja extensions to use.  This can either be import paths\n            as strings or extension classes.  For more information have a\n            look at :ref:`the extensions documentation <jinja-extensions>`.\n\n        `optimized`\n            should the optimizer be enabled?  Default is ``True``.\n\n        `undefined`\n            :class:`Undefined` or a subclass of it that is used to represent\n            undefined values in the template.\n\n        `finalize`\n            A callable that can be used to process the result of a variable\n            expression before it is output.  For example one can convert\n            ``None`` implicitly into an empty string here.\n\n        `autoescape`\n            If set to ``True`` the XML/HTML autoescaping feature is enabled by\n            default.  For more details about autoescaping see\n            :class:`~markupsafe.Markup`.  As of Jinja 2.4 this can also\n            be a callable that is passed the template name and has to\n            return ``True`` or ``False`` depending on autoescape should be\n            enabled by default.\n\n            .. versionchanged:: 2.4\n               `autoescape` can now be a function\n\n        `loader`\n            The template loader for this environment.\n\n        `cache_size`\n            The size of the cache.  Per default this is ``400`` which means\n            that if more than 400 templates are loaded the loader will clean\n            out the least recently used template.  If the cache size is set to\n            ``0`` templates are recompiled all the time, if the cache size is\n            ``-1`` the cache will not be cleaned.\n\n            .. versionchanged:: 2.8\n               The cache size was increased to 400 from a low 50.\n\n        `auto_reload`\n            Some loaders load templates from locations where the template\n            sources may change (ie: file system or database).  If\n            ``auto_reload`` is set to ``True`` (default) every time a template is\n            requested the loader checks if the source changed and if yes, it\n            will reload the template.  For higher performance it's possible to\n            disable that.\n\n        `bytecode_cache`\n            If set to a bytecode cache object, this object will provide a\n            cache for the internal Jinja bytecode so that templates don't\n            have to be parsed if they were not changed.\n\n            See :ref:`bytecode-cache` for more information.\n\n        `enable_async`\n            If set to true this enables async template execution which\n            allows using async functions and generators.\n    \"\"\"\n\n    #: if this environment is sandboxed.  Modifying this variable won't make\n    #: the environment sandboxed though.  For a real sandboxed environment\n    #: have a look at jinja2.sandbox.  This flag alone controls the code\n    #: generation by the compiler.\n    sandboxed = False\n\n    #: True if the environment is just an overlay\n    overlayed = False\n\n    #: the environment this environment is linked to if it is an overlay\n    linked_to: t.Optional[\"Environment\"] = None\n\n    #: shared environments have this set to `True`.  A shared environment\n    #: must not be modified\n    shared = False\n\n    #: the class that is used for code generation.  See\n    #: :class:`~jinja2.compiler.CodeGenerator` for more information.\n    code_generator_class: t.Type[\"CodeGenerator\"] = CodeGenerator\n\n    concat = \"\".join\n\n    #: the context class that is used for templates.  See\n    #: :class:`~jinja2.runtime.Context` for more information.\n    context_class: t.Type[Context] = Context\n\n    template_class: t.Type[\"Template\"]\n\n    def __init__(\n        self,\n        block_start_string: str = BLOCK_START_STRING,\n        block_end_string: str = BLOCK_END_STRING,\n        variable_start_string: str = VARIABLE_START_STRING,\n        variable_end_string: str = VARIABLE_END_STRING,\n        comment_start_string: str = COMMENT_START_STRING,\n        comment_end_string: str = COMMENT_END_STRING,\n        line_statement_prefix: t.Optional[str] = LINE_STATEMENT_PREFIX,\n        line_comment_prefix: t.Optional[str] = LINE_COMMENT_PREFIX,\n        trim_blocks: bool = TRIM_BLOCKS,\n        lstrip_blocks: bool = LSTRIP_BLOCKS,\n        newline_sequence: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = NEWLINE_SEQUENCE,\n        keep_trailing_newline: bool = KEEP_TRAILING_NEWLINE,\n        extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]] = (),\n        optimized: bool = True,\n        undefined: t.Type[Undefined] = Undefined,\n        finalize: t.Optional[t.Callable[..., t.Any]] = None,\n        autoescape: t.Union[bool, t.Callable[[t.Optional[str]], bool]] = False,\n        loader: t.Optional[\"BaseLoader\"] = None,\n        cache_size: int = 400,\n        auto_reload: bool = True,\n        bytecode_cache: t.Optional[\"BytecodeCache\"] = None,\n        enable_async: bool = False,\n    ):\n        # !!Important notice!!\n        #   The constructor accepts quite a few arguments that should be\n        #   passed by keyword rather than position.  However it's important to\n        #   not change the order of arguments because it's used at least\n        #   internally in those cases:\n        #       -   spontaneous environments (i18n extension and Template)\n        #       -   unittests\n        #   If parameter changes are required only add parameters at the end\n        #   and don't change the arguments (or the defaults!) of the arguments\n        #   existing already.\n\n        # lexer / parser information\n        self.block_start_string = block_start_string\n        self.block_end_string = block_end_string\n        self.variable_start_string = variable_start_string\n        self.variable_end_string = variable_end_string\n        self.comment_start_string = comment_start_string\n        self.comment_end_string = comment_end_string\n        self.line_statement_prefix = line_statement_prefix\n        self.line_comment_prefix = line_comment_prefix\n        self.trim_blocks = trim_blocks\n        self.lstrip_blocks = lstrip_blocks\n        self.newline_sequence = newline_sequence\n        self.keep_trailing_newline = keep_trailing_newline\n\n        # runtime information\n        self.undefined: t.Type[Undefined] = undefined\n        self.optimized = optimized\n        self.finalize = finalize\n        self.autoescape = autoescape\n\n        # defaults\n        self.filters = DEFAULT_FILTERS.copy()\n        self.tests = DEFAULT_TESTS.copy()\n        self.globals = DEFAULT_NAMESPACE.copy()\n\n        # set the loader provided\n        self.loader = loader\n        self.cache = create_cache(cache_size)\n        self.bytecode_cache = bytecode_cache\n        self.auto_reload = auto_reload\n\n        # configurable policies\n        self.policies = DEFAULT_POLICIES.copy()\n\n        # load extensions\n        self.extensions = load_extensions(self, extensions)\n\n        self.is_async = enable_async\n        _environment_config_check(self)\n\n    def add_extension(self, extension: t.Union[str, t.Type[\"Extension\"]]) -> None:\n        \"\"\"Adds an extension after the environment was created.\n\n        .. versionadded:: 2.5\n        \"\"\"\n        self.extensions.update(load_extensions(self, [extension]))\n\n    def extend(self, **attributes: t.Any) -> None:\n        \"\"\"Add the items to the instance of the environment if they do not exist\n        yet.  This is used by :ref:`extensions <writing-extensions>` to register\n        callbacks and configuration values without breaking inheritance.\n        \"\"\"\n        for key, value in attributes.items():\n            if not hasattr(self, key):\n                setattr(self, key, value)\n\n    def overlay(\n        self,\n        block_start_string: str = missing,\n        block_end_string: str = missing,\n        variable_start_string: str = missing,\n        variable_end_string: str = missing,\n        comment_start_string: str = missing,\n        comment_end_string: str = missing,\n        line_statement_prefix: t.Optional[str] = missing,\n        line_comment_prefix: t.Optional[str] = missing,\n        trim_blocks: bool = missing,\n        lstrip_blocks: bool = missing,\n        newline_sequence: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = missing,\n        keep_trailing_newline: bool = missing,\n        extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]] = missing,\n        optimized: bool = missing,\n        undefined: t.Type[Undefined] = missing,\n        finalize: t.Optional[t.Callable[..., t.Any]] = missing,\n        autoescape: t.Union[bool, t.Callable[[t.Optional[str]], bool]] = missing,\n        loader: t.Optional[\"BaseLoader\"] = missing,\n        cache_size: int = missing,\n        auto_reload: bool = missing,\n        bytecode_cache: t.Optional[\"BytecodeCache\"] = missing,\n        enable_async: bool = missing,\n    ) -> \"te.Self\":\n        \"\"\"Create a new overlay environment that shares all the data with the\n        current environment except for cache and the overridden attributes.\n        Extensions cannot be removed for an overlayed environment.  An overlayed\n        environment automatically gets all the extensions of the environment it\n        is linked to plus optional extra extensions.\n\n        Creating overlays should happen after the initial environment was set\n        up completely.  Not all attributes are truly linked, some are just\n        copied over so modifications on the original environment may not shine\n        through.\n\n        .. versionchanged:: 3.1.5\n            ``enable_async`` is applied correctly.\n\n        .. versionchanged:: 3.1.2\n            Added the ``newline_sequence``, ``keep_trailing_newline``,\n            and ``enable_async`` parameters to match ``__init__``.\n        \"\"\"\n        args = dict(locals())\n        del args[\"self\"], args[\"cache_size\"], args[\"extensions\"], args[\"enable_async\"]\n\n        rv = object.__new__(self.__class__)\n        rv.__dict__.update(self.__dict__)\n        rv.overlayed = True\n        rv.linked_to = self\n\n        for key, value in args.items():\n            if value is not missing:\n                setattr(rv, key, value)\n\n        if cache_size is not missing:\n            rv.cache = create_cache(cache_size)\n        else:\n            rv.cache = copy_cache(self.cache)\n\n        rv.extensions = {}\n        for key, value in self.extensions.items():\n            rv.extensions[key] = value.bind(rv)\n        if extensions is not missing:\n            rv.extensions.update(load_extensions(rv, extensions))\n\n        if enable_async is not missing:\n            rv.is_async = enable_async\n\n        return _environment_config_check(rv)\n\n    @property\n    def lexer(self) -> Lexer:\n        \"\"\"The lexer for this environment.\"\"\"\n        return get_lexer(self)\n\n    def iter_extensions(self) -> t.Iterator[\"Extension\"]:\n        \"\"\"Iterates over the extensions by priority.\"\"\"\n        return iter(sorted(self.extensions.values(), key=lambda x: x.priority))\n\n    def getitem(\n        self, obj: t.Any, argument: t.Union[str, t.Any]\n    ) -> t.Union[t.Any, Undefined]:\n        \"\"\"Get an item or attribute of an object but prefer the item.\"\"\"\n        try:\n            return obj[argument]\n        except (AttributeError, TypeError, LookupError):\n            if isinstance(argument, str):\n                try:\n                    attr = str(argument)\n                except Exception:\n                    pass\n                else:\n                    try:\n                        return getattr(obj, attr)\n                    except AttributeError:\n                        pass\n            return self.undefined(obj=obj, name=argument)\n\n    def getattr(self, obj: t.Any, attribute: str) -> t.Any:\n        \"\"\"Get an item or attribute of an object but prefer the attribute.\n        Unlike :meth:`getitem` the attribute *must* be a string.\n        \"\"\"\n        try:\n            return getattr(obj, attribute)\n        except AttributeError:\n            pass\n        try:\n            return obj[attribute]\n        except (TypeError, LookupError, AttributeError):\n            return self.undefined(obj=obj, name=attribute)\n\n    def _filter_test_common(\n        self,\n        name: t.Union[str, Undefined],\n        value: t.Any,\n        args: t.Optional[t.Sequence[t.Any]],\n        kwargs: t.Optional[t.Mapping[str, t.Any]],\n        context: t.Optional[Context],\n        eval_ctx: t.Optional[EvalContext],\n        is_filter: bool,\n    ) -> t.Any:\n        if is_filter:\n            env_map = self.filters\n            type_name = \"filter\"\n        else:\n            env_map = self.tests\n            type_name = \"test\"\n\n        func = env_map.get(name)  # type: ignore\n\n        if func is None:\n            msg = f\"No {type_name} named {name!r}.\"\n\n            if isinstance(name, Undefined):\n                try:\n                    name._fail_with_undefined_error()\n                except Exception as e:\n                    msg = f\"{msg} ({e}; did you forget to quote the callable name?)\"\n\n            raise TemplateRuntimeError(msg)\n\n        args = [value, *(args if args is not None else ())]\n        kwargs = kwargs if kwargs is not None else {}\n        pass_arg = _PassArg.from_obj(func)\n\n        if pass_arg is _PassArg.context:\n            if context is None:\n                raise TemplateRuntimeError(\n                    f\"Attempted to invoke a context {type_name} without context.\"\n                )\n\n            args.insert(0, context)\n        elif pass_arg is _PassArg.eval_context:\n            if eval_ctx is None:\n                if context is not None:\n                    eval_ctx = context.eval_ctx\n                else:\n                    eval_ctx = EvalContext(self)\n\n            args.insert(0, eval_ctx)\n        elif pass_arg is _PassArg.environment:\n            args.insert(0, self)\n\n        return func(*args, **kwargs)\n\n    def call_filter(\n        self,\n        name: str,\n        value: t.Any,\n        args: t.Optional[t.Sequence[t.Any]] = None,\n        kwargs: t.Optional[t.Mapping[str, t.Any]] = None,\n        context: t.Optional[Context] = None,\n        eval_ctx: t.Optional[EvalContext] = None,\n    ) -> t.Any:\n        \"\"\"Invoke a filter on a value the same way the compiler does.\n\n        This might return a coroutine if the filter is running from an\n        environment in async mode and the filter supports async\n        execution. It's your responsibility to await this if needed.\n\n        .. versionadded:: 2.7\n        \"\"\"\n        return self._filter_test_common(\n            name, value, args, kwargs, context, eval_ctx, True\n        )\n\n    def call_test(\n        self,\n        name: str,\n        value: t.Any,\n        args: t.Optional[t.Sequence[t.Any]] = None,\n        kwargs: t.Optional[t.Mapping[str, t.Any]] = None,\n        context: t.Optional[Context] = None,\n        eval_ctx: t.Optional[EvalContext] = None,\n    ) -> t.Any:\n        \"\"\"Invoke a test on a value the same way the compiler does.\n\n        This might return a coroutine if the test is running from an\n        environment in async mode and the test supports async execution.\n        It's your responsibility to await this if needed.\n\n        .. versionchanged:: 3.0\n            Tests support ``@pass_context``, etc. decorators. Added\n            the ``context`` and ``eval_ctx`` parameters.\n\n        .. versionadded:: 2.7\n        \"\"\"\n        return self._filter_test_common(\n            name, value, args, kwargs, context, eval_ctx, False\n        )\n\n    @internalcode\n    def parse(\n        self,\n        source: str,\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n    ) -> nodes.Template:\n        \"\"\"Parse the sourcecode and return the abstract syntax tree.  This\n        tree of nodes is used by the compiler to convert the template into\n        executable source- or bytecode.  This is useful for debugging or to\n        extract information from templates.\n\n        If you are :ref:`developing Jinja extensions <writing-extensions>`\n        this gives you a good overview of the node tree generated.\n        \"\"\"\n        try:\n            return self._parse(source, name, filename)\n        except TemplateSyntaxError:\n            self.handle_exception(source=source)\n\n    def _parse(\n        self, source: str, name: t.Optional[str], filename: t.Optional[str]\n    ) -> nodes.Template:\n        \"\"\"Internal parsing function used by `parse` and `compile`.\"\"\"\n        return Parser(self, source, name, filename).parse()\n\n    def lex(\n        self,\n        source: str,\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n    ) -> t.Iterator[t.Tuple[int, str, str]]:\n        \"\"\"Lex the given sourcecode and return a generator that yields\n        tokens as tuples in the form ``(lineno, token_type, value)``.\n        This can be useful for :ref:`extension development <writing-extensions>`\n        and debugging templates.\n\n        This does not perform preprocessing.  If you want the preprocessing\n        of the extensions to be applied you have to filter source through\n        the :meth:`preprocess` method.\n        \"\"\"\n        source = str(source)\n        try:\n            return self.lexer.tokeniter(source, name, filename)\n        except TemplateSyntaxError:\n            self.handle_exception(source=source)\n\n    def preprocess(\n        self,\n        source: str,\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n    ) -> str:\n        \"\"\"Preprocesses the source with all extensions.  This is automatically\n        called for all parsing and compiling methods but *not* for :meth:`lex`\n        because there you usually only want the actual source tokenized.\n        \"\"\"\n        return reduce(\n            lambda s, e: e.preprocess(s, name, filename),\n            self.iter_extensions(),\n            str(source),\n        )\n\n    def _tokenize(\n        self,\n        source: str,\n        name: t.Optional[str],\n        filename: t.Optional[str] = None,\n        state: t.Optional[str] = None,\n    ) -> TokenStream:\n        \"\"\"Called by the parser to do the preprocessing and filtering\n        for all the extensions.  Returns a :class:`~jinja2.lexer.TokenStream`.\n        \"\"\"\n        source = self.preprocess(source, name, filename)\n        stream = self.lexer.tokenize(source, name, filename, state)\n\n        for ext in self.iter_extensions():\n            stream = ext.filter_stream(stream)  # type: ignore\n\n            if not isinstance(stream, TokenStream):\n                stream = TokenStream(stream, name, filename)\n\n        return stream\n\n    def _generate(\n        self,\n        source: nodes.Template,\n        name: t.Optional[str],\n        filename: t.Optional[str],\n        defer_init: bool = False,\n    ) -> str:\n        \"\"\"Internal hook that can be overridden to hook a different generate\n        method in.\n\n        .. versionadded:: 2.5\n        \"\"\"\n        return generate(  # type: ignore\n            source,\n            self,\n            name,\n            filename,\n            defer_init=defer_init,\n            optimized=self.optimized,\n        )\n\n    def _compile(self, source: str, filename: str) -> CodeType:\n        \"\"\"Internal hook that can be overridden to hook a different compile\n        method in.\n\n        .. versionadded:: 2.5\n        \"\"\"\n        return compile(source, filename, \"exec\")\n\n    @typing.overload\n    def compile(\n        self,\n        source: t.Union[str, nodes.Template],\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n        raw: \"te.Literal[False]\" = False,\n        defer_init: bool = False,\n    ) -> CodeType: ...\n\n    @typing.overload\n    def compile(\n        self,\n        source: t.Union[str, nodes.Template],\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n        raw: \"te.Literal[True]\" = ...,\n        defer_init: bool = False,\n    ) -> str: ...\n\n    @internalcode\n    def compile(\n        self,\n        source: t.Union[str, nodes.Template],\n        name: t.Optional[str] = None,\n        filename: t.Optional[str] = None,\n        raw: bool = False,\n        defer_init: bool = False,\n    ) -> t.Union[str, CodeType]:\n        \"\"\"Compile a node or template source code.  The `name` parameter is\n        the load name of the template after it was joined using\n        :meth:`join_path` if necessary, not the filename on the file system.\n        the `filename` parameter is the estimated filename of the template on\n        the file system.  If the template came from a database or memory this\n        can be omitted.\n\n        The return value of this method is a python code object.  If the `raw`\n        parameter is `True` the return value will be a string with python\n        code equivalent to the bytecode returned otherwise.  This method is\n        mainly used internally.\n\n        `defer_init` is use internally to aid the module code generator.  This\n        causes the generated code to be able to import without the global\n        environment variable to be set.\n\n        .. versionadded:: 2.4\n           `defer_init` parameter added.\n        \"\"\"\n        source_hint = None\n        try:\n            if isinstance(source, str):\n                source_hint = source\n                source = self._parse(source, name, filename)\n            source = self._generate(source, name, filename, defer_init=defer_init)\n            if raw:\n                return source\n            if filename is None:\n                filename = \"<template>\"\n            return self._compile(source, filename)\n        except TemplateSyntaxError:\n            self.handle_exception(source=source_hint)\n\n    def compile_expression(\n        self, source: str, undefined_to_none: bool = True\n    ) -> \"TemplateExpression\":\n        \"\"\"A handy helper method that returns a callable that accepts keyword\n        arguments that appear as variables in the expression.  If called it\n        returns the result of the expression.\n\n        This is useful if applications want to use the same rules as Jinja\n        in template \"configuration files\" or similar situations.\n\n        Example usage:\n\n        >>> env = Environment()\n        >>> expr = env.compile_expression('foo == 42')\n        >>> expr(foo=23)\n        False\n        >>> expr(foo=42)\n        True\n\n        Per default the return value is converted to `None` if the\n        expression returns an undefined value.  This can be changed\n        by setting `undefined_to_none` to `False`.\n\n        >>> env.compile_expression('var')() is None\n        True\n        >>> env.compile_expression('var', undefined_to_none=False)()\n        Undefined\n\n        .. versionadded:: 2.1\n        \"\"\"\n        parser = Parser(self, source, state=\"variable\")\n        try:\n            expr = parser.parse_expression()\n            if not parser.stream.eos:\n                raise TemplateSyntaxError(\n                    \"chunk after expression\", parser.stream.current.lineno, None, None\n                )\n            expr.set_environment(self)\n        except TemplateSyntaxError:\n            self.handle_exception(source=source)\n\n        body = [nodes.Assign(nodes.Name(\"result\", \"store\"), expr, lineno=1)]\n        template = self.from_string(nodes.Template(body, lineno=1))\n        return TemplateExpression(template, undefined_to_none)\n\n    def compile_templates(\n        self,\n        target: t.Union[str, \"os.PathLike[str]\"],\n        extensions: t.Optional[t.Collection[str]] = None,\n        filter_func: t.Optional[t.Callable[[str], bool]] = None,\n        zip: t.Optional[str] = \"deflated\",\n        log_function: t.Optional[t.Callable[[str], None]] = None,\n        ignore_errors: bool = True,\n    ) -> None:\n        \"\"\"Finds all the templates the loader can find, compiles them\n        and stores them in `target`.  If `zip` is `None`, instead of in a\n        zipfile, the templates will be stored in a directory.\n        By default a deflate zip algorithm is used. To switch to\n        the stored algorithm, `zip` can be set to ``'stored'``.\n\n        `extensions` and `filter_func` are passed to :meth:`list_templates`.\n        Each template returned will be compiled to the target folder or\n        zipfile.\n\n        By default template compilation errors are ignored.  In case a\n        log function is provided, errors are logged.  If you want template\n        syntax errors to abort the compilation you can set `ignore_errors`\n        to `False` and you will get an exception on syntax errors.\n\n        .. versionadded:: 2.4\n        \"\"\"\n        from .loaders import ModuleLoader\n\n        if log_function is None:\n\n            def log_function(x: str) -> None:\n                pass\n\n        assert log_function is not None\n        assert self.loader is not None, \"No loader configured.\"\n\n        def write_file(filename: str, data: str) -> None:\n            if zip:\n                info = ZipInfo(filename)\n                info.external_attr = 0o755 << 16\n                zip_file.writestr(info, data)\n            else:\n                with open(os.path.join(target, filename), \"wb\") as f:\n                    f.write(data.encode(\"utf8\"))\n\n        if zip is not None:\n            from zipfile import ZIP_DEFLATED\n            from zipfile import ZIP_STORED\n            from zipfile import ZipFile\n            from zipfile import ZipInfo\n\n            zip_file = ZipFile(\n                target, \"w\", dict(deflated=ZIP_DEFLATED, stored=ZIP_STORED)[zip]\n            )\n            log_function(f\"Compiling into Zip archive {target!r}\")\n        else:\n            if not os.path.isdir(target):\n                os.makedirs(target)\n            log_function(f\"Compiling into folder {target!r}\")\n\n        try:\n            for name in self.list_templates(extensions, filter_func):\n                source, filename, _ = self.loader.get_source(self, name)\n                try:\n                    code = self.compile(source, name, filename, True, True)\n                except TemplateSyntaxError as e:\n                    if not ignore_errors:\n                        raise\n                    log_function(f'Could not compile \"{name}\": {e}')\n                    continue\n\n                filename = ModuleLoader.get_module_filename(name)\n\n                write_file(filename, code)\n                log_function(f'Compiled \"{name}\" as {filename}')\n        finally:\n            if zip:\n                zip_file.close()\n\n        log_function(\"Finished compiling templates\")\n\n    def list_templates(\n        self,\n        extensions: t.Optional[t.Collection[str]] = None,\n        filter_func: t.Optional[t.Callable[[str], bool]] = None,\n    ) -> t.List[str]:\n        \"\"\"Returns a list of templates for this environment.  This requires\n        that the loader supports the loader's\n        :meth:`~BaseLoader.list_templates` method.\n\n        If there are other files in the template folder besides the\n        actual templates, the returned list can be filtered.  There are two\n        ways: either `extensions` is set to a list of file extensions for\n        templates, or a `filter_func` can be provided which is a callable that\n        is passed a template name and should return `True` if it should end up\n        in the result list.\n\n        If the loader does not support that, a :exc:`TypeError` is raised.\n\n        .. versionadded:: 2.4\n        \"\"\"\n        assert self.loader is not None, \"No loader configured.\"\n        names = self.loader.list_templates()\n\n        if extensions is not None:\n            if filter_func is not None:\n                raise TypeError(\n                    \"either extensions or filter_func can be passed, but not both\"\n                )\n\n            def filter_func(x: str) -> bool:\n                return \".\" in x and x.rsplit(\".\", 1)[1] in extensions\n\n        if filter_func is not None:\n            names = [name for name in names if filter_func(name)]\n\n        return names\n\n    def handle_exception(self, source: t.Optional[str] = None) -> \"te.NoReturn\":\n        \"\"\"Exception handling helper.  This is used internally to either raise\n        rewritten exceptions or return a rendered traceback for the template.\n        \"\"\"\n        from .debug import rewrite_traceback_stack\n\n        raise rewrite_traceback_stack(source=source)\n\n    def join_path(self, template: str, parent: str) -> str:\n        \"\"\"Join a template with the parent.  By default all the lookups are\n        relative to the loader root so this method returns the `template`\n        parameter unchanged, but if the paths should be relative to the\n        parent template, this function can be used to calculate the real\n        template name.\n\n        Subclasses may override this method and implement template path\n        joining here.\n        \"\"\"\n        return template\n\n    @internalcode\n    def _load_template(\n        self, name: str, globals: t.Optional[t.MutableMapping[str, t.Any]]\n    ) -> \"Template\":\n        if self.loader is None:\n            raise TypeError(\"no loader for this environment specified\")\n        cache_key = (weakref.ref(self.loader), name)\n        if self.cache is not None:\n            template = self.cache.get(cache_key)\n            if template is not None and (\n                not self.auto_reload or template.is_up_to_date\n            ):\n                # template.globals is a ChainMap, modifying it will only\n                # affect the template, not the environment globals.\n                if globals:\n                    template.globals.update(globals)\n\n                return template\n\n        template = self.loader.load(self, name, self.make_globals(globals))\n\n        if self.cache is not None:\n            self.cache[cache_key] = template\n        return template\n\n    @internalcode\n    def get_template(\n        self,\n        name: t.Union[str, \"Template\"],\n        parent: t.Optional[str] = None,\n        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n    ) -> \"Template\":\n        \"\"\"Load a template by name with :attr:`loader` and return a\n        :class:`Template`. If the template does not exist a\n        :exc:`TemplateNotFound` exception is raised.\n\n        :param name: Name of the template to load. When loading\n            templates from the filesystem, \"/\" is used as the path\n            separator, even on Windows.\n        :param parent: The name of the parent template importing this\n            template. :meth:`join_path` can be used to implement name\n            transformations with this.\n        :param globals: Extend the environment :attr:`globals` with\n            these extra variables available for all renders of this\n            template. If the template has already been loaded and\n            cached, its globals are updated with any new items.\n\n        .. versionchanged:: 3.0\n            If a template is loaded from cache, ``globals`` will update\n            the template's globals instead of ignoring the new values.\n\n        .. versionchanged:: 2.4\n            If ``name`` is a :class:`Template` object it is returned\n            unchanged.\n        \"\"\"\n        if isinstance(name, Template):\n            return name\n        if parent is not None:\n            name = self.join_path(name, parent)\n\n        return self._load_template(name, globals)\n\n    @internalcode\n    def select_template(\n        self,\n        names: t.Iterable[t.Union[str, \"Template\"]],\n        parent: t.Optional[str] = None,\n        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n    ) -> \"Template\":\n        \"\"\"Like :meth:`get_template`, but tries loading multiple names.\n        If none of the names can be loaded a :exc:`TemplatesNotFound`\n        exception is raised.\n\n        :param names: List of template names to try loading in order.\n        :param parent: The name of the parent template importing this\n            template. :meth:`join_path` can be used to implement name\n            transformations with this.\n        :param globals: Extend the environment :attr:`globals` with\n            these extra variables available for all renders of this\n            template. If the template has already been loaded and\n            cached, its globals are updated with any new items.\n\n        .. versionchanged:: 3.0\n            If a template is loaded from cache, ``globals`` will update\n            the template's globals instead of ignoring the new values.\n\n        .. versionchanged:: 2.11\n            If ``names`` is :class:`Undefined`, an :exc:`UndefinedError`\n            is raised instead. If no templates were found and ``names``\n            contains :class:`Undefined`, the message is more helpful.\n\n        .. versionchanged:: 2.4\n            If ``names`` contains a :class:`Template` object it is\n            returned unchanged.\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if isinstance(names, Undefined):\n            names._fail_with_undefined_error()\n\n        if not names:\n            raise TemplatesNotFound(\n                message=\"Tried to select from an empty list of templates.\"\n            )\n\n        for name in names:\n            if isinstance(name, Template):\n                return name\n            if parent is not None:\n                name = self.join_path(name, parent)\n            try:\n                return self._load_template(name, globals)\n            except (TemplateNotFound, UndefinedError):\n                pass\n        raise TemplatesNotFound(names)  # type: ignore\n\n    @internalcode\n    def get_or_select_template(\n        self,\n        template_name_or_list: t.Union[\n            str, \"Template\", t.List[t.Union[str, \"Template\"]]\n        ],\n        parent: t.Optional[str] = None,\n        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n    ) -> \"Template\":\n        \"\"\"Use :meth:`select_template` if an iterable of template names\n        is given, or :meth:`get_template` if one name is given.\n\n        .. versionadded:: 2.3\n        \"\"\"\n        if isinstance(template_name_or_list, (str, Undefined)):\n            return self.get_template(template_name_or_list, parent, globals)\n        elif isinstance(template_name_or_list, Template):\n            return template_name_or_list\n        return self.select_template(template_name_or_list, parent, globals)\n\n    def from_string(\n        self,\n        source: t.Union[str, nodes.Template],\n        globals: t.Optional[t.MutableMapping[str, t.Any]] = None,\n        template_class: t.Optional[t.Type[\"Template\"]] = None,\n    ) -> \"Template\":\n        \"\"\"Load a template from a source string without using\n        :attr:`loader`.\n\n        :param source: Jinja source to compile into a template.\n        :param globals: Extend the environment :attr:`globals` with\n            these extra variables available for all renders of this\n            template. If the template has already been loaded and\n            cached, its globals are updated with any new items.\n        :param template_class: Return an instance of this\n            :class:`Template` class.\n        \"\"\"\n        gs = self.make_globals(globals)\n        cls = template_class or self.template_class\n        return cls.from_code(self, self.compile(source), gs, None)\n\n    def make_globals(\n        self, d: t.Optional[t.MutableMapping[str, t.Any]]\n    ) -> t.MutableMapping[str, t.Any]:\n        \"\"\"Make the globals map for a template. Any given template\n        globals overlay the environment :attr:`globals`.\n\n        Returns a :class:`collections.ChainMap`. This allows any changes\n        to a template's globals to only affect that template, while\n        changes to the environment's globals are still reflected.\n        However, avoid modifying any globals after a template is loaded.\n\n        :param d: Dict of template-specific globals.\n\n        .. versionchanged:: 3.0\n            Use :class:`collections.ChainMap` to always prevent mutating\n            environment globals.\n        \"\"\"\n        if d is None:\n            d = {}\n\n        return ChainMap(d, self.globals)\n\n\nclass Template:\n    \"\"\"A compiled template that can be rendered.\n\n    Use the methods on :class:`Environment` to create or load templates.\n    The environment is used to configure how templates are compiled and\n    behave.\n\n    It is also possible to create a template object directly. This is\n    not usually recommended. The constructor takes most of the same\n    arguments as :class:`Environment`. All templates created with the\n    same environment arguments share the same ephemeral ``Environment``\n    instance behind the scenes.\n\n    A template object should be considered immutable. Modifications on\n    the object are not supported.\n    \"\"\"\n\n    #: Type of environment to create when creating a template directly\n    #: rather than through an existing environment.\n    environment_class: t.Type[Environment] = Environment\n\n    environment: Environment\n    globals: t.MutableMapping[str, t.Any]\n    name: t.Optional[str]\n    filename: t.Optional[str]\n    blocks: t.Dict[str, t.Callable[[Context], t.Iterator[str]]]\n    root_render_func: t.Callable[[Context], t.Iterator[str]]\n    _module: t.Optional[\"TemplateModule\"]\n    _debug_info: str\n    _uptodate: t.Optional[t.Callable[[], bool]]\n\n    def __new__(\n        cls,\n        source: t.Union[str, nodes.Template],\n        block_start_string: str = BLOCK_START_STRING,\n        block_end_string: str = BLOCK_END_STRING,\n        variable_start_string: str = VARIABLE_START_STRING,\n        variable_end_string: str = VARIABLE_END_STRING,\n        comment_start_string: str = COMMENT_START_STRING,\n        comment_end_string: str = COMMENT_END_STRING,\n        line_statement_prefix: t.Optional[str] = LINE_STATEMENT_PREFIX,\n        line_comment_prefix: t.Optional[str] = LINE_COMMENT_PREFIX,\n        trim_blocks: bool = TRIM_BLOCKS,\n        lstrip_blocks: bool = LSTRIP_BLOCKS,\n        newline_sequence: \"te.Literal['\\\\n', '\\\\r\\\\n', '\\\\r']\" = NEWLINE_SEQUENCE,\n        keep_trailing_newline: bool = KEEP_TRAILING_NEWLINE,\n        extensions: t.Sequence[t.Union[str, t.Type[\"Extension\"]]] = (),\n        optimized: bool = True,\n        undefined: t.Type[Undefined] = Undefined,\n        finalize: t.Optional[t.Callable[..., t.Any]] = None,\n        autoescape: t.Union[bool, t.Callable[[t.Optional[str]], bool]] = False,\n        enable_async: bool = False,\n    ) -> t.Any:  # it returns a `Template`, but this breaks the sphinx build...\n        env = get_spontaneous_environment(\n            cls.environment_class,  # type: ignore\n            block_start_string,\n            block_end_string,\n            variable_start_string,\n            variable_end_string,\n            comment_start_string,\n            comment_end_string,\n            line_statement_prefix,\n            line_comment_prefix,\n            trim_blocks,\n            lstrip_blocks,\n            newline_sequence,\n            keep_trailing_newline,\n            frozenset(extensions),\n            optimized,\n            undefined,  # type: ignore\n            finalize,\n            autoescape,\n            None,\n            0,\n            False,\n            None,\n            enable_async,\n        )\n        return env.from_string(source, template_class=cls)\n\n    @classmethod\n    def from_code(\n        cls,\n        environment: Environment,\n        code: CodeType,\n        globals: t.MutableMapping[str, t.Any],\n        uptodate: t.Optional[t.Callable[[], bool]] = None,\n    ) -> \"Template\":\n        \"\"\"Creates a template object from compiled code and the globals.  This\n        is used by the loaders and environment to create a template object.\n        \"\"\"\n        namespace = {\"environment\": environment, \"__file__\": code.co_filename}\n        exec(code, namespace)\n        rv = cls._from_namespace(environment, namespace, globals)\n        rv._uptodate = uptodate\n        return rv\n\n    @classmethod\n    def from_module_dict(\n        cls,\n        environment: Environment,\n        module_dict: t.MutableMapping[str, t.Any],\n        globals: t.MutableMapping[str, t.Any],\n    ) -> \"Template\":\n        \"\"\"Creates a template object from a module.  This is used by the\n        module loader to create a template object.\n\n        .. versionadded:: 2.4\n        \"\"\"\n        return cls._from_namespace(environment, module_dict, globals)\n\n    @classmethod\n    def _from_namespace(\n        cls,\n        environment: Environment,\n        namespace: t.MutableMapping[str, t.Any],\n        globals: t.MutableMapping[str, t.Any],\n    ) -> \"Template\":\n        t: Template = object.__new__(cls)\n        t.environment = environment\n        t.globals = globals\n        t.name = namespace[\"name\"]\n        t.filename = namespace[\"__file__\"]\n        t.blocks = namespace[\"blocks\"]\n\n        # render function and module\n        t.root_render_func = namespace[\"root\"]\n        t._module = None\n\n        # debug and loader helpers\n        t._debug_info = namespace[\"debug_info\"]\n        t._uptodate = None\n\n        # store the reference\n        namespace[\"environment\"] = environment\n        namespace[\"__jinja_template__\"] = t\n\n        return t\n\n    def render(self, *args: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"This method accepts the same arguments as the `dict` constructor:\n        A dict, a dict subclass or some keyword arguments.  If no arguments\n        are given the context will be empty.  These two calls do the same::\n\n            template.render(knights='that say nih')\n            template.render({'knights': 'that say nih'})\n\n        This will return the rendered template as a string.\n        \"\"\"\n        if self.environment.is_async:\n            import asyncio\n\n            return asyncio.run(self.render_async(*args, **kwargs))\n\n        ctx = self.new_context(dict(*args, **kwargs))\n\n        try:\n            return self.environment.concat(self.root_render_func(ctx))  # type: ignore\n        except Exception:\n            self.environment.handle_exception()\n\n    async def render_async(self, *args: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"This works similar to :meth:`render` but returns a coroutine\n        that when awaited returns the entire rendered template string.  This\n        requires the async feature to be enabled.\n\n        Example usage::\n\n            await template.render_async(knights='that say nih; asynchronously')\n        \"\"\"\n        if not self.environment.is_async:\n            raise RuntimeError(\n                \"The environment was not created with async mode enabled.\"\n            )\n\n        ctx = self.new_context(dict(*args, **kwargs))\n\n        try:\n            return self.environment.concat(  # type: ignore\n                [n async for n in self.root_render_func(ctx)]  # type: ignore\n            )\n        except Exception:\n            return self.environment.handle_exception()\n\n    def stream(self, *args: t.Any, **kwargs: t.Any) -> \"TemplateStream\":\n        \"\"\"Works exactly like :meth:`generate` but returns a\n        :class:`TemplateStream`.\n        \"\"\"\n        return TemplateStream(self.generate(*args, **kwargs))\n\n    def generate(self, *args: t.Any, **kwargs: t.Any) -> t.Iterator[str]:\n        \"\"\"For very large templates it can be useful to not render the whole\n        template at once but evaluate each statement after another and yield\n        piece for piece.  This method basically does exactly that and returns\n        a generator that yields one item after another as strings.\n\n        It accepts the same arguments as :meth:`render`.\n        \"\"\"\n        if self.environment.is_async:\n            import asyncio\n\n            async def to_list() -> t.List[str]:\n                return [x async for x in self.generate_async(*args, **kwargs)]\n\n            yield from asyncio.run(to_list())\n            return\n\n        ctx = self.new_context(dict(*args, **kwargs))\n\n        try:\n            yield from self.root_render_func(ctx)\n        except Exception:\n            yield self.environment.handle_exception()\n\n    async def generate_async(\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.AsyncGenerator[str, object]:\n        \"\"\"An async version of :meth:`generate`.  Works very similarly but\n        returns an async iterator instead.\n        \"\"\"\n        if not self.environment.is_async:\n            raise RuntimeError(\n                \"The environment was not created with async mode enabled.\"\n            )\n\n        ctx = self.new_context(dict(*args, **kwargs))\n\n        try:\n            agen = self.root_render_func(ctx)\n            try:\n                async for event in agen:  # type: ignore\n                    yield event\n            finally:\n                # we can't use async with aclosing(...) because that's only\n                # in 3.10+\n                await agen.aclose()  # type: ignore\n        except Exception:\n            yield self.environment.handle_exception()\n\n    def new_context(\n        self,\n        vars: t.Optional[t.Dict[str, t.Any]] = None,\n        shared: bool = False,\n        locals: t.Optional[t.Mapping[str, t.Any]] = None,\n    ) -> Context:\n        \"\"\"Create a new :class:`Context` for this template.  The vars\n        provided will be passed to the template.  Per default the globals\n        are added to the context.  If shared is set to `True` the data\n        is passed as is to the context without adding the globals.\n\n        `locals` can be a dict of local variables for internal usage.\n        \"\"\"\n        return new_context(\n            self.environment, self.name, self.blocks, vars, shared, self.globals, locals\n        )\n\n    def make_module(\n        self,\n        vars: t.Optional[t.Dict[str, t.Any]] = None,\n        shared: bool = False,\n        locals: t.Optional[t.Mapping[str, t.Any]] = None,\n    ) -> \"TemplateModule\":\n        \"\"\"This method works like the :attr:`module` attribute when called\n        without arguments but it will evaluate the template on every call\n        rather than caching it.  It's also possible to provide\n        a dict which is then used as context.  The arguments are the same\n        as for the :meth:`new_context` method.\n        \"\"\"\n        ctx = self.new_context(vars, shared, locals)\n        return TemplateModule(self, ctx)\n\n    async def make_module_async(\n        self,\n        vars: t.Optional[t.Dict[str, t.Any]] = None,\n        shared: bool = False,\n        locals: t.Optional[t.Mapping[str, t.Any]] = None,\n    ) -> \"TemplateModule\":\n        \"\"\"As template module creation can invoke template code for\n        asynchronous executions this method must be used instead of the\n        normal :meth:`make_module` one.  Likewise the module attribute\n        becomes unavailable in async mode.\n        \"\"\"\n        ctx = self.new_context(vars, shared, locals)\n        return TemplateModule(\n            self,\n            ctx,\n            [x async for x in self.root_render_func(ctx)],  # type: ignore\n        )\n\n    @internalcode\n    def _get_default_module(self, ctx: t.Optional[Context] = None) -> \"TemplateModule\":\n        \"\"\"If a context is passed in, this means that the template was\n        imported. Imported templates have access to the current\n        template's globals by default, but they can only be accessed via\n        the context during runtime.\n\n        If there are new globals, we need to create a new module because\n        the cached module is already rendered and will not have access\n        to globals from the current context. This new module is not\n        cached because the template can be imported elsewhere, and it\n        should have access to only the current template's globals.\n        \"\"\"\n        if self.environment.is_async:\n            raise RuntimeError(\"Module is not available in async mode.\")\n\n        if ctx is not None:\n            keys = ctx.globals_keys - self.globals.keys()\n\n            if keys:\n                return self.make_module({k: ctx.parent[k] for k in keys})\n\n        if self._module is None:\n            self._module = self.make_module()\n\n        return self._module\n\n    async def _get_default_module_async(\n        self, ctx: t.Optional[Context] = None\n    ) -> \"TemplateModule\":\n        if ctx is not None:\n            keys = ctx.globals_keys - self.globals.keys()\n\n            if keys:\n                return await self.make_module_async({k: ctx.parent[k] for k in keys})\n\n        if self._module is None:\n            self._module = await self.make_module_async()\n\n        return self._module\n\n    @property\n    def module(self) -> \"TemplateModule\":\n        \"\"\"The template as module.  This is used for imports in the\n        template runtime but is also useful if one wants to access\n        exported template variables from the Python layer:\n\n        >>> t = Template('{% macro foo() %}42{% endmacro %}23')\n        >>> str(t.module)\n        '23'\n        >>> t.module.foo() == u'42'\n        True\n\n        This attribute is not available if async mode is enabled.\n        \"\"\"\n        return self._get_default_module()\n\n    def get_corresponding_lineno(self, lineno: int) -> int:\n        \"\"\"Return the source line number of a line number in the\n        generated bytecode as they are not in sync.\n        \"\"\"\n        for template_line, code_line in reversed(self.debug_info):\n            if code_line <= lineno:\n                return template_line\n        return 1\n\n    @property\n    def is_up_to_date(self) -> bool:\n        \"\"\"If this variable is `False` there is a newer version available.\"\"\"\n        if self._uptodate is None:\n            return True\n        return self._uptodate()\n\n    @property\n    def debug_info(self) -> t.List[t.Tuple[int, int]]:\n        \"\"\"The debug info mapping.\"\"\"\n        if self._debug_info:\n            return [\n                tuple(map(int, x.split(\"=\")))  # type: ignore\n                for x in self._debug_info.split(\"&\")\n            ]\n\n        return []\n\n    def __repr__(self) -> str:\n        if self.name is None:\n            name = f\"memory:{id(self):x}\"\n        else:\n            name = repr(self.name)\n        return f\"<{type(self).__name__} {name}>\"\n\n\nclass TemplateModule:\n    \"\"\"Represents an imported template.  All the exported names of the\n    template are available as attributes on this object.  Additionally\n    converting it into a string renders the contents.\n    \"\"\"\n\n    def __init__(\n        self,\n        template: Template,\n        context: Context,\n        body_stream: t.Optional[t.Iterable[str]] = None,\n    ) -> None:\n        if body_stream is None:\n            if context.environment.is_async:\n                raise RuntimeError(\n                    \"Async mode requires a body stream to be passed to\"\n                    \" a template module. Use the async methods of the\"\n                    \" API you are using.\"\n                )\n\n            body_stream = list(template.root_render_func(context))\n\n        self._body_stream = body_stream\n        self.__dict__.update(context.get_exported())\n        self.__name__ = template.name\n\n    def __html__(self) -> Markup:\n        return Markup(concat(self._body_stream))\n\n    def __str__(self) -> str:\n        return concat(self._body_stream)\n\n    def __repr__(self) -> str:\n        if self.__name__ is None:\n            name = f\"memory:{id(self):x}\"\n        else:\n            name = repr(self.__name__)\n        return f\"<{type(self).__name__} {name}>\"\n\n\nclass TemplateExpression:\n    \"\"\"The :meth:`jinja2.Environment.compile_expression` method returns an\n    instance of this object.  It encapsulates the expression-like access\n    to the template with an expression it wraps.\n    \"\"\"\n\n    def __init__(self, template: Template, undefined_to_none: bool) -> None:\n        self._template = template\n        self._undefined_to_none = undefined_to_none\n\n    def __call__(self, *args: t.Any, **kwargs: t.Any) -> t.Optional[t.Any]:\n        context = self._template.new_context(dict(*args, **kwargs))\n        consume(self._template.root_render_func(context))\n        rv = context.vars[\"result\"]\n        if self._undefined_to_none and isinstance(rv, Undefined):\n            rv = None\n        return rv\n\n\nclass TemplateStream:\n    \"\"\"A template stream works pretty much like an ordinary python generator\n    but it can buffer multiple items to reduce the number of total iterations.\n    Per default the output is unbuffered which means that for every unbuffered\n    instruction in the template one string is yielded.\n\n    If buffering is enabled with a buffer size of 5, five items are combined\n    into a new string.  This is mainly useful if you are streaming\n    big templates to a client via WSGI which flushes after each iteration.\n    \"\"\"\n\n    def __init__(self, gen: t.Iterator[str]) -> None:\n        self._gen = gen\n        self.disable_buffering()\n\n    def dump(\n        self,\n        fp: t.Union[str, t.IO[bytes]],\n        encoding: t.Optional[str] = None,\n        errors: t.Optional[str] = \"strict\",\n    ) -> None:\n        \"\"\"Dump the complete stream into a file or file-like object.\n        Per default strings are written, if you want to encode\n        before writing specify an `encoding`.\n\n        Example usage::\n\n            Template('Hello {{ name }}!').stream(name='foo').dump('hello.html')\n        \"\"\"\n        close = False\n\n        if isinstance(fp, str):\n            if encoding is None:\n                encoding = \"utf-8\"\n\n            real_fp: t.IO[bytes] = open(fp, \"wb\")\n            close = True\n        else:\n            real_fp = fp\n\n        try:\n            if encoding is not None:\n                iterable = (x.encode(encoding, errors) for x in self)  # type: ignore\n            else:\n                iterable = self  # type: ignore\n\n            if hasattr(real_fp, \"writelines\"):\n                real_fp.writelines(iterable)\n            else:\n                for item in iterable:\n                    real_fp.write(item)\n        finally:\n            if close:\n                real_fp.close()\n\n    def disable_buffering(self) -> None:\n        \"\"\"Disable the output buffering.\"\"\"\n        self._next = partial(next, self._gen)\n        self.buffered = False\n\n    def _buffered_generator(self, size: int) -> t.Iterator[str]:\n        buf: t.List[str] = []\n        c_size = 0\n        push = buf.append\n\n        while True:\n            try:\n                while c_size < size:\n                    c = next(self._gen)\n                    push(c)\n                    if c:\n                        c_size += 1\n            except StopIteration:\n                if not c_size:\n                    return\n            yield concat(buf)\n            del buf[:]\n            c_size = 0\n\n    def enable_buffering(self, size: int = 5) -> None:\n        \"\"\"Enable buffering.  Buffer `size` items before yielding them.\"\"\"\n        if size <= 1:\n            raise ValueError(\"buffer size too small\")\n\n        self.buffered = True\n        self._next = partial(next, self._buffered_generator(size))\n\n    def __iter__(self) -> \"TemplateStream\":\n        return self\n\n    def __next__(self) -> str:\n        return self._next()  # type: ignore\n\n\n# hook in default template class.  if anyone reads this comment: ignore that\n# it's possible to use custom templates ;-)\nEnvironment.template_class = Template\n", 1672], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/app.py": ["from __future__ import annotations\n\nimport collections.abc as cabc\nimport os\nimport sys\nimport typing as t\nimport weakref\nfrom datetime import timedelta\nfrom inspect import iscoroutinefunction\nfrom itertools import chain\nfrom types import TracebackType\nfrom urllib.parse import quote as _url_quote\n\nimport click\nfrom werkzeug.datastructures import Headers\nfrom werkzeug.datastructures import ImmutableDict\nfrom werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.exceptions import InternalServerError\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import MapAdapter\nfrom werkzeug.routing import RequestRedirect\nfrom werkzeug.routing import RoutingException\nfrom werkzeug.routing import Rule\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.wrappers import Response as BaseResponse\nfrom werkzeug.wsgi import get_host\n\nfrom . import cli\nfrom . import typing as ft\nfrom .ctx import AppContext\nfrom .ctx import RequestContext\nfrom .globals import _cv_app\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import g\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .helpers import get_debug_flag\nfrom .helpers import get_flashed_messages\nfrom .helpers import get_load_dotenv\nfrom .helpers import send_from_directory\nfrom .sansio.app import App\nfrom .sansio.scaffold import _sentinel\nfrom .sessions import SecureCookieSessionInterface\nfrom .sessions import SessionInterface\nfrom .signals import appcontext_tearing_down\nfrom .signals import got_request_exception\nfrom .signals import request_finished\nfrom .signals import request_started\nfrom .signals import request_tearing_down\nfrom .templating import Environment\nfrom .wrappers import Request\nfrom .wrappers import Response\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .testing import FlaskClient\n    from .testing import FlaskCliRunner\n    from .typing import HeadersValue\n\nT_shell_context_processor = t.TypeVar(\n    \"T_shell_context_processor\", bound=ft.ShellContextProcessorCallable\n)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_filter = t.TypeVar(\"T_template_filter\", bound=ft.TemplateFilterCallable)\nT_template_global = t.TypeVar(\"T_template_global\", bound=ft.TemplateGlobalCallable)\nT_template_test = t.TypeVar(\"T_template_test\", bound=ft.TemplateTestCallable)\n\n\ndef _make_timedelta(value: timedelta | int | None) -> timedelta | None:\n    if value is None or isinstance(value, timedelta):\n        return value\n\n    return timedelta(seconds=value)\n\n\nclass Flask(App):\n    \"\"\"The flask object implements a WSGI application and acts as the central\n    object.  It is passed the name of the module or package of the\n    application.  Once it is created it will act as a central registry for\n    the view functions, the URL rules, template configuration and much more.\n\n    The name of the package is used to resolve resources from inside the\n    package or the folder the module is contained in depending on if the\n    package parameter resolves to an actual python package (a folder with\n    an :file:`__init__.py` file inside) or a standard module (just a ``.py`` file).\n\n    For more information about resource loading, see :func:`open_resource`.\n\n    Usually you create a :class:`Flask` instance in your main module or\n    in the :file:`__init__.py` file of your package like this::\n\n        from flask import Flask\n        app = Flask(__name__)\n\n    .. admonition:: About the First Parameter\n\n        The idea of the first parameter is to give Flask an idea of what\n        belongs to your application.  This name is used to find resources\n        on the filesystem, can be used by extensions to improve debugging\n        information and a lot more.\n\n        So it's important what you provide there.  If you are using a single\n        module, `__name__` is always the correct value.  If you however are\n        using a package, it's usually recommended to hardcode the name of\n        your package there.\n\n        For example if your application is defined in :file:`yourapplication/app.py`\n        you should create it with one of the two versions below::\n\n            app = Flask('yourapplication')\n            app = Flask(__name__.split('.')[0])\n\n        Why is that?  The application will work even with `__name__`, thanks\n        to how resources are looked up.  However it will make debugging more\n        painful.  Certain extensions can make assumptions based on the\n        import name of your application.  For example the Flask-SQLAlchemy\n        extension will look for the code in your application that triggered\n        an SQL query in debug mode.  If the import name is not properly set\n        up, that debugging information is lost.  (For example it would only\n        pick up SQL queries in `yourapplication.app` and not\n        `yourapplication.views.frontend`)\n\n    .. versionadded:: 0.7\n       The `static_url_path`, `static_folder`, and `template_folder`\n       parameters were added.\n\n    .. versionadded:: 0.8\n       The `instance_path` and `instance_relative_config` parameters were\n       added.\n\n    .. versionadded:: 0.11\n       The `root_path` parameter was added.\n\n    .. versionadded:: 1.0\n       The ``host_matching`` and ``static_host`` parameters were added.\n\n    .. versionadded:: 1.0\n       The ``subdomain_matching`` parameter was added. Subdomain\n       matching needs to be enabled manually now. Setting\n       :data:`SERVER_NAME` does not implicitly enable it.\n\n    :param import_name: the name of the application package\n    :param static_url_path: can be used to specify a different path for the\n                            static files on the web.  Defaults to the name\n                            of the `static_folder` folder.\n    :param static_folder: The folder with static files that is served at\n        ``static_url_path``. Relative to the application ``root_path``\n        or an absolute path. Defaults to ``'static'``.\n    :param static_host: the host to use when adding the static route.\n        Defaults to None. Required when using ``host_matching=True``\n        with a ``static_folder`` configured.\n    :param host_matching: set ``url_map.host_matching`` attribute.\n        Defaults to False.\n    :param subdomain_matching: consider the subdomain relative to\n        :data:`SERVER_NAME` when matching routes. Defaults to False.\n    :param template_folder: the folder that contains the templates that should\n                            be used by the application.  Defaults to\n                            ``'templates'`` folder in the root path of the\n                            application.\n    :param instance_path: An alternative instance path for the application.\n                          By default the folder ``'instance'`` next to the\n                          package or module is assumed to be the instance\n                          path.\n    :param instance_relative_config: if set to ``True`` relative filenames\n                                     for loading the config are assumed to\n                                     be relative to the instance path instead\n                                     of the application root.\n    :param root_path: The path to the root of the application files.\n        This should only be set manually when it can't be detected\n        automatically, such as for namespace packages.\n    \"\"\"\n\n    default_config = ImmutableDict(\n        {\n            \"DEBUG\": None,\n            \"TESTING\": False,\n            \"PROPAGATE_EXCEPTIONS\": None,\n            \"SECRET_KEY\": None,\n            \"SECRET_KEY_FALLBACKS\": None,\n            \"PERMANENT_SESSION_LIFETIME\": timedelta(days=31),\n            \"USE_X_SENDFILE\": False,\n            \"TRUSTED_HOSTS\": None,\n            \"SERVER_NAME\": None,\n            \"APPLICATION_ROOT\": \"/\",\n            \"SESSION_COOKIE_NAME\": \"session\",\n            \"SESSION_COOKIE_DOMAIN\": None,\n            \"SESSION_COOKIE_PATH\": None,\n            \"SESSION_COOKIE_HTTPONLY\": True,\n            \"SESSION_COOKIE_SECURE\": False,\n            \"SESSION_COOKIE_PARTITIONED\": False,\n            \"SESSION_COOKIE_SAMESITE\": None,\n            \"SESSION_REFRESH_EACH_REQUEST\": True,\n            \"MAX_CONTENT_LENGTH\": None,\n            \"MAX_FORM_MEMORY_SIZE\": 500_000,\n            \"MAX_FORM_PARTS\": 1_000,\n            \"SEND_FILE_MAX_AGE_DEFAULT\": None,\n            \"TRAP_BAD_REQUEST_ERRORS\": None,\n            \"TRAP_HTTP_EXCEPTIONS\": False,\n            \"EXPLAIN_TEMPLATE_LOADING\": False,\n            \"PREFERRED_URL_SCHEME\": \"http\",\n            \"TEMPLATES_AUTO_RELOAD\": None,\n            \"MAX_COOKIE_SIZE\": 4093,\n            \"PROVIDE_AUTOMATIC_OPTIONS\": True,\n        }\n    )\n\n    #: The class that is used for request objects.  See :class:`~flask.Request`\n    #: for more information.\n    request_class: type[Request] = Request\n\n    #: The class that is used for response objects.  See\n    #: :class:`~flask.Response` for more information.\n    response_class: type[Response] = Response\n\n    #: the session interface to use.  By default an instance of\n    #: :class:`~flask.sessions.SecureCookieSessionInterface` is used here.\n    #:\n    #: .. versionadded:: 0.8\n    session_interface: SessionInterface = SecureCookieSessionInterface()\n\n    def __init__(\n        self,\n        import_name: str,\n        static_url_path: str | None = None,\n        static_folder: str | os.PathLike[str] | None = \"static\",\n        static_host: str | None = None,\n        host_matching: bool = False,\n        subdomain_matching: bool = False,\n        template_folder: str | os.PathLike[str] | None = \"templates\",\n        instance_path: str | None = None,\n        instance_relative_config: bool = False,\n        root_path: str | None = None,\n    ):\n        super().__init__(\n            import_name=import_name,\n            static_url_path=static_url_path,\n            static_folder=static_folder,\n            static_host=static_host,\n            host_matching=host_matching,\n            subdomain_matching=subdomain_matching,\n            template_folder=template_folder,\n            instance_path=instance_path,\n            instance_relative_config=instance_relative_config,\n            root_path=root_path,\n        )\n\n        #: The Click command group for registering CLI commands for this\n        #: object. The commands are available from the ``flask`` command\n        #: once the application has been discovered and blueprints have\n        #: been registered.\n        self.cli = cli.AppGroup()\n\n        # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name\n\n        # Add a static route using the provided static_url_path, static_host,\n        # and static_folder if there is a configured static_folder.\n        # Note we do this without checking if static_folder exists.\n        # For one, it might be created while the server is running (e.g. during\n        # development). Also, Google App Engine stores static files somewhere\n        if self.has_static_folder:\n            assert bool(static_host) == host_matching, (\n                \"Invalid static_host/host_matching combination\"\n            )\n            # Use a weakref to avoid creating a reference cycle between the app\n            # and the view function (see #3761).\n            self_ref = weakref.ref(self)\n            self.add_url_rule(\n                f\"{self.static_url_path}/<path:filename>\",\n                endpoint=\"static\",\n                host=static_host,\n                view_func=lambda **kw: self_ref().send_static_file(**kw),  # type: ignore # noqa: B950\n            )\n\n    def get_send_file_max_age(self, filename: str | None) -> int | None:\n        \"\"\"Used by :func:`send_file` to determine the ``max_age`` cache\n        value for a given file path if it wasn't passed.\n\n        By default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\n        the configuration of :data:`~flask.current_app`. This defaults\n        to ``None``, which tells the browser to use conditional requests\n        instead of a timed cache, which is usually preferable.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionchanged:: 2.0\n            The default configuration is ``None`` instead of 12 hours.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        value = current_app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n\n        if value is None:\n            return None\n\n        if isinstance(value, timedelta):\n            return int(value.total_seconds())\n\n        return value  # type: ignore[no-any-return]\n\n    def send_static_file(self, filename: str) -> Response:\n        \"\"\"The view function used to serve files from\n        :attr:`static_folder`. A route is automatically registered for\n        this view at :attr:`static_url_path` if :attr:`static_folder` is\n        set.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionadded:: 0.5\n\n        \"\"\"\n        if not self.has_static_folder:\n            raise RuntimeError(\"'static_folder' must be set to serve static_files.\")\n\n        # send_file only knows to call get_send_file_max_age on the app,\n        # call it here so it works for blueprints too.\n        max_age = self.get_send_file_max_age(filename)\n        return send_from_directory(\n            t.cast(str, self.static_folder), filename, max_age=max_age\n        )\n\n    def open_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = None\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to :attr:`root_path` for reading.\n\n        For example, if the file ``schema.sql`` is next to the file\n        ``app.py`` where the ``Flask`` app is defined, it can be opened\n        with:\n\n        .. code-block:: python\n\n            with app.open_resource(\"schema.sql\") as f:\n                conn.executescript(f.read())\n\n        :param resource: Path to the resource relative to :attr:`root_path`.\n        :param mode: Open the file in this mode. Only reading is supported,\n            valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        if mode not in {\"r\", \"rt\", \"rb\"}:\n            raise ValueError(\"Resources can only be opened for reading.\")\n\n        path = os.path.join(self.root_path, resource)\n\n        if mode == \"rb\":\n            return open(path, mode)  # pyright: ignore\n\n        return open(path, mode, encoding=encoding)\n\n    def open_instance_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = \"utf-8\"\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to the application's instance folder\n        :attr:`instance_path`. Unlike :meth:`open_resource`, files in the\n        instance folder can be opened for writing.\n\n        :param resource: Path to the resource relative to :attr:`instance_path`.\n        :param mode: Open the file in this mode.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        path = os.path.join(self.instance_path, resource)\n\n        if \"b\" in mode:\n            return open(path, mode)\n\n        return open(path, mode, encoding=encoding)\n\n    def create_jinja_environment(self) -> Environment:\n        \"\"\"Create the Jinja environment based on :attr:`jinja_options`\n        and the various Jinja-related methods of the app. Changing\n        :attr:`jinja_options` after this will have no effect. Also adds\n        Flask-related globals and filters to the environment.\n\n        .. versionchanged:: 0.11\n           ``Environment.auto_reload`` set in accordance with\n           ``TEMPLATES_AUTO_RELOAD`` configuration option.\n\n        .. versionadded:: 0.5\n        \"\"\"\n        options = dict(self.jinja_options)\n\n        if \"autoescape\" not in options:\n            options[\"autoescape\"] = self.select_jinja_autoescape\n\n        if \"auto_reload\" not in options:\n            auto_reload = self.config[\"TEMPLATES_AUTO_RELOAD\"]\n\n            if auto_reload is None:\n                auto_reload = self.debug\n\n            options[\"auto_reload\"] = auto_reload\n\n        rv = self.jinja_environment(self, **options)\n        rv.globals.update(\n            url_for=self.url_for,\n            get_flashed_messages=get_flashed_messages,\n            config=self.config,\n            # request, session and g are normally added with the\n            # context processor for efficiency reasons but for imported\n            # templates we also want the proxies in there.\n            request=request,\n            session=session,\n            g=g,\n        )\n        rv.policies[\"json.dumps_function\"] = self.json.dumps\n        return rv\n\n    def create_url_adapter(self, request: Request | None) -> MapAdapter | None:\n        \"\"\"Creates a URL adapter for the given request. The URL adapter\n        is created at a point where the request context is not yet set\n        up so the request is passed explicitly.\n\n        .. versionchanged:: 3.1\n            If :data:`SERVER_NAME` is set, it does not restrict requests to\n            only that domain, for both ``subdomain_matching`` and\n            ``host_matching``.\n\n        .. versionchanged:: 1.0\n            :data:`SERVER_NAME` no longer implicitly enables subdomain\n            matching. Use :attr:`subdomain_matching` instead.\n\n        .. versionchanged:: 0.9\n           This can be called outside a request when the URL adapter is created\n           for an application context.\n\n        .. versionadded:: 0.6\n        \"\"\"\n        if request is not None:\n            if (trusted_hosts := self.config[\"TRUSTED_HOSTS\"]) is not None:\n                request.trusted_hosts = trusted_hosts\n\n            # Check trusted_hosts here until bind_to_environ does.\n            request.host = get_host(request.environ, request.trusted_hosts)  # pyright: ignore\n            subdomain = None\n            server_name = self.config[\"SERVER_NAME\"]\n\n            if self.url_map.host_matching:\n                # Don't pass SERVER_NAME, otherwise it's used and the actual\n                # host is ignored, which breaks host matching.\n                server_name = None\n            elif not self.subdomain_matching:\n                # Werkzeug doesn't implement subdomain matching yet. Until then,\n                # disable it by forcing the current subdomain to the default, or\n                # the empty string.\n                subdomain = self.url_map.default_subdomain or \"\"\n\n            return self.url_map.bind_to_environ(\n                request.environ, server_name=server_name, subdomain=subdomain\n            )\n\n        # Need at least SERVER_NAME to match/build outside a request.\n        if self.config[\"SERVER_NAME\"] is not None:\n            return self.url_map.bind(\n                self.config[\"SERVER_NAME\"],\n                script_name=self.config[\"APPLICATION_ROOT\"],\n                url_scheme=self.config[\"PREFERRED_URL_SCHEME\"],\n            )\n\n        return None\n\n    def raise_routing_exception(self, request: Request) -> t.NoReturn:\n        \"\"\"Intercept routing exceptions and possibly do something else.\n\n        In debug mode, intercept a routing redirect and replace it with\n        an error if the body will be discarded.\n\n        With modern Werkzeug this shouldn't occur, since it now uses a\n        308 status which tells the browser to resend the method and\n        body.\n\n        .. versionchanged:: 2.1\n            Don't intercept 307 and 308 redirects.\n\n        :meta private:\n        :internal:\n        \"\"\"\n        if (\n            not self.debug\n            or not isinstance(request.routing_exception, RequestRedirect)\n            or request.routing_exception.code in {307, 308}\n            or request.method in {\"GET\", \"HEAD\", \"OPTIONS\"}\n        ):\n            raise request.routing_exception  # type: ignore[misc]\n\n        from .debughelpers import FormDataRoutingRedirect\n\n        raise FormDataRoutingRedirect(request)\n\n    def update_template_context(self, context: dict[str, t.Any]) -> None:\n        \"\"\"Update the template context with some commonly used variables.\n        This injects request, session, config and g into the template\n        context as well as everything template context processors want\n        to inject.  Note that the as of Flask 0.6, the original values\n        in the context will not be overridden if a context processor\n        decides to return a value with the same key.\n\n        :param context: the context as a dictionary that is updated in place\n                        to add extra variables.\n        \"\"\"\n        names: t.Iterable[str | None] = (None,)\n\n        # A template may be rendered outside a request context.\n        if request:\n            names = chain(names, reversed(request.blueprints))\n\n        # The values passed to render_template take precedence. Keep a\n        # copy to re-apply after all context functions.\n        orig_ctx = context.copy()\n\n        for name in names:\n            if name in self.template_context_processors:\n                for func in self.template_context_processors[name]:\n                    context.update(self.ensure_sync(func)())\n\n        context.update(orig_ctx)\n\n    def make_shell_context(self) -> dict[str, t.Any]:\n        \"\"\"Returns the shell context for an interactive shell for this\n        application.  This runs all the registered shell context\n        processors.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        rv = {\"app\": self, \"g\": g}\n        for processor in self.shell_context_processors:\n            rv.update(processor())\n        return rv\n\n    def run(\n        self,\n        host: str | None = None,\n        port: int | None = None,\n        debug: bool | None = None,\n        load_dotenv: bool = True,\n        **options: t.Any,\n    ) -> None:\n        \"\"\"Runs the application on a local development server.\n\n        Do not use ``run()`` in a production setting. It is not intended to\n        meet security and performance requirements for a production server.\n        Instead, see :doc:`/deploying/index` for WSGI server recommendations.\n\n        If the :attr:`debug` flag is set the server will automatically reload\n        for code changes and show a debugger in case an exception happened.\n\n        If you want to run the application in debug mode, but disable the\n        code execution on the interactive debugger, you can pass\n        ``use_evalex=False`` as parameter.  This will keep the debugger's\n        traceback screen active, but disable code execution.\n\n        It is not recommended to use this function for development with\n        automatic reloading as this is badly supported.  Instead you should\n        be using the :command:`flask` command line script's ``run`` support.\n\n        .. admonition:: Keep in Mind\n\n           Flask will suppress any server error with a generic error page\n           unless it is in debug mode.  As such to enable just the\n           interactive debugger without the code reloading, you have to\n           invoke :meth:`run` with ``debug=True`` and ``use_reloader=False``.\n           Setting ``use_debugger`` to ``True`` without being in debug mode\n           won't catch any exceptions because there won't be any to\n           catch.\n\n        :param host: the hostname to listen on. Set this to ``'0.0.0.0'`` to\n            have the server available externally as well. Defaults to\n            ``'127.0.0.1'`` or the host in the ``SERVER_NAME`` config variable\n            if present.\n        :param port: the port of the webserver. Defaults to ``5000`` or the\n            port defined in the ``SERVER_NAME`` config variable if present.\n        :param debug: if given, enable or disable debug mode. See\n            :attr:`debug`.\n        :param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n            files to set environment variables. Will also change the working\n            directory to the directory containing the first file found.\n        :param options: the options to be forwarded to the underlying Werkzeug\n            server. See :func:`werkzeug.serving.run_simple` for more\n            information.\n\n        .. versionchanged:: 1.0\n            If installed, python-dotenv will be used to load environment\n            variables from :file:`.env` and :file:`.flaskenv` files.\n\n            The :envvar:`FLASK_DEBUG` environment variable will override :attr:`debug`.\n\n            Threaded mode is enabled by default.\n\n        .. versionchanged:: 0.10\n            The default port is now picked from the ``SERVER_NAME``\n            variable.\n        \"\"\"\n        # Ignore this call so that it doesn't start another server if\n        # the 'flask run' command is used.\n        if os.environ.get(\"FLASK_RUN_FROM_CLI\") == \"true\":\n            if not is_running_from_reloader():\n                click.secho(\n                    \" * Ignoring a call to 'app.run()' that would block\"\n                    \" the current 'flask' CLI command.\\n\"\n                    \"   Only call 'app.run()' in an 'if __name__ ==\"\n                    ' \"__main__\"\\' guard.',\n                    fg=\"red\",\n                )\n\n            return\n\n        if get_load_dotenv(load_dotenv):\n            cli.load_dotenv()\n\n            # if set, env var overrides existing value\n            if \"FLASK_DEBUG\" in os.environ:\n                self.debug = get_debug_flag()\n\n        # debug passed to method overrides all other sources\n        if debug is not None:\n            self.debug = bool(debug)\n\n        server_name = self.config.get(\"SERVER_NAME\")\n        sn_host = sn_port = None\n\n        if server_name:\n            sn_host, _, sn_port = server_name.partition(\":\")\n\n        if not host:\n            if sn_host:\n                host = sn_host\n            else:\n                host = \"127.0.0.1\"\n\n        if port or port == 0:\n            port = int(port)\n        elif sn_port:\n            port = int(sn_port)\n        else:\n            port = 5000\n\n        options.setdefault(\"use_reloader\", self.debug)\n        options.setdefault(\"use_debugger\", self.debug)\n        options.setdefault(\"threaded\", True)\n\n        cli.show_server_banner(self.debug, self.name)\n\n        from werkzeug.serving import run_simple\n\n        try:\n            run_simple(t.cast(str, host), port, self, **options)\n        finally:\n            # reset the first request information if the development server\n            # reset normally.  This makes it possible to restart the server\n            # without reloader and that stuff from an interactive shell.\n            self._got_first_request = False\n\n    def test_client(self, use_cookies: bool = True, **kwargs: t.Any) -> FlaskClient:\n        \"\"\"Creates a test client for this application.  For information\n        about unit testing head over to :doc:`/testing`.\n\n        Note that if you are testing for assertions or exceptions in your\n        application code, you must set ``app.testing = True`` in order for the\n        exceptions to propagate to the test client.  Otherwise, the exception\n        will be handled by the application (not visible to the test client) and\n        the only indication of an AssertionError or other exception will be a\n        500 status code response to the test client.  See the :attr:`testing`\n        attribute.  For example::\n\n            app.testing = True\n            client = app.test_client()\n\n        The test client can be used in a ``with`` block to defer the closing down\n        of the context until the end of the ``with`` block.  This is useful if\n        you want to access the context locals for testing::\n\n            with app.test_client() as c:\n                rv = c.get('/?vodka=42')\n                assert request.args['vodka'] == '42'\n\n        Additionally, you may pass optional keyword arguments that will then\n        be passed to the application's :attr:`test_client_class` constructor.\n        For example::\n\n            from flask.testing import FlaskClient\n\n            class CustomClient(FlaskClient):\n                def __init__(self, *args, **kwargs):\n                    self._authentication = kwargs.pop(\"authentication\")\n                    super(CustomClient,self).__init__( *args, **kwargs)\n\n            app.test_client_class = CustomClient\n            client = app.test_client(authentication='Basic ....')\n\n        See :class:`~flask.testing.FlaskClient` for more information.\n\n        .. versionchanged:: 0.4\n           added support for ``with`` block usage for the client.\n\n        .. versionadded:: 0.7\n           The `use_cookies` parameter was added as well as the ability\n           to override the client to be used by setting the\n           :attr:`test_client_class` attribute.\n\n        .. versionchanged:: 0.11\n           Added `**kwargs` to support passing additional keyword arguments to\n           the constructor of :attr:`test_client_class`.\n        \"\"\"\n        cls = self.test_client_class\n        if cls is None:\n            from .testing import FlaskClient as cls\n        return cls(  # type: ignore\n            self, self.response_class, use_cookies=use_cookies, **kwargs\n        )\n\n    def test_cli_runner(self, **kwargs: t.Any) -> FlaskCliRunner:\n        \"\"\"Create a CLI runner for testing CLI commands.\n        See :ref:`testing-cli`.\n\n        Returns an instance of :attr:`test_cli_runner_class`, by default\n        :class:`~flask.testing.FlaskCliRunner`. The Flask app object is\n        passed as the first argument.\n\n        .. versionadded:: 1.0\n        \"\"\"\n        cls = self.test_cli_runner_class\n\n        if cls is None:\n            from .testing import FlaskCliRunner as cls\n\n        return cls(self, **kwargs)  # type: ignore\n\n    def handle_http_exception(\n        self, e: HTTPException\n    ) -> HTTPException | ft.ResponseReturnValue:\n        \"\"\"Handles an HTTP exception.  By default this will invoke the\n        registered error handlers and fall back to returning the\n        exception as response.\n\n        .. versionchanged:: 1.0.3\n            ``RoutingException``, used internally for actions such as\n             slash redirects during routing, is not passed to error\n             handlers.\n\n        .. versionchanged:: 1.0\n            Exceptions are looked up by code *and* by MRO, so\n            ``HTTPException`` subclasses can be handled with a catch-all\n            handler for the base ``HTTPException``.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        # Proxy exceptions don't have error codes.  We want to always return\n        # those unchanged as errors\n        if e.code is None:\n            return e\n\n        # RoutingExceptions are used internally to trigger routing\n        # actions, such as slash redirects raising RequestRedirect. They\n        # are not raised or handled in user code.\n        if isinstance(e, RoutingException):\n            return e\n\n        handler = self._find_error_handler(e, request.blueprints)\n        if handler is None:\n            return e\n        return self.ensure_sync(handler)(e)  # type: ignore[no-any-return]\n\n    def handle_user_exception(\n        self, e: Exception\n    ) -> HTTPException | ft.ResponseReturnValue:\n        \"\"\"This method is called whenever an exception occurs that\n        should be handled. A special case is :class:`~werkzeug\n        .exceptions.HTTPException` which is forwarded to the\n        :meth:`handle_http_exception` method. This function will either\n        return a response value or reraise the exception with the same\n        traceback.\n\n        .. versionchanged:: 1.0\n            Key errors raised from request data like ``form`` show the\n            bad key in debug mode rather than a generic bad request\n            message.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        if isinstance(e, BadRequestKeyError) and (\n            self.debug or self.config[\"TRAP_BAD_REQUEST_ERRORS\"]\n        ):\n            e.show_exception = True\n\n        if isinstance(e, HTTPException) and not self.trap_http_exception(e):\n            return self.handle_http_exception(e)\n\n        handler = self._find_error_handler(e, request.blueprints)\n\n        if handler is None:\n            raise\n\n        return self.ensure_sync(handler)(e)  # type: ignore[no-any-return]\n\n    def handle_exception(self, e: Exception) -> Response:\n        \"\"\"Handle an exception that did not have an error handler\n        associated with it, or that was raised from an error handler.\n        This always causes a 500 ``InternalServerError``.\n\n        Always sends the :data:`got_request_exception` signal.\n\n        If :data:`PROPAGATE_EXCEPTIONS` is ``True``, such as in debug\n        mode, the error will be re-raised so that the debugger can\n        display it. Otherwise, the original exception is logged, and\n        an :exc:`~werkzeug.exceptions.InternalServerError` is returned.\n\n        If an error handler is registered for ``InternalServerError`` or\n        ``500``, it will be used. For consistency, the handler will\n        always receive the ``InternalServerError``. The original\n        unhandled exception is available as ``e.original_exception``.\n\n        .. versionchanged:: 1.1.0\n            Always passes the ``InternalServerError`` instance to the\n            handler, setting ``original_exception`` to the unhandled\n            error.\n\n        .. versionchanged:: 1.1.0\n            ``after_request`` functions and other finalization is done\n            even for the default 500 response when there is no handler.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        exc_info = sys.exc_info()\n        got_request_exception.send(self, _async_wrapper=self.ensure_sync, exception=e)\n        propagate = self.config[\"PROPAGATE_EXCEPTIONS\"]\n\n        if propagate is None:\n            propagate = self.testing or self.debug\n\n        if propagate:\n            # Re-raise if called with an active exception, otherwise\n            # raise the passed in exception.\n            if exc_info[1] is e:\n                raise\n\n            raise e\n\n        self.log_exception(exc_info)\n        server_error: InternalServerError | ft.ResponseReturnValue\n        server_error = InternalServerError(original_exception=e)\n        handler = self._find_error_handler(server_error, request.blueprints)\n\n        if handler is not None:\n            server_error = self.ensure_sync(handler)(server_error)\n\n        return self.finalize_request(server_error, from_error_handler=True)\n\n    def log_exception(\n        self,\n        exc_info: (tuple[type, BaseException, TracebackType] | tuple[None, None, None]),\n    ) -> None:\n        \"\"\"Logs an exception.  This is called by :meth:`handle_exception`\n        if debugging is disabled and right before the handler is called.\n        The default implementation logs the exception as error on the\n        :attr:`logger`.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        self.logger.error(\n            f\"Exception on {request.path} [{request.method}]\", exc_info=exc_info\n        )\n\n    def dispatch_request(self) -> ft.ResponseReturnValue:\n        \"\"\"Does the request dispatching.  Matches the URL and returns the\n        return value of the view or error handler.  This does not have to\n        be a response object.  In order to convert the return value to a\n        proper response object, call :func:`make_response`.\n\n        .. versionchanged:: 0.7\n           This no longer does the exception handling, this code was\n           moved to the new :meth:`full_dispatch_request`.\n        \"\"\"\n        req = request_ctx.request\n        if req.routing_exception is not None:\n            self.raise_routing_exception(req)\n        rule: Rule = req.url_rule  # type: ignore[assignment]\n        # if we provide automatic options for this URL and the\n        # request came with the OPTIONS method, reply automatically\n        if (\n            getattr(rule, \"provide_automatic_options\", False)\n            and req.method == \"OPTIONS\"\n        ):\n            return self.make_default_options_response()\n        # otherwise dispatch to the handler for that endpoint\n        view_args: dict[str, t.Any] = req.view_args  # type: ignore[assignment]\n        return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n\n    def full_dispatch_request(self) -> Response:\n        \"\"\"Dispatches the request and on top of that performs request\n        pre and postprocessing as well as HTTP exception catching and\n        error handling.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        self._got_first_request = True\n\n        try:\n            request_started.send(self, _async_wrapper=self.ensure_sync)\n            rv = self.preprocess_request()\n            if rv is None:\n                rv = self.dispatch_request()\n        except Exception as e:\n            rv = self.handle_user_exception(e)\n        return self.finalize_request(rv)\n\n    def finalize_request(\n        self,\n        rv: ft.ResponseReturnValue | HTTPException,\n        from_error_handler: bool = False,\n    ) -> Response:\n        \"\"\"Given the return value from a view function this finalizes\n        the request by converting it into a response and invoking the\n        postprocessing functions.  This is invoked for both normal\n        request dispatching as well as error handlers.\n\n        Because this means that it might be called as a result of a\n        failure a special safe mode is available which can be enabled\n        with the `from_error_handler` flag.  If enabled, failures in\n        response processing will be logged and otherwise ignored.\n\n        :internal:\n        \"\"\"\n        response = self.make_response(rv)\n        try:\n            response = self.process_response(response)\n            request_finished.send(\n                self, _async_wrapper=self.ensure_sync, response=response\n            )\n        except Exception:\n            if not from_error_handler:\n                raise\n            self.logger.exception(\n                \"Request finalizing failed with an error while handling an error\"\n            )\n        return response\n\n    def make_default_options_response(self) -> Response:\n        \"\"\"This method is called to create the default ``OPTIONS`` response.\n        This can be changed through subclassing to change the default\n        behavior of ``OPTIONS`` responses.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        adapter = request_ctx.url_adapter\n        methods = adapter.allowed_methods()  # type: ignore[union-attr]\n        rv = self.response_class()\n        rv.allow.update(methods)\n        return rv\n\n    def ensure_sync(self, func: t.Callable[..., t.Any]) -> t.Callable[..., t.Any]:\n        \"\"\"Ensure that the function is synchronous for WSGI workers.\n        Plain ``def`` functions are returned as-is. ``async def``\n        functions are wrapped to run and wait for the response.\n\n        Override this method to change how the app runs async views.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        if iscoroutinefunction(func):\n            return self.async_to_sync(func)\n\n        return func\n\n    def async_to_sync(\n        self, func: t.Callable[..., t.Coroutine[t.Any, t.Any, t.Any]]\n    ) -> t.Callable[..., t.Any]:\n        \"\"\"Return a sync function that will run the coroutine function.\n\n        .. code-block:: python\n\n            result = app.async_to_sync(func)(*args, **kwargs)\n\n        Override this method to change how the app converts async code\n        to be synchronously callable.\n\n        .. versionadded:: 2.0\n        \"\"\"\n        try:\n            from asgiref.sync import async_to_sync as asgiref_async_to_sync\n        except ImportError:\n            raise RuntimeError(\n                \"Install Flask with the 'async' extra in order to use async views.\"\n            ) from None\n\n        return asgiref_async_to_sync(func)\n\n    def url_for(\n        self,\n        /,\n        endpoint: str,\n        *,\n        _anchor: str | None = None,\n        _method: str | None = None,\n        _scheme: str | None = None,\n        _external: bool | None = None,\n        **values: t.Any,\n    ) -> str:\n        \"\"\"Generate a URL to the given endpoint with the given values.\n\n        This is called by :func:`flask.url_for`, and can be called\n        directly as well.\n\n        An *endpoint* is the name of a URL rule, usually added with\n        :meth:`@app.route() <route>`, and usually the same name as the\n        view function. A route defined in a :class:`~flask.Blueprint`\n        will prepend the blueprint's name separated by a ``.`` to the\n        endpoint.\n\n        In some cases, such as email messages, you want URLs to include\n        the scheme and domain, like ``https://example.com/hello``. When\n        not in an active request, URLs will be external by default, but\n        this requires setting :data:`SERVER_NAME` so Flask knows what\n        domain to use. :data:`APPLICATION_ROOT` and\n        :data:`PREFERRED_URL_SCHEME` should also be configured as\n        needed. This config is only used when not in an active request.\n\n        Functions can be decorated with :meth:`url_defaults` to modify\n        keyword arguments before the URL is built.\n\n        If building fails for some reason, such as an unknown endpoint\n        or incorrect values, the app's :meth:`handle_url_build_error`\n        method is called. If that returns a string, that is returned,\n        otherwise a :exc:`~werkzeug.routing.BuildError` is raised.\n\n        :param endpoint: The endpoint name associated with the URL to\n            generate. If this starts with a ``.``, the current blueprint\n            name (if any) will be used.\n        :param _anchor: If given, append this as ``#anchor`` to the URL.\n        :param _method: If given, generate the URL associated with this\n            method for the endpoint.\n        :param _scheme: If given, the URL will have this scheme if it\n            is external.\n        :param _external: If given, prefer the URL to be internal\n            (False) or require it to be external (True). External URLs\n            include the scheme and domain. When not in an active\n            request, URLs are external by default.\n        :param values: Values to use for the variable parts of the URL\n            rule. Unknown keys are appended as query string arguments,\n            like ``?a=b&c=d``.\n\n        .. versionadded:: 2.2\n            Moved from ``flask.url_for``, which calls this method.\n        \"\"\"\n        req_ctx = _cv_request.get(None)\n\n        if req_ctx is not None:\n            url_adapter = req_ctx.url_adapter\n            blueprint_name = req_ctx.request.blueprint\n\n            # If the endpoint starts with \".\" and the request matches a\n            # blueprint, the endpoint is relative to the blueprint.\n            if endpoint[:1] == \".\":\n                if blueprint_name is not None:\n                    endpoint = f\"{blueprint_name}{endpoint}\"\n                else:\n                    endpoint = endpoint[1:]\n\n            # When in a request, generate a URL without scheme and\n            # domain by default, unless a scheme is given.\n            if _external is None:\n                _external = _scheme is not None\n        else:\n            app_ctx = _cv_app.get(None)\n\n            # If called by helpers.url_for, an app context is active,\n            # use its url_adapter. Otherwise, app.url_for was called\n            # directly, build an adapter.\n            if app_ctx is not None:\n                url_adapter = app_ctx.url_adapter\n            else:\n                url_adapter = self.create_url_adapter(None)\n\n            if url_adapter is None:\n                raise RuntimeError(\n                    \"Unable to build URLs outside an active request\"\n                    \" without 'SERVER_NAME' configured. Also configure\"\n                    \" 'APPLICATION_ROOT' and 'PREFERRED_URL_SCHEME' as\"\n                    \" needed.\"\n                )\n\n            # When outside a request, generate a URL with scheme and\n            # domain by default.\n            if _external is None:\n                _external = True\n\n        # It is an error to set _scheme when _external=False, in order\n        # to avoid accidental insecure URLs.\n        if _scheme is not None and not _external:\n            raise ValueError(\"When specifying '_scheme', '_external' must be True.\")\n\n        self.inject_url_defaults(endpoint, values)\n\n        try:\n            rv = url_adapter.build(  # type: ignore[union-attr]\n                endpoint,\n                values,\n                method=_method,\n                url_scheme=_scheme,\n                force_external=_external,\n            )\n        except BuildError as error:\n            values.update(\n                _anchor=_anchor, _method=_method, _scheme=_scheme, _external=_external\n            )\n            return self.handle_url_build_error(error, endpoint, values)\n\n        if _anchor is not None:\n            _anchor = _url_quote(_anchor, safe=\"%!#$&'()*+,/:;=?@\")\n            rv = f\"{rv}#{_anchor}\"\n\n        return rv\n\n    def make_response(self, rv: ft.ResponseReturnValue) -> Response:\n        \"\"\"Convert the return value from a view function to an instance of\n        :attr:`response_class`.\n\n        :param rv: the return value from the view function. The view function\n            must return a response. Returning ``None``, or the view ending\n            without returning, is not allowed. The following types are allowed\n            for ``view_rv``:\n\n            ``str``\n                A response object is created with the string encoded to UTF-8\n                as the body.\n\n            ``bytes``\n                A response object is created with the bytes as the body.\n\n            ``dict``\n                A dictionary that will be jsonify'd before being returned.\n\n            ``list``\n                A list that will be jsonify'd before being returned.\n\n            ``generator`` or ``iterator``\n                A generator that returns ``str`` or ``bytes`` to be\n                streamed as the response.\n\n            ``tuple``\n                Either ``(body, status, headers)``, ``(body, status)``, or\n                ``(body, headers)``, where ``body`` is any of the other types\n                allowed here, ``status`` is a string or an integer, and\n                ``headers`` is a dictionary or a list of ``(key, value)``\n                tuples. If ``body`` is a :attr:`response_class` instance,\n                ``status`` overwrites the exiting value and ``headers`` are\n                extended.\n\n            :attr:`response_class`\n                The object is returned unchanged.\n\n            other :class:`~werkzeug.wrappers.Response` class\n                The object is coerced to :attr:`response_class`.\n\n            :func:`callable`\n                The function is called as a WSGI application. The result is\n                used to create a response object.\n\n        .. versionchanged:: 2.2\n            A generator will be converted to a streaming response.\n            A list will be converted to a JSON response.\n\n        .. versionchanged:: 1.1\n            A dict will be converted to a JSON response.\n\n        .. versionchanged:: 0.9\n           Previously a tuple was interpreted as the arguments for the\n           response object.\n        \"\"\"\n\n        status: int | None = None\n        headers: HeadersValue | None = None\n\n        # unpack tuple returns\n        if isinstance(rv, tuple):\n            len_rv = len(rv)\n\n            # a 3-tuple is unpacked directly\n            if len_rv == 3:\n                rv, status, headers = rv  # type: ignore[misc]\n            # decide if a 2-tuple has status or headers\n            elif len_rv == 2:\n                if isinstance(rv[1], (Headers, dict, tuple, list)):\n                    rv, headers = rv  # pyright: ignore\n                else:\n                    rv, status = rv  # type: ignore[assignment,misc]\n            # other sized tuples are not allowed\n            else:\n                raise TypeError(\n                    \"The view function did not return a valid response tuple.\"\n                    \" The tuple must have the form (body, status, headers),\"\n                    \" (body, status), or (body, headers).\"\n                )\n\n        # the body must not be None\n        if rv is None:\n            raise TypeError(\n                f\"The view function for {request.endpoint!r} did not\"\n                \" return a valid response. The function either returned\"\n                \" None or ended without a return statement.\"\n            )\n\n        # make sure the body is an instance of the response class\n        if not isinstance(rv, self.response_class):\n            if isinstance(rv, (str, bytes, bytearray)) or isinstance(rv, cabc.Iterator):\n                # let the response class set the status and headers instead of\n                # waiting to do it manually, so that the class can handle any\n                # special logic\n                rv = self.response_class(\n                    rv,  # pyright: ignore\n                    status=status,\n                    headers=headers,  # type: ignore[arg-type]\n                )\n                status = headers = None\n            elif isinstance(rv, (dict, list)):\n                rv = self.json.response(rv)\n            elif isinstance(rv, BaseResponse) or callable(rv):\n                # evaluate a WSGI callable, or coerce a different response\n                # class to the correct type\n                try:\n                    rv = self.response_class.force_type(\n                        rv,  # type: ignore[arg-type]\n                        request.environ,\n                    )\n                except TypeError as e:\n                    raise TypeError(\n                        f\"{e}\\nThe view function did not return a valid\"\n                        \" response. The return type must be a string,\"\n                        \" dict, list, tuple with headers or status,\"\n                        \" Response instance, or WSGI callable, but it\"\n                        f\" was a {type(rv).__name__}.\"\n                    ).with_traceback(sys.exc_info()[2]) from None\n            else:\n                raise TypeError(\n                    \"The view function did not return a valid\"\n                    \" response. The return type must be a string,\"\n                    \" dict, list, tuple with headers or status,\"\n                    \" Response instance, or WSGI callable, but it was a\"\n                    f\" {type(rv).__name__}.\"\n                )\n\n        rv = t.cast(Response, rv)\n        # prefer the status if it was provided\n        if status is not None:\n            if isinstance(status, (str, bytes, bytearray)):\n                rv.status = status\n            else:\n                rv.status_code = status\n\n        # extend existing headers with provided headers\n        if headers:\n            rv.headers.update(headers)\n\n        return rv\n\n    def preprocess_request(self) -> ft.ResponseReturnValue | None:\n        \"\"\"Called before the request is dispatched. Calls\n        :attr:`url_value_preprocessors` registered with the app and the\n        current blueprint (if any). Then calls :attr:`before_request_funcs`\n        registered with the app and the blueprint.\n\n        If any :meth:`before_request` handler returns a non-None value, the\n        value is handled as if it was the return value from the view, and\n        further request handling is stopped.\n        \"\"\"\n        names = (None, *reversed(request.blueprints))\n\n        for name in names:\n            if name in self.url_value_preprocessors:\n                for url_func in self.url_value_preprocessors[name]:\n                    url_func(request.endpoint, request.view_args)\n\n        for name in names:\n            if name in self.before_request_funcs:\n                for before_func in self.before_request_funcs[name]:\n                    rv = self.ensure_sync(before_func)()\n\n                    if rv is not None:\n                        return rv  # type: ignore[no-any-return]\n\n        return None\n\n    def process_response(self, response: Response) -> Response:\n        \"\"\"Can be overridden in order to modify the response object\n        before it's sent to the WSGI server.  By default this will\n        call all the :meth:`after_request` decorated functions.\n\n        .. versionchanged:: 0.5\n           As of Flask 0.5 the functions registered for after request\n           execution are called in reverse order of registration.\n\n        :param response: a :attr:`response_class` object.\n        :return: a new response object or the same, has to be an\n                 instance of :attr:`response_class`.\n        \"\"\"\n        ctx = request_ctx._get_current_object()  # type: ignore[attr-defined]\n\n        for func in ctx._after_request_functions:\n            response = self.ensure_sync(func)(response)\n\n        for name in chain(request.blueprints, (None,)):\n            if name in self.after_request_funcs:\n                for func in reversed(self.after_request_funcs[name]):\n                    response = self.ensure_sync(func)(response)\n\n        if not self.session_interface.is_null_session(ctx.session):\n            self.session_interface.save_session(self, ctx.session, response)\n\n        return response\n\n    def do_teardown_request(\n        self,\n        exc: BaseException | None = _sentinel,  # type: ignore[assignment]\n    ) -> None:\n        \"\"\"Called after the request is dispatched and the response is\n        returned, right before the request context is popped.\n\n        This calls all functions decorated with\n        :meth:`teardown_request`, and :meth:`Blueprint.teardown_request`\n        if a blueprint handled the request. Finally, the\n        :data:`request_tearing_down` signal is sent.\n\n        This is called by\n        :meth:`RequestContext.pop() <flask.ctx.RequestContext.pop>`,\n        which may be delayed during testing to maintain access to\n        resources.\n\n        :param exc: An unhandled exception raised while dispatching the\n            request. Detected from the current exception information if\n            not passed. Passed to each teardown function.\n\n        .. versionchanged:: 0.9\n            Added the ``exc`` argument.\n        \"\"\"\n        if exc is _sentinel:\n            exc = sys.exc_info()[1]\n\n        for name in chain(request.blueprints, (None,)):\n            if name in self.teardown_request_funcs:\n                for func in reversed(self.teardown_request_funcs[name]):\n                    self.ensure_sync(func)(exc)\n\n        request_tearing_down.send(self, _async_wrapper=self.ensure_sync, exc=exc)\n\n    def do_teardown_appcontext(\n        self,\n        exc: BaseException | None = _sentinel,  # type: ignore[assignment]\n    ) -> None:\n        \"\"\"Called right before the application context is popped.\n\n        When handling a request, the application context is popped\n        after the request context. See :meth:`do_teardown_request`.\n\n        This calls all functions decorated with\n        :meth:`teardown_appcontext`. Then the\n        :data:`appcontext_tearing_down` signal is sent.\n\n        This is called by\n        :meth:`AppContext.pop() <flask.ctx.AppContext.pop>`.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        if exc is _sentinel:\n            exc = sys.exc_info()[1]\n\n        for func in reversed(self.teardown_appcontext_funcs):\n            self.ensure_sync(func)(exc)\n\n        appcontext_tearing_down.send(self, _async_wrapper=self.ensure_sync, exc=exc)\n\n    def app_context(self) -> AppContext:\n        \"\"\"Create an :class:`~flask.ctx.AppContext`. Use as a ``with``\n        block to push the context, which will make :data:`current_app`\n        point at this application.\n\n        An application context is automatically pushed by\n        :meth:`RequestContext.push() <flask.ctx.RequestContext.push>`\n        when handling a request, and when running a CLI command. Use\n        this to manually create a context outside of these situations.\n\n        ::\n\n            with app.app_context():\n                init_db()\n\n        See :doc:`/appcontext`.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        return AppContext(self)\n\n    def request_context(self, environ: WSGIEnvironment) -> RequestContext:\n        \"\"\"Create a :class:`~flask.ctx.RequestContext` representing a\n        WSGI environment. Use a ``with`` block to push the context,\n        which will make :data:`request` point at this request.\n\n        See :doc:`/reqcontext`.\n\n        Typically you should not call this from your own code. A request\n        context is automatically pushed by the :meth:`wsgi_app` when\n        handling a request. Use :meth:`test_request_context` to create\n        an environment and context instead of this method.\n\n        :param environ: a WSGI environment\n        \"\"\"\n        return RequestContext(self, environ)\n\n    def test_request_context(self, *args: t.Any, **kwargs: t.Any) -> RequestContext:\n        \"\"\"Create a :class:`~flask.ctx.RequestContext` for a WSGI\n        environment created from the given values. This is mostly useful\n        during testing, where you may want to run a function that uses\n        request data without dispatching a full request.\n\n        See :doc:`/reqcontext`.\n\n        Use a ``with`` block to push the context, which will make\n        :data:`request` point at the request for the created\n        environment. ::\n\n            with app.test_request_context(...):\n                generate_report()\n\n        When using the shell, it may be easier to push and pop the\n        context manually to avoid indentation. ::\n\n            ctx = app.test_request_context(...)\n            ctx.push()\n            ...\n            ctx.pop()\n\n        Takes the same arguments as Werkzeug's\n        :class:`~werkzeug.test.EnvironBuilder`, with some defaults from\n        the application. See the linked Werkzeug docs for most of the\n        available arguments. Flask-specific behavior is listed here.\n\n        :param path: URL path being requested.\n        :param base_url: Base URL where the app is being served, which\n            ``path`` is relative to. If not given, built from\n            :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n            :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n        :param subdomain: Subdomain name to append to\n            :data:`SERVER_NAME`.\n        :param url_scheme: Scheme to use instead of\n            :data:`PREFERRED_URL_SCHEME`.\n        :param data: The request body, either as a string or a dict of\n            form keys and values.\n        :param json: If given, this is serialized as JSON and passed as\n            ``data``. Also defaults ``content_type`` to\n            ``application/json``.\n        :param args: other positional arguments passed to\n            :class:`~werkzeug.test.EnvironBuilder`.\n        :param kwargs: other keyword arguments passed to\n            :class:`~werkzeug.test.EnvironBuilder`.\n        \"\"\"\n        from .testing import EnvironBuilder\n\n        builder = EnvironBuilder(self, *args, **kwargs)\n\n        try:\n            return self.request_context(builder.get_environ())\n        finally:\n            builder.close()\n\n    def wsgi_app(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> cabc.Iterable[bytes]:\n        \"\"\"The actual WSGI application. This is not implemented in\n        :meth:`__call__` so that middlewares can be applied without\n        losing a reference to the app object. Instead of doing this::\n\n            app = MyMiddleware(app)\n\n        It's a better idea to do this instead::\n\n            app.wsgi_app = MyMiddleware(app.wsgi_app)\n\n        Then you still have the original application object around and\n        can continue to call methods on it.\n\n        .. versionchanged:: 0.7\n            Teardown events for the request and app contexts are called\n            even if an unhandled error occurs. Other events may not be\n            called depending on when an error occurs during dispatch.\n            See :ref:`callbacks-and-errors`.\n\n        :param environ: A WSGI environment.\n        :param start_response: A callable accepting a status code,\n            a list of headers, and an optional exception context to\n            start the response.\n        \"\"\"\n        ctx = self.request_context(environ)\n        error: BaseException | None = None\n        try:\n            try:\n                ctx.push()\n                response = self.full_dispatch_request()\n            except Exception as e:\n                error = e\n                response = self.handle_exception(e)\n            except:  # noqa: B001\n                error = sys.exc_info()[1]\n                raise\n            return response(environ, start_response)\n        finally:\n            if \"werkzeug.debug.preserve_context\" in environ:\n                environ[\"werkzeug.debug.preserve_context\"](_cv_app.get())\n                environ[\"werkzeug.debug.preserve_context\"](_cv_request.get())\n\n            if error is not None and self.should_ignore_error(error):\n                error = None\n\n            ctx.pop(error)\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> cabc.Iterable[bytes]:\n        \"\"\"The WSGI server calls the Flask application object as the\n        WSGI application. This calls :meth:`wsgi_app`, which can be\n        wrapped to apply middleware.\n        \"\"\"\n        return self.wsgi_app(environ, start_response)\n", 1536], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/utils.py": ["from __future__ import annotations\n\nimport io\nimport mimetypes\nimport os\nimport pkgutil\nimport re\nimport sys\nimport typing as t\nimport unicodedata\nfrom datetime import datetime\nfrom time import time\nfrom urllib.parse import quote\nfrom zlib import adler32\n\nfrom markupsafe import escape\n\nfrom ._internal import _DictAccessorProperty\nfrom ._internal import _missing\nfrom ._internal import _TAccessorValue\nfrom .datastructures import Headers\nfrom .exceptions import NotFound\nfrom .exceptions import RequestedRangeNotSatisfiable\nfrom .security import safe_join\nfrom .wsgi import wrap_file\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n    from .wrappers.response import Response\n\n_T = t.TypeVar(\"_T\")\n\n_entity_re = re.compile(r\"&([^;]+);\")\n_filename_ascii_strip_re = re.compile(r\"[^A-Za-z0-9_.-]\")\n_windows_device_files = {\n    \"CON\",\n    \"PRN\",\n    \"AUX\",\n    \"NUL\",\n    *(f\"COM{i}\" for i in range(10)),\n    *(f\"LPT{i}\" for i in range(10)),\n}\n\n\nclass cached_property(property, t.Generic[_T]):\n    \"\"\"A :func:`property` that is only evaluated once. Subsequent access\n    returns the cached value. Setting the property sets the cached\n    value. Deleting the property clears the cached value, accessing it\n    again will evaluate it again.\n\n    .. code-block:: python\n\n        class Example:\n            @cached_property\n            def value(self):\n                # calculate something important here\n                return 42\n\n        e = Example()\n        e.value  # evaluates\n        e.value  # uses cache\n        e.value = 16  # sets cache\n        del e.value  # clears cache\n\n    If the class defines ``__slots__``, it must add ``_cache_{name}`` as\n    a slot. Alternatively, it can add ``__dict__``, but that's usually\n    not desirable.\n\n    .. versionchanged:: 2.1\n        Works with ``__slots__``.\n\n    .. versionchanged:: 2.0\n        ``del obj.name`` clears the cached value.\n    \"\"\"\n\n    def __init__(\n        self,\n        fget: t.Callable[[t.Any], _T],\n        name: str | None = None,\n        doc: str | None = None,\n    ) -> None:\n        super().__init__(fget, doc=doc)\n        self.__name__ = name or fget.__name__\n        self.slot_name = f\"_cache_{self.__name__}\"\n        self.__module__ = fget.__module__\n\n    def __set__(self, obj: object, value: _T) -> None:\n        if hasattr(obj, \"__dict__\"):\n            obj.__dict__[self.__name__] = value\n        else:\n            setattr(obj, self.slot_name, value)\n\n    def __get__(self, obj: object, type: type = None) -> _T:  # type: ignore\n        if obj is None:\n            return self  # type: ignore\n\n        obj_dict = getattr(obj, \"__dict__\", None)\n\n        if obj_dict is not None:\n            value: _T = obj_dict.get(self.__name__, _missing)\n        else:\n            value = getattr(obj, self.slot_name, _missing)  # type: ignore[arg-type]\n\n        if value is _missing:\n            value = self.fget(obj)  # type: ignore\n\n            if obj_dict is not None:\n                obj.__dict__[self.__name__] = value\n            else:\n                setattr(obj, self.slot_name, value)\n\n        return value\n\n    def __delete__(self, obj: object) -> None:\n        if hasattr(obj, \"__dict__\"):\n            del obj.__dict__[self.__name__]\n        else:\n            setattr(obj, self.slot_name, _missing)\n\n\nclass environ_property(_DictAccessorProperty[_TAccessorValue]):\n    \"\"\"Maps request attributes to environment variables. This works not only\n    for the Werkzeug request object, but also any other class with an\n    environ attribute:\n\n    >>> class Test(object):\n    ...     environ = {'key': 'value'}\n    ...     test = environ_property('key')\n    >>> var = Test()\n    >>> var.test\n    'value'\n\n    If you pass it a second value it's used as default if the key does not\n    exist, the third one can be a converter that takes a value and converts\n    it.  If it raises :exc:`ValueError` or :exc:`TypeError` the default value\n    is used. If no default value is provided `None` is used.\n\n    Per default the property is read only.  You have to explicitly enable it\n    by passing ``read_only=False`` to the constructor.\n    \"\"\"\n\n    read_only = True\n\n    def lookup(self, obj: Request) -> WSGIEnvironment:\n        return obj.environ\n\n\nclass header_property(_DictAccessorProperty[_TAccessorValue]):\n    \"\"\"Like `environ_property` but for headers.\"\"\"\n\n    def lookup(self, obj: Request | Response) -> Headers:  # type: ignore[override]\n        return obj.headers\n\n\n# https://cgit.freedesktop.org/xdg/shared-mime-info/tree/freedesktop.org.xml.in\n# https://www.iana.org/assignments/media-types/media-types.xhtml\n# Types listed in the XDG mime info that have a charset in the IANA registration.\n_charset_mimetypes = {\n    \"application/ecmascript\",\n    \"application/javascript\",\n    \"application/sql\",\n    \"application/xml\",\n    \"application/xml-dtd\",\n    \"application/xml-external-parsed-entity\",\n}\n\n\ndef get_content_type(mimetype: str, charset: str) -> str:\n    \"\"\"Returns the full content type string with charset for a mimetype.\n\n    If the mimetype represents text, the charset parameter will be\n    appended, otherwise the mimetype is returned unchanged.\n\n    :param mimetype: The mimetype to be used as content type.\n    :param charset: The charset to be appended for text mimetypes.\n    :return: The content type.\n\n    .. versionchanged:: 0.15\n        Any type that ends with ``+xml`` gets a charset, not just those\n        that start with ``application/``. Known text types such as\n        ``application/javascript`` are also given charsets.\n    \"\"\"\n    if (\n        mimetype.startswith(\"text/\")\n        or mimetype in _charset_mimetypes\n        or mimetype.endswith(\"+xml\")\n    ):\n        mimetype += f\"; charset={charset}\"\n\n    return mimetype\n\n\ndef secure_filename(filename: str) -> str:\n    r\"\"\"Pass it a filename and it will return a secure version of it.  This\n    filename can then safely be stored on a regular file system and passed\n    to :func:`os.path.join`.  The filename returned is an ASCII only string\n    for maximum portability.\n\n    On windows systems the function also makes sure that the file is not\n    named after one of the special device files.\n\n    >>> secure_filename(\"My cool movie.mov\")\n    'My_cool_movie.mov'\n    >>> secure_filename(\"../../../etc/passwd\")\n    'etc_passwd'\n    >>> secure_filename('i contain cool \\xfcml\\xe4uts.txt')\n    'i_contain_cool_umlauts.txt'\n\n    The function might return an empty filename.  It's your responsibility\n    to ensure that the filename is unique and that you abort or\n    generate a random filename if the function returned an empty one.\n\n    .. versionadded:: 0.5\n\n    :param filename: the filename to secure\n    \"\"\"\n    filename = unicodedata.normalize(\"NFKD\", filename)\n    filename = filename.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n\n    for sep in os.sep, os.path.altsep:\n        if sep:\n            filename = filename.replace(sep, \" \")\n    filename = str(_filename_ascii_strip_re.sub(\"\", \"_\".join(filename.split()))).strip(\n        \"._\"\n    )\n\n    # on nt a couple of special files are present in each folder.  We\n    # have to ensure that the target file is not such a filename.  In\n    # this case we prepend an underline\n    if (\n        os.name == \"nt\"\n        and filename\n        and filename.split(\".\")[0].upper() in _windows_device_files\n    ):\n        filename = f\"_{filename}\"\n\n    return filename\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[Response] | None = None\n) -> Response:\n    \"\"\"Returns a response object (a WSGI application) that, if called,\n    redirects the client to the target location. Supported codes are\n    301, 302, 303, 305, 307, and 308. 300 is not supported because\n    it's not a real redirect and 304 because it's the answer for a\n    request with a request with defined If-Modified-Since headers.\n\n    .. versionadded:: 0.6\n       The location can now be a unicode string that is encoded using\n       the :func:`iri_to_uri` function.\n\n    .. versionadded:: 0.10\n        The class used for the Response object can now be passed in.\n\n    :param location: the location the response should redirect to.\n    :param code: the redirect status code. defaults to 302.\n    :param class Response: a Response class to use when instantiating a\n        response. The default is :class:`werkzeug.wrappers.Response` if\n        unspecified.\n    \"\"\"\n    if Response is None:\n        from .wrappers import Response\n\n    html_location = escape(location)\n    response = Response(  # type: ignore[misc]\n        \"<!doctype html>\\n\"\n        \"<html lang=en>\\n\"\n        \"<title>Redirecting...</title>\\n\"\n        \"<h1>Redirecting...</h1>\\n\"\n        \"<p>You should be redirected automatically to the target URL: \"\n        f'<a href=\"{html_location}\">{html_location}</a>. If not, click the link.\\n',\n        code,\n        mimetype=\"text/html\",\n    )\n    response.headers[\"Location\"] = location\n    return response\n\n\ndef append_slash_redirect(environ: WSGIEnvironment, code: int = 308) -> Response:\n    \"\"\"Redirect to the current URL with a slash appended.\n\n    If the current URL is ``/user/42``, the redirect URL will be\n    ``42/``. When joined to the current URL during response\n    processing or by the browser, this will produce ``/user/42/``.\n\n    The behavior is undefined if the path ends with a slash already. If\n    called unconditionally on a URL, it may produce a redirect loop.\n\n    :param environ: Use the path and query from this WSGI environment\n        to produce the redirect URL.\n    :param code: the status code for the redirect.\n\n    .. versionchanged:: 2.1\n        Produce a relative URL that only modifies the last segment.\n        Relevant when the current path has multiple segments.\n\n    .. versionchanged:: 2.1\n        The default status code is 308 instead of 301. This preserves\n        the request method and body.\n    \"\"\"\n    tail = environ[\"PATH_INFO\"].rpartition(\"/\")[2]\n\n    if not tail:\n        new_path = \"./\"\n    else:\n        new_path = f\"{tail}/\"\n\n    query_string = environ.get(\"QUERY_STRING\")\n\n    if query_string:\n        new_path = f\"{new_path}?{query_string}\"\n\n    return redirect(new_path, code)\n\n\ndef send_file(\n    path_or_file: os.PathLike[str] | str | t.IO[bytes],\n    environ: WSGIEnvironment,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n    use_x_sendfile: bool = False,\n    response_class: type[Response] | None = None,\n    _root_path: os.PathLike[str] | str | None = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve user-provided paths.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, ``use_x_sendfile=True``\n    will tell the server to send the given path, which is much more\n    efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param environ: The WSGI environ for the current request.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n    :param use_x_sendfile: Set the ``X-Sendfile`` header to let the\n        server to efficiently send the file. Requires support from the\n        HTTP server. Requires passing a file path.\n    :param response_class: Build the response using this class. Defaults\n        to :class:`~werkzeug.wrappers.Response`.\n    :param _root_path: Do not use. For internal use only. Use\n        :func:`send_from_directory` to safely send files under a path.\n\n    .. versionchanged:: 2.0.2\n        ``send_file`` only sets a detected ``Content-Encoding`` if\n        ``as_attachment`` is disabled.\n\n    .. versionadded:: 2.0\n        Adapted from Flask's implementation.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces Flask's ``attachment_filename``\n         parameter. If ``as_attachment=False``, it is passed with\n         ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces Flask's ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces Flask's ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        If an encoding is returned when guessing ``mimetype`` from\n        ``download_name``, set the ``Content-Encoding`` header.\n    \"\"\"\n    if response_class is None:\n        from .wrappers import Response\n\n        response_class = Response\n\n    path: str | None = None\n    file: t.IO[bytes] | None = None\n    size: int | None = None\n    mtime: float | None = None\n    headers = Headers()\n\n    if isinstance(path_or_file, (os.PathLike, str)) or hasattr(\n        path_or_file, \"__fspath__\"\n    ):\n        path_or_file = t.cast(\"t.Union[os.PathLike[str], str]\", path_or_file)\n\n        # Flask will pass app.root_path, allowing its send_file wrapper\n        # to not have to deal with paths.\n        if _root_path is not None:\n            path = os.path.join(_root_path, path_or_file)\n        else:\n            path = os.path.abspath(path_or_file)\n\n        stat = os.stat(path)\n        size = stat.st_size\n        mtime = stat.st_mtime\n    else:\n        file = path_or_file\n\n    if download_name is None and path is not None:\n        download_name = os.path.basename(path)\n\n    if mimetype is None:\n        if download_name is None:\n            raise TypeError(\n                \"Unable to detect the MIME type because a file name is\"\n                \" not available. Either set 'download_name', pass a\"\n                \" path instead of a file, or set 'mimetype'.\"\n            )\n\n        mimetype, encoding = mimetypes.guess_type(download_name)\n\n        if mimetype is None:\n            mimetype = \"application/octet-stream\"\n\n        # Don't send encoding for attachments, it causes browsers to\n        # save decompress tar.gz files.\n        if encoding is not None and not as_attachment:\n            headers.set(\"Content-Encoding\", encoding)\n\n    if download_name is not None:\n        try:\n            download_name.encode(\"ascii\")\n        except UnicodeEncodeError:\n            simple = unicodedata.normalize(\"NFKD\", download_name)\n            simple = simple.encode(\"ascii\", \"ignore\").decode(\"ascii\")\n            # safe = RFC 5987 attr-char\n            quoted = quote(download_name, safe=\"!#$&+-.^_`|~\")\n            names = {\"filename\": simple, \"filename*\": f\"UTF-8''{quoted}\"}\n        else:\n            names = {\"filename\": download_name}\n\n        value = \"attachment\" if as_attachment else \"inline\"\n        headers.set(\"Content-Disposition\", value, **names)\n    elif as_attachment:\n        raise TypeError(\n            \"No name provided for attachment. Either set\"\n            \" 'download_name' or pass a path instead of a file.\"\n        )\n\n    if use_x_sendfile and path is not None:\n        headers[\"X-Sendfile\"] = path\n        data = None\n    else:\n        if file is None:\n            file = open(path, \"rb\")  # type: ignore\n        elif isinstance(file, io.BytesIO):\n            size = file.getbuffer().nbytes\n        elif isinstance(file, io.TextIOBase):\n            raise ValueError(\"Files must be opened in binary mode or use BytesIO.\")\n\n        data = wrap_file(environ, file)\n\n    rv = response_class(\n        data, mimetype=mimetype, headers=headers, direct_passthrough=True\n    )\n\n    if size is not None:\n        rv.content_length = size\n\n    if last_modified is not None:\n        rv.last_modified = last_modified  # type: ignore\n    elif mtime is not None:\n        rv.last_modified = mtime  # type: ignore\n\n    rv.cache_control.no_cache = True\n\n    # Flask will pass app.get_send_file_max_age, allowing its send_file\n    # wrapper to not have to deal with paths.\n    if callable(max_age):\n        max_age = max_age(path)\n\n    if max_age is not None:\n        if max_age > 0:\n            rv.cache_control.no_cache = None\n            rv.cache_control.public = True\n\n        rv.cache_control.max_age = max_age\n        rv.expires = int(time() + max_age)  # type: ignore\n\n    if isinstance(etag, str):\n        rv.set_etag(etag)\n    elif etag and path is not None:\n        check = adler32(path.encode()) & 0xFFFFFFFF\n        rv.set_etag(f\"{mtime}-{size}-{check}\")\n\n    if conditional:\n        try:\n            rv = rv.make_conditional(environ, accept_ranges=True, complete_length=size)\n        except RequestedRangeNotSatisfiable:\n            if file is not None:\n                file.close()\n\n            raise\n\n        # Some x-sendfile implementations incorrectly ignore the 304\n        # status code and send the file anyway.\n        if rv.status_code == 304:\n            rv.headers.pop(\"x-sendfile\", None)\n\n    return rv\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    environ: WSGIEnvironment,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    returns a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under. This *must not*\n        be a value provided by the client, otherwise it becomes insecure.\n    :param path: The path to the file to send, relative to ``directory``. This is the\n        part of the path provided by the client, which is checked for security.\n    :param environ: The WSGI environ for the current request.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionadded:: 2.0\n        Adapted from Flask's implementation.\n    \"\"\"\n    path_str = safe_join(os.fspath(directory), os.fspath(path))\n\n    if path_str is None:\n        raise NotFound()\n\n    # Flask will pass app.root_path, allowing its send_from_directory\n    # wrapper to not have to deal with paths.\n    if \"_root_path\" in kwargs:\n        path_str = os.path.join(kwargs[\"_root_path\"], path_str)\n\n    if not os.path.isfile(path_str):\n        raise NotFound()\n\n    return send_file(path_str, environ, **kwargs)\n\n\ndef import_string(import_name: str, silent: bool = False) -> t.Any:\n    \"\"\"Imports an object based on a string.  This is useful if you want to\n    use import paths as endpoints or something similar.  An import path can\n    be specified either in dotted notation (``xml.sax.saxutils.escape``)\n    or with a colon as object delimiter (``xml.sax.saxutils:escape``).\n\n    If `silent` is True the return value will be `None` if the import fails.\n\n    :param import_name: the dotted name for the object to import.\n    :param silent: if set to `True` import errors are ignored and\n                   `None` is returned instead.\n    :return: imported object\n    \"\"\"\n    import_name = import_name.replace(\":\", \".\")\n    try:\n        try:\n            __import__(import_name)\n        except ImportError:\n            if \".\" not in import_name:\n                raise\n        else:\n            return sys.modules[import_name]\n\n        module_name, obj_name = import_name.rsplit(\".\", 1)\n        module = __import__(module_name, globals(), locals(), [obj_name])\n        try:\n            return getattr(module, obj_name)\n        except AttributeError as e:\n            raise ImportError(e) from None\n\n    except ImportError as e:\n        if not silent:\n            raise ImportStringError(import_name, e).with_traceback(\n                sys.exc_info()[2]\n            ) from None\n\n    return None\n\n\ndef find_modules(\n    import_path: str, include_packages: bool = False, recursive: bool = False\n) -> t.Iterator[str]:\n    \"\"\"Finds all the modules below a package.  This can be useful to\n    automatically import all views / controllers so that their metaclasses /\n    function decorators have a chance to register themselves on the\n    application.\n\n    Packages are not returned unless `include_packages` is `True`.  This can\n    also recursively list modules but in that case it will import all the\n    packages to get the correct load path of that module.\n\n    :param import_path: the dotted name for the package to find child modules.\n    :param include_packages: set to `True` if packages should be returned, too.\n    :param recursive: set to `True` if recursion should happen.\n    :return: generator\n    \"\"\"\n    module = import_string(import_path)\n    path = getattr(module, \"__path__\", None)\n    if path is None:\n        raise ValueError(f\"{import_path!r} is not a package\")\n    basename = f\"{module.__name__}.\"\n    for _importer, modname, ispkg in pkgutil.iter_modules(path):\n        modname = basename + modname\n        if ispkg:\n            if include_packages:\n                yield modname\n            if recursive:\n                yield from find_modules(modname, include_packages, True)\n        else:\n            yield modname\n\n\nclass ImportStringError(ImportError):\n    \"\"\"Provides information about a failed :func:`import_string` attempt.\"\"\"\n\n    #: String in dotted notation that failed to be imported.\n    import_name: str\n    #: Wrapped exception.\n    exception: BaseException\n\n    def __init__(self, import_name: str, exception: BaseException) -> None:\n        self.import_name = import_name\n        self.exception = exception\n        msg = import_name\n        name = \"\"\n        tracked = []\n        for part in import_name.replace(\":\", \".\").split(\".\"):\n            name = f\"{name}.{part}\" if name else part\n            imported = import_string(name, silent=True)\n            if imported:\n                tracked.append((name, getattr(imported, \"__file__\", None)))\n            else:\n                track = [f\"- {n!r} found in {i!r}.\" for n, i in tracked]\n                track.append(f\"- {name!r} not found.\")\n                track_str = \"\\n\".join(track)\n                msg = (\n                    f\"import_string() failed for {import_name!r}. Possible reasons\"\n                    f\" are:\\n\\n\"\n                    \"- missing __init__.py in a package;\\n\"\n                    \"- package or module path not included in sys.path;\\n\"\n                    \"- duplicated package or module name taking precedence in\"\n                    \" sys.path;\\n\"\n                    \"- missing module, class, function or variable;\\n\\n\"\n                    f\"Debugged import:\\n\\n{track_str}\\n\\n\"\n                    f\"Original exception:\\n\\n{type(exception).__name__}: {exception}\"\n                )\n                break\n\n        super().__init__(msg)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__}({self.import_name!r}, {self.exception!r})>\"\n", 691], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py": ["\"\"\"A WSGI and HTTP server for use **during development only**. This\nserver is convenient to use, but is not designed to be particularly\nstable, secure, or efficient. Use a dedicate WSGI server and HTTP\nserver when deploying to production.\n\nIt provides features like interactive debugging and code reloading. Use\n``run_simple`` to start the server. Put this in a ``run.py`` script:\n\n.. code-block:: python\n\n    from myapp import create_app\n    from werkzeug import run_simple\n\"\"\"\n\nfrom __future__ import annotations\n\nimport errno\nimport io\nimport os\nimport selectors\nimport socket\nimport socketserver\nimport sys\nimport typing as t\nfrom datetime import datetime as dt\nfrom datetime import timedelta\nfrom datetime import timezone\nfrom http.server import BaseHTTPRequestHandler\nfrom http.server import HTTPServer\nfrom urllib.parse import unquote\nfrom urllib.parse import urlsplit\n\nfrom ._internal import _log\nfrom ._internal import _wsgi_encoding_dance\nfrom .exceptions import InternalServerError\nfrom .urls import uri_to_iri\n\ntry:\n    import ssl\n\n    connection_dropped_errors: tuple[type[Exception], ...] = (\n        ConnectionError,\n        socket.timeout,\n        ssl.SSLEOFError,\n    )\nexcept ImportError:\n\n    class _SslDummy:\n        def __getattr__(self, name: str) -> t.Any:\n            raise RuntimeError(  # noqa: B904\n                \"SSL is unavailable because this Python runtime was not\"\n                \" compiled with SSL/TLS support.\"\n            )\n\n    ssl = _SslDummy()  # type: ignore\n    connection_dropped_errors = (ConnectionError, socket.timeout)\n\n_log_add_style = True\n\nif os.name == \"nt\":\n    try:\n        __import__(\"colorama\")\n    except ImportError:\n        _log_add_style = False\n\ncan_fork = hasattr(os, \"fork\")\n\nif can_fork:\n    ForkingMixIn = socketserver.ForkingMixIn\nelse:\n\n    class ForkingMixIn:  # type: ignore\n        pass\n\n\ntry:\n    af_unix = socket.AF_UNIX\nexcept AttributeError:\n    af_unix = None  # type: ignore\n\nLISTEN_QUEUE = 128\n\n_TSSLContextArg = t.Optional[\n    t.Union[\"ssl.SSLContext\", tuple[str, t.Optional[str]], t.Literal[\"adhoc\"]]\n]\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n    from cryptography.hazmat.primitives.asymmetric.rsa import (\n        RSAPrivateKeyWithSerialization,\n    )\n    from cryptography.x509 import Certificate\n\n\nclass DechunkedInput(io.RawIOBase):\n    \"\"\"An input stream that handles Transfer-Encoding 'chunked'\"\"\"\n\n    def __init__(self, rfile: t.IO[bytes]) -> None:\n        self._rfile = rfile\n        self._done = False\n        self._len = 0\n\n    def readable(self) -> bool:\n        return True\n\n    def read_chunk_len(self) -> int:\n        try:\n            line = self._rfile.readline().decode(\"latin1\")\n            _len = int(line.strip(), 16)\n        except ValueError as e:\n            raise OSError(\"Invalid chunk header\") from e\n        if _len < 0:\n            raise OSError(\"Negative chunk length not allowed\")\n        return _len\n\n    def readinto(self, buf: bytearray) -> int:  # type: ignore\n        read = 0\n        while not self._done and read < len(buf):\n            if self._len == 0:\n                # This is the first chunk or we fully consumed the previous\n                # one. Read the next length of the next chunk\n                self._len = self.read_chunk_len()\n\n            if self._len == 0:\n                # Found the final chunk of size 0. The stream is now exhausted,\n                # but there is still a final newline that should be consumed\n                self._done = True\n\n            if self._len > 0:\n                # There is data (left) in this chunk, so append it to the\n                # buffer. If this operation fully consumes the chunk, this will\n                # reset self._len to 0.\n                n = min(len(buf), self._len)\n\n                # If (read + chunk size) becomes more than len(buf), buf will\n                # grow beyond the original size and read more data than\n                # required. So only read as much data as can fit in buf.\n                if read + n > len(buf):\n                    buf[read:] = self._rfile.read(len(buf) - read)\n                    self._len -= len(buf) - read\n                    read = len(buf)\n                else:\n                    buf[read : read + n] = self._rfile.read(n)\n                    self._len -= n\n                    read += n\n\n            if self._len == 0:\n                # Skip the terminating newline of a chunk that has been fully\n                # consumed. This also applies to the 0-sized final chunk\n                terminator = self._rfile.readline()\n                if terminator not in (b\"\\n\", b\"\\r\\n\", b\"\\r\"):\n                    raise OSError(\"Missing chunk terminating newline\")\n\n        return read\n\n\nclass WSGIRequestHandler(BaseHTTPRequestHandler):\n    \"\"\"A request handler that implements WSGI dispatching.\"\"\"\n\n    server: BaseWSGIServer\n\n    @property\n    def server_version(self) -> str:  # type: ignore\n        return self.server._server_version\n\n    def make_environ(self) -> WSGIEnvironment:\n        request_url = urlsplit(self.path)\n        url_scheme = \"http\" if self.server.ssl_context is None else \"https\"\n\n        if not self.client_address:\n            self.client_address = (\"<local>\", 0)\n        elif isinstance(self.client_address, str):\n            self.client_address = (self.client_address, 0)\n\n        # If there was no scheme but the path started with two slashes,\n        # the first segment may have been incorrectly parsed as the\n        # netloc, prepend it to the path again.\n        if not request_url.scheme and request_url.netloc:\n            path_info = f\"/{request_url.netloc}{request_url.path}\"\n        else:\n            path_info = request_url.path\n\n        path_info = unquote(path_info)\n\n        environ: WSGIEnvironment = {\n            \"wsgi.version\": (1, 0),\n            \"wsgi.url_scheme\": url_scheme,\n            \"wsgi.input\": self.rfile,\n            \"wsgi.errors\": sys.stderr,\n            \"wsgi.multithread\": self.server.multithread,\n            \"wsgi.multiprocess\": self.server.multiprocess,\n            \"wsgi.run_once\": False,\n            \"werkzeug.socket\": self.connection,\n            \"SERVER_SOFTWARE\": self.server_version,\n            \"REQUEST_METHOD\": self.command,\n            \"SCRIPT_NAME\": \"\",\n            \"PATH_INFO\": _wsgi_encoding_dance(path_info),\n            \"QUERY_STRING\": _wsgi_encoding_dance(request_url.query),\n            # Non-standard, added by mod_wsgi, uWSGI\n            \"REQUEST_URI\": _wsgi_encoding_dance(self.path),\n            # Non-standard, added by gunicorn\n            \"RAW_URI\": _wsgi_encoding_dance(self.path),\n            \"REMOTE_ADDR\": self.address_string(),\n            \"REMOTE_PORT\": self.port_integer(),\n            \"SERVER_NAME\": self.server.server_address[0],\n            \"SERVER_PORT\": str(self.server.server_address[1]),\n            \"SERVER_PROTOCOL\": self.request_version,\n        }\n\n        for key, value in self.headers.items():\n            if \"_\" in key:\n                continue\n\n            key = key.upper().replace(\"-\", \"_\")\n            value = value.replace(\"\\r\\n\", \"\")\n            if key not in (\"CONTENT_TYPE\", \"CONTENT_LENGTH\"):\n                key = f\"HTTP_{key}\"\n                if key in environ:\n                    value = f\"{environ[key]},{value}\"\n            environ[key] = value\n\n        if environ.get(\"HTTP_TRANSFER_ENCODING\", \"\").strip().lower() == \"chunked\":\n            environ[\"wsgi.input_terminated\"] = True\n            environ[\"wsgi.input\"] = DechunkedInput(environ[\"wsgi.input\"])\n\n        # Per RFC 2616, if the URL is absolute, use that as the host.\n        # We're using \"has a scheme\" to indicate an absolute URL.\n        if request_url.scheme and request_url.netloc:\n            environ[\"HTTP_HOST\"] = request_url.netloc\n\n        try:\n            # binary_form=False gives nicer information, but wouldn't be compatible with\n            # what Nginx or Apache could return.\n            peer_cert = self.connection.getpeercert(binary_form=True)\n            if peer_cert is not None:\n                # Nginx and Apache use PEM format.\n                environ[\"SSL_CLIENT_CERT\"] = ssl.DER_cert_to_PEM_cert(peer_cert)\n        except ValueError:\n            # SSL handshake hasn't finished.\n            self.server.log(\"error\", \"Cannot fetch SSL peer certificate info\")\n        except AttributeError:\n            # Not using TLS, the socket will not have getpeercert().\n            pass\n\n        return environ\n\n    def run_wsgi(self) -> None:\n        if self.headers.get(\"Expect\", \"\").lower().strip() == \"100-continue\":\n            self.wfile.write(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n\n        self.environ = environ = self.make_environ()\n        status_set: str | None = None\n        headers_set: list[tuple[str, str]] | None = None\n        status_sent: str | None = None\n        headers_sent: list[tuple[str, str]] | None = None\n        chunk_response: bool = False\n\n        def write(data: bytes) -> None:\n            nonlocal status_sent, headers_sent, chunk_response\n            assert status_set is not None, \"write() before start_response\"\n            assert headers_set is not None, \"write() before start_response\"\n            if status_sent is None:\n                status_sent = status_set\n                headers_sent = headers_set\n                try:\n                    code_str, msg = status_sent.split(None, 1)\n                except ValueError:\n                    code_str, msg = status_sent, \"\"\n                code = int(code_str)\n                self.send_response(code, msg)\n                header_keys = set()\n                for key, value in headers_sent:\n                    self.send_header(key, value)\n                    header_keys.add(key.lower())\n\n                # Use chunked transfer encoding if there is no content\n                # length. Do not use for 1xx and 204 responses. 304\n                # responses and HEAD requests are also excluded, which\n                # is the more conservative behavior and matches other\n                # parts of the code.\n                # https://httpwg.org/specs/rfc7230.html#rfc.section.3.3.1\n                if (\n                    not (\n                        \"content-length\" in header_keys\n                        or environ[\"REQUEST_METHOD\"] == \"HEAD\"\n                        or (100 <= code < 200)\n                        or code in {204, 304}\n                    )\n                    and self.protocol_version >= \"HTTP/1.1\"\n                ):\n                    chunk_response = True\n                    self.send_header(\"Transfer-Encoding\", \"chunked\")\n\n                # Always close the connection. This disables HTTP/1.1\n                # keep-alive connections. They aren't handled well by\n                # Python's http.server because it doesn't know how to\n                # drain the stream before the next request line.\n                self.send_header(\"Connection\", \"close\")\n                self.end_headers()\n\n            assert isinstance(data, bytes), \"applications must write bytes\"\n\n            if data:\n                if chunk_response:\n                    self.wfile.write(hex(len(data))[2:].encode())\n                    self.wfile.write(b\"\\r\\n\")\n\n                self.wfile.write(data)\n\n                if chunk_response:\n                    self.wfile.write(b\"\\r\\n\")\n\n            self.wfile.flush()\n\n        def start_response(status, headers, exc_info=None):  # type: ignore\n            nonlocal status_set, headers_set\n            if exc_info:\n                try:\n                    if headers_sent:\n                        raise exc_info[1].with_traceback(exc_info[2])\n                finally:\n                    exc_info = None\n            elif headers_set:\n                raise AssertionError(\"Headers already set\")\n            status_set = status\n            headers_set = headers\n            return write\n\n        def execute(app: WSGIApplication) -> None:\n            application_iter = app(environ, start_response)\n            try:\n                for data in application_iter:\n                    write(data)\n                if not headers_sent:\n                    write(b\"\")\n                if chunk_response:\n                    self.wfile.write(b\"0\\r\\n\\r\\n\")\n            finally:\n                # Check for any remaining data in the read socket, and discard it. This\n                # will read past request.max_content_length, but lets the client see a\n                # 413 response instead of a connection reset failure. If we supported\n                # keep-alive connections, this naive approach would break by reading the\n                # next request line. Since we know that write (above) closes every\n                # connection we can read everything.\n                selector = selectors.DefaultSelector()\n                selector.register(self.connection, selectors.EVENT_READ)\n                total_size = 0\n                total_reads = 0\n\n                # A timeout of 0 tends to fail because a client needs a small amount of\n                # time to continue sending its data.\n                while selector.select(timeout=0.01):\n                    # Only read 10MB into memory at a time.\n                    data = self.rfile.read(10_000_000)\n                    total_size += len(data)\n                    total_reads += 1\n\n                    # Stop reading on no data, >=10GB, or 1000 reads. If a client sends\n                    # more than that, they'll get a connection reset failure.\n                    if not data or total_size >= 10_000_000_000 or total_reads > 1000:\n                        break\n\n                selector.close()\n\n                if hasattr(application_iter, \"close\"):\n                    application_iter.close()\n\n        try:\n            execute(self.server.app)\n        except connection_dropped_errors as e:\n            self.connection_dropped(e, environ)\n        except Exception as e:\n            if self.server.passthrough_errors:\n                raise\n\n            if status_sent is not None and chunk_response:\n                self.close_connection = True\n\n            try:\n                # if we haven't yet sent the headers but they are set\n                # we roll back to be able to set them again.\n                if status_sent is None:\n                    status_set = None\n                    headers_set = None\n                execute(InternalServerError())\n            except Exception:\n                pass\n\n            from .debug.tbtools import DebugTraceback\n\n            msg = DebugTraceback(e).render_traceback_text()\n            self.server.log(\"error\", f\"Error on request:\\n{msg}\")\n\n    def handle(self) -> None:\n        \"\"\"Handles a request ignoring dropped connections.\"\"\"\n        try:\n            super().handle()\n        except (ConnectionError, socket.timeout) as e:\n            self.connection_dropped(e)\n        except Exception as e:\n            if self.server.ssl_context is not None and is_ssl_error(e):\n                self.log_error(\"SSL error occurred: %s\", e)\n            else:\n                raise\n\n    def connection_dropped(\n        self, error: BaseException, environ: WSGIEnvironment | None = None\n    ) -> None:\n        \"\"\"Called if the connection was closed by the client.  By default\n        nothing happens.\n        \"\"\"\n\n    def __getattr__(self, name: str) -> t.Any:\n        # All HTTP methods are handled by run_wsgi.\n        if name.startswith(\"do_\"):\n            return self.run_wsgi\n\n        # All other attributes are forwarded to the base class.\n        return getattr(super(), name)\n\n    def address_string(self) -> str:\n        if getattr(self, \"environ\", None):\n            return self.environ[\"REMOTE_ADDR\"]  # type: ignore\n\n        if not self.client_address:\n            return \"<local>\"\n\n        return self.client_address[0]\n\n    def port_integer(self) -> int:\n        return self.client_address[1]\n\n    # Escape control characters. This is defined (but private) in Python 3.12.\n    _control_char_table = str.maketrans(\n        {c: rf\"\\x{c:02x}\" for c in [*range(0x20), *range(0x7F, 0xA0)]}\n    )\n    _control_char_table[ord(\"\\\\\")] = r\"\\\\\"\n\n    def log_request(self, code: int | str = \"-\", size: int | str = \"-\") -> None:\n        try:\n            path = uri_to_iri(self.path)\n            msg = f\"{self.command} {path} {self.request_version}\"\n        except AttributeError:\n            # path isn't set if the requestline was bad\n            msg = self.requestline\n\n        # Escape control characters that may be in the decoded path.\n        msg = msg.translate(self._control_char_table)\n        code = str(code)\n\n        if code[0] == \"1\":  # 1xx - Informational\n            msg = _ansi_style(msg, \"bold\")\n        elif code == \"200\":  # 2xx - Success\n            pass\n        elif code == \"304\":  # 304 - Resource Not Modified\n            msg = _ansi_style(msg, \"cyan\")\n        elif code[0] == \"3\":  # 3xx - Redirection\n            msg = _ansi_style(msg, \"green\")\n        elif code == \"404\":  # 404 - Resource Not Found\n            msg = _ansi_style(msg, \"yellow\")\n        elif code[0] == \"4\":  # 4xx - Client Error\n            msg = _ansi_style(msg, \"bold\", \"red\")\n        else:  # 5xx, or any other response\n            msg = _ansi_style(msg, \"bold\", \"magenta\")\n\n        self.log(\"info\", '\"%s\" %s %s', msg, code, size)\n\n    def log_error(self, format: str, *args: t.Any) -> None:\n        self.log(\"error\", format, *args)\n\n    def log_message(self, format: str, *args: t.Any) -> None:\n        self.log(\"info\", format, *args)\n\n    def log(self, type: str, message: str, *args: t.Any) -> None:\n        # an IPv6 scoped address contains \"%\" which breaks logging\n        address_string = self.address_string().replace(\"%\", \"%%\")\n        _log(\n            type,\n            f\"{address_string} - - [{self.log_date_time_string()}] {message}\\n\",\n            *args,\n        )\n\n\ndef _ansi_style(value: str, *styles: str) -> str:\n    if not _log_add_style:\n        return value\n\n    codes = {\n        \"bold\": 1,\n        \"red\": 31,\n        \"green\": 32,\n        \"yellow\": 33,\n        \"magenta\": 35,\n        \"cyan\": 36,\n    }\n\n    for style in styles:\n        value = f\"\\x1b[{codes[style]}m{value}\"\n\n    return f\"{value}\\x1b[0m\"\n\n\ndef generate_adhoc_ssl_pair(\n    cn: str | None = None,\n) -> tuple[Certificate, RSAPrivateKeyWithSerialization]:\n    try:\n        from cryptography import x509\n        from cryptography.hazmat.backends import default_backend\n        from cryptography.hazmat.primitives import hashes\n        from cryptography.hazmat.primitives.asymmetric import rsa\n        from cryptography.x509.oid import NameOID\n    except ImportError:\n        raise TypeError(\n            \"Using ad-hoc certificates requires the cryptography library.\"\n        ) from None\n\n    backend = default_backend()\n    pkey = rsa.generate_private_key(\n        public_exponent=65537, key_size=2048, backend=backend\n    )\n\n    # pretty damn sure that this is not actually accepted by anyone\n    if cn is None:\n        cn = \"*\"\n\n    subject = x509.Name(\n        [\n            x509.NameAttribute(NameOID.ORGANIZATION_NAME, \"Dummy Certificate\"),\n            x509.NameAttribute(NameOID.COMMON_NAME, cn),\n        ]\n    )\n\n    backend = default_backend()\n    cert = (\n        x509.CertificateBuilder()\n        .subject_name(subject)\n        .issuer_name(subject)\n        .public_key(pkey.public_key())\n        .serial_number(x509.random_serial_number())\n        .not_valid_before(dt.now(timezone.utc))\n        .not_valid_after(dt.now(timezone.utc) + timedelta(days=365))\n        .add_extension(x509.ExtendedKeyUsage([x509.OID_SERVER_AUTH]), critical=False)\n        .add_extension(\n            x509.SubjectAlternativeName([x509.DNSName(cn), x509.DNSName(f\"*.{cn}\")]),\n            critical=False,\n        )\n        .sign(pkey, hashes.SHA256(), backend)\n    )\n    return cert, pkey\n\n\ndef make_ssl_devcert(\n    base_path: str, host: str | None = None, cn: str | None = None\n) -> tuple[str, str]:\n    \"\"\"Creates an SSL key for development.  This should be used instead of\n    the ``'adhoc'`` key which generates a new cert on each server start.\n    It accepts a path for where it should store the key and cert and\n    either a host or CN.  If a host is given it will use the CN\n    ``*.host/CN=host``.\n\n    For more information see :func:`run_simple`.\n\n    .. versionadded:: 0.9\n\n    :param base_path: the path to the certificate and key.  The extension\n                      ``.crt`` is added for the certificate, ``.key`` is\n                      added for the key.\n    :param host: the name of the host.  This can be used as an alternative\n                 for the `cn`.\n    :param cn: the `CN` to use.\n    \"\"\"\n\n    if host is not None:\n        cn = host\n    cert, pkey = generate_adhoc_ssl_pair(cn=cn)\n\n    from cryptography.hazmat.primitives import serialization\n\n    cert_file = f\"{base_path}.crt\"\n    pkey_file = f\"{base_path}.key\"\n\n    with open(cert_file, \"wb\") as f:\n        f.write(cert.public_bytes(serialization.Encoding.PEM))\n    with open(pkey_file, \"wb\") as f:\n        f.write(\n            pkey.private_bytes(\n                encoding=serialization.Encoding.PEM,\n                format=serialization.PrivateFormat.TraditionalOpenSSL,\n                encryption_algorithm=serialization.NoEncryption(),\n            )\n        )\n\n    return cert_file, pkey_file\n\n\ndef generate_adhoc_ssl_context() -> ssl.SSLContext:\n    \"\"\"Generates an adhoc SSL context for the development server.\"\"\"\n    import atexit\n    import tempfile\n\n    cert, pkey = generate_adhoc_ssl_pair()\n\n    from cryptography.hazmat.primitives import serialization\n\n    cert_handle, cert_file = tempfile.mkstemp()\n    pkey_handle, pkey_file = tempfile.mkstemp()\n    atexit.register(os.remove, pkey_file)\n    atexit.register(os.remove, cert_file)\n\n    os.write(cert_handle, cert.public_bytes(serialization.Encoding.PEM))\n    os.write(\n        pkey_handle,\n        pkey.private_bytes(\n            encoding=serialization.Encoding.PEM,\n            format=serialization.PrivateFormat.TraditionalOpenSSL,\n            encryption_algorithm=serialization.NoEncryption(),\n        ),\n    )\n\n    os.close(cert_handle)\n    os.close(pkey_handle)\n    ctx = load_ssl_context(cert_file, pkey_file)\n    return ctx\n\n\ndef load_ssl_context(\n    cert_file: str, pkey_file: str | None = None, protocol: int | None = None\n) -> ssl.SSLContext:\n    \"\"\"Loads SSL context from cert/private key files and optional protocol.\n    Many parameters are directly taken from the API of\n    :py:class:`ssl.SSLContext`.\n\n    :param cert_file: Path of the certificate to use.\n    :param pkey_file: Path of the private key to use. If not given, the key\n                      will be obtained from the certificate file.\n    :param protocol: A ``PROTOCOL`` constant from the :mod:`ssl` module.\n        Defaults to :data:`ssl.PROTOCOL_TLS_SERVER`.\n    \"\"\"\n    if protocol is None:\n        protocol = ssl.PROTOCOL_TLS_SERVER\n\n    ctx = ssl.SSLContext(protocol)\n    ctx.load_cert_chain(cert_file, pkey_file)\n    return ctx\n\n\ndef is_ssl_error(error: Exception | None = None) -> bool:\n    \"\"\"Checks if the given error (or the current one) is an SSL error.\"\"\"\n    if error is None:\n        error = t.cast(Exception, sys.exc_info()[1])\n    return isinstance(error, ssl.SSLError)\n\n\ndef select_address_family(host: str, port: int) -> socket.AddressFamily:\n    \"\"\"Return ``AF_INET4``, ``AF_INET6``, or ``AF_UNIX`` depending on\n    the host and port.\"\"\"\n    if host.startswith(\"unix://\"):\n        return socket.AF_UNIX\n    elif \":\" in host and hasattr(socket, \"AF_INET6\"):\n        return socket.AF_INET6\n    return socket.AF_INET\n\n\ndef get_sockaddr(\n    host: str, port: int, family: socket.AddressFamily\n) -> tuple[str, int] | str:\n    \"\"\"Return a fully qualified socket address that can be passed to\n    :func:`socket.bind`.\"\"\"\n    if family == af_unix:\n        # Absolute path avoids IDNA encoding error when path starts with dot.\n        return os.path.abspath(host.partition(\"://\")[2])\n    try:\n        res = socket.getaddrinfo(\n            host, port, family, socket.SOCK_STREAM, socket.IPPROTO_TCP\n        )\n    except socket.gaierror:\n        return host, port\n    return res[0][4]  # type: ignore\n\n\ndef get_interface_ip(family: socket.AddressFamily) -> str:\n    \"\"\"Get the IP address of an external interface. Used when binding to\n    0.0.0.0 or ::1 to show a more useful URL.\n\n    :meta private:\n    \"\"\"\n    # arbitrary private address\n    host = \"fd31:f903:5ab5:1::1\" if family == socket.AF_INET6 else \"10.253.155.219\"\n\n    with socket.socket(family, socket.SOCK_DGRAM) as s:\n        try:\n            s.connect((host, 58162))\n        except OSError:\n            return \"::1\" if family == socket.AF_INET6 else \"127.0.0.1\"\n\n        return s.getsockname()[0]  # type: ignore\n\n\nclass BaseWSGIServer(HTTPServer):\n    \"\"\"A WSGI server that that handles one request at a time.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multithread = False\n    multiprocess = False\n    request_queue_size = LISTEN_QUEUE\n    allow_reuse_address = True\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        app: WSGIApplication,\n        handler: type[WSGIRequestHandler] | None = None,\n        passthrough_errors: bool = False,\n        ssl_context: _TSSLContextArg | None = None,\n        fd: int | None = None,\n    ) -> None:\n        if handler is None:\n            handler = WSGIRequestHandler\n\n        # If the handler doesn't directly set a protocol version and\n        # thread or process workers are used, then allow chunked\n        # responses and keep-alive connections by enabling HTTP/1.1.\n        if \"protocol_version\" not in vars(handler) and (\n            self.multithread or self.multiprocess\n        ):\n            handler.protocol_version = \"HTTP/1.1\"\n\n        self.host = host\n        self.port = port\n        self.app = app\n        self.passthrough_errors = passthrough_errors\n\n        self.address_family = address_family = select_address_family(host, port)\n        server_address = get_sockaddr(host, int(port), address_family)\n\n        # Remove a leftover Unix socket file from a previous run. Don't\n        # remove a file that was set up by run_simple.\n        if address_family == af_unix and fd is None:\n            server_address = t.cast(str, server_address)\n\n            if os.path.exists(server_address):\n                os.unlink(server_address)\n\n        # Bind and activate will be handled manually, it should only\n        # happen if we're not using a socket that was already set up.\n        super().__init__(\n            server_address,  # type: ignore[arg-type]\n            handler,\n            bind_and_activate=False,\n        )\n\n        if fd is None:\n            # No existing socket descriptor, do bind_and_activate=True.\n            try:\n                self.server_bind()\n                self.server_activate()\n            except OSError as e:\n                # Catch connection issues and show them without the traceback. Show\n                # extra instructions for address not found, and for macOS.\n                self.server_close()\n                print(e.strerror, file=sys.stderr)\n\n                if e.errno == errno.EADDRINUSE:\n                    print(\n                        f\"Port {port} is in use by another program. Either identify and\"\n                        \" stop that program, or start the server with a different\"\n                        \" port.\",\n                        file=sys.stderr,\n                    )\n\n                    if sys.platform == \"darwin\" and port == 5000:\n                        print(\n                            \"On macOS, try disabling the 'AirPlay Receiver' service\"\n                            \" from System Preferences -> General -> AirDrop & Handoff.\",\n                            file=sys.stderr,\n                        )\n\n                sys.exit(1)\n            except BaseException:\n                self.server_close()\n                raise\n        else:\n            # TCPServer automatically opens a socket even if bind_and_activate is False.\n            # Close it to silence a ResourceWarning.\n            self.server_close()\n\n            # Use the passed in socket directly.\n            self.socket = socket.fromfd(fd, address_family, socket.SOCK_STREAM)\n            self.server_address = self.socket.getsockname()\n\n        if address_family != af_unix:\n            # If port was 0, this will record the bound port.\n            self.port = self.server_address[1]\n\n        if ssl_context is not None:\n            if isinstance(ssl_context, tuple):\n                ssl_context = load_ssl_context(*ssl_context)\n            elif ssl_context == \"adhoc\":\n                ssl_context = generate_adhoc_ssl_context()\n\n            self.socket = ssl_context.wrap_socket(self.socket, server_side=True)\n            self.ssl_context: ssl.SSLContext | None = ssl_context\n        else:\n            self.ssl_context = None\n\n        import importlib.metadata\n\n        self._server_version = f\"Werkzeug/{importlib.metadata.version('werkzeug')}\"\n\n    def log(self, type: str, message: str, *args: t.Any) -> None:\n        _log(type, message, *args)\n\n    def serve_forever(self, poll_interval: float = 0.5) -> None:\n        try:\n            super().serve_forever(poll_interval=poll_interval)\n        except KeyboardInterrupt:\n            pass\n        finally:\n            self.server_close()\n\n    def handle_error(\n        self, request: t.Any, client_address: tuple[str, int] | str\n    ) -> None:\n        if self.passthrough_errors:\n            raise\n\n        return super().handle_error(request, client_address)\n\n    def log_startup(self) -> None:\n        \"\"\"Show information about the address when starting the server.\"\"\"\n        dev_warning = (\n            \"WARNING: This is a development server. Do not use it in a production\"\n            \" deployment. Use a production WSGI server instead.\"\n        )\n        dev_warning = _ansi_style(dev_warning, \"bold\", \"red\")\n        messages = [dev_warning]\n\n        if self.address_family == af_unix:\n            messages.append(f\" * Running on {self.host}\")\n        else:\n            scheme = \"http\" if self.ssl_context is None else \"https\"\n            display_hostname = self.host\n\n            if self.host in {\"0.0.0.0\", \"::\"}:\n                messages.append(f\" * Running on all addresses ({self.host})\")\n\n                if self.host == \"0.0.0.0\":\n                    localhost = \"127.0.0.1\"\n                    display_hostname = get_interface_ip(socket.AF_INET)\n                else:\n                    localhost = \"[::1]\"\n                    display_hostname = get_interface_ip(socket.AF_INET6)\n\n                messages.append(f\" * Running on {scheme}://{localhost}:{self.port}\")\n\n            if \":\" in display_hostname:\n                display_hostname = f\"[{display_hostname}]\"\n\n            messages.append(f\" * Running on {scheme}://{display_hostname}:{self.port}\")\n\n        _log(\"info\", \"\\n\".join(messages))\n\n\nclass ThreadedWSGIServer(socketserver.ThreadingMixIn, BaseWSGIServer):\n    \"\"\"A WSGI server that handles concurrent requests in separate\n    threads.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multithread = True\n    daemon_threads = True\n\n\nclass ForkingWSGIServer(ForkingMixIn, BaseWSGIServer):\n    \"\"\"A WSGI server that handles concurrent requests in separate forked\n    processes.\n\n    Use :func:`make_server` to create a server instance.\n    \"\"\"\n\n    multiprocess = True\n\n    def __init__(\n        self,\n        host: str,\n        port: int,\n        app: WSGIApplication,\n        processes: int = 40,\n        handler: type[WSGIRequestHandler] | None = None,\n        passthrough_errors: bool = False,\n        ssl_context: _TSSLContextArg | None = None,\n        fd: int | None = None,\n    ) -> None:\n        if not can_fork:\n            raise ValueError(\"Your platform does not support forking.\")\n\n        super().__init__(host, port, app, handler, passthrough_errors, ssl_context, fd)\n        self.max_children = processes\n\n\ndef make_server(\n    host: str,\n    port: int,\n    app: WSGIApplication,\n    threaded: bool = False,\n    processes: int = 1,\n    request_handler: type[WSGIRequestHandler] | None = None,\n    passthrough_errors: bool = False,\n    ssl_context: _TSSLContextArg | None = None,\n    fd: int | None = None,\n) -> BaseWSGIServer:\n    \"\"\"Create an appropriate WSGI server instance based on the value of\n    ``threaded`` and ``processes``.\n\n    This is called from :func:`run_simple`, but can be used separately\n    to have access to the server object, such as to run it in a separate\n    thread.\n\n    See :func:`run_simple` for parameter docs.\n    \"\"\"\n    if threaded and processes > 1:\n        raise ValueError(\"Cannot have a multi-thread and multi-process server.\")\n\n    if threaded:\n        return ThreadedWSGIServer(\n            host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n        )\n\n    if processes > 1:\n        return ForkingWSGIServer(\n            host,\n            port,\n            app,\n            processes,\n            request_handler,\n            passthrough_errors,\n            ssl_context,\n            fd=fd,\n        )\n\n    return BaseWSGIServer(\n        host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n    )\n\n\ndef is_running_from_reloader() -> bool:\n    \"\"\"Check if the server is running as a subprocess within the\n    Werkzeug reloader.\n\n    .. versionadded:: 0.10\n    \"\"\"\n    return os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\"\n\n\ndef run_simple(\n    hostname: str,\n    port: int,\n    application: WSGIApplication,\n    use_reloader: bool = False,\n    use_debugger: bool = False,\n    use_evalex: bool = True,\n    extra_files: t.Iterable[str] | None = None,\n    exclude_patterns: t.Iterable[str] | None = None,\n    reloader_interval: int = 1,\n    reloader_type: str = \"auto\",\n    threaded: bool = False,\n    processes: int = 1,\n    request_handler: type[WSGIRequestHandler] | None = None,\n    static_files: dict[str, str | tuple[str, str]] | None = None,\n    passthrough_errors: bool = False,\n    ssl_context: _TSSLContextArg | None = None,\n) -> None:\n    \"\"\"Start a development server for a WSGI application. Various\n    optional features can be enabled.\n\n    .. warning::\n\n        Do not use the development server when deploying to production.\n        It is intended for use only during local development. It is not\n        designed to be particularly efficient, stable, or secure.\n\n    :param hostname: The host to bind to, for example ``'localhost'``.\n        Can be a domain, IPv4 or IPv6 address, or file path starting\n        with ``unix://`` for a Unix socket.\n    :param port: The port to bind to, for example ``8080``. Using ``0``\n        tells the OS to pick a random free port.\n    :param application: The WSGI application to run.\n    :param use_reloader: Use a reloader process to restart the server\n        process when files are changed.\n    :param use_debugger: Use Werkzeug's debugger, which will show\n        formatted tracebacks on unhandled exceptions.\n    :param use_evalex: Make the debugger interactive. A Python terminal\n        can be opened for any frame in the traceback. Some protection is\n        provided by requiring a PIN, but this should never be enabled\n        on a publicly visible server.\n    :param extra_files: The reloader will watch these files for changes\n        in addition to Python modules. For example, watch a\n        configuration file.\n    :param exclude_patterns: The reloader will ignore changes to any\n        files matching these :mod:`fnmatch` patterns. For example,\n        ignore cache files.\n    :param reloader_interval: How often the reloader tries to check for\n        changes.\n    :param reloader_type: The reloader to use. The ``'stat'`` reloader\n        is built in, but may require significant CPU to watch files. The\n        ``'watchdog'`` reloader is much more efficient but requires\n        installing the ``watchdog`` package first.\n    :param threaded: Handle concurrent requests using threads. Cannot be\n        used with ``processes``.\n    :param processes: Handle concurrent requests using up to this number\n        of processes. Cannot be used with ``threaded``.\n    :param request_handler: Use a different\n        :class:`~BaseHTTPServer.BaseHTTPRequestHandler` subclass to\n        handle requests.\n    :param static_files: A dict mapping URL prefixes to directories to\n        serve static files from using\n        :class:`~werkzeug.middleware.SharedDataMiddleware`.\n    :param passthrough_errors: Don't catch unhandled exceptions at the\n        server level, let the server crash instead. If ``use_debugger``\n        is enabled, the debugger will still catch such errors.\n    :param ssl_context: Configure TLS to serve over HTTPS. Can be an\n        :class:`ssl.SSLContext` object, a ``(cert_file, key_file)``\n        tuple to create a typical context, or the string ``'adhoc'`` to\n        generate a temporary self-signed certificate.\n\n    .. versionchanged:: 2.1\n        Instructions are shown for dealing with an \"address already in\n        use\" error.\n\n    .. versionchanged:: 2.1\n        Running on ``0.0.0.0`` or ``::`` shows the loopback IP in\n        addition to a real IP.\n\n    .. versionchanged:: 2.1\n        The command-line interface was removed.\n\n    .. versionchanged:: 2.0\n        Running on ``0.0.0.0`` or ``::`` shows a real IP address that\n        was bound as well as a warning not to run the development server\n        in production.\n\n    .. versionchanged:: 2.0\n        The ``exclude_patterns`` parameter was added.\n\n    .. versionchanged:: 0.15\n        Bind to a Unix socket by passing a ``hostname`` that starts with\n        ``unix://``.\n\n    .. versionchanged:: 0.10\n        Improved the reloader and added support for changing the backend\n        through the ``reloader_type`` parameter.\n\n    .. versionchanged:: 0.9\n        A command-line interface was added.\n\n    .. versionchanged:: 0.8\n        ``ssl_context`` can be a tuple of paths to the certificate and\n        private key files.\n\n    .. versionchanged:: 0.6\n        The ``ssl_context`` parameter was added.\n\n    .. versionchanged:: 0.5\n       The ``static_files`` and ``passthrough_errors`` parameters were\n       added.\n    \"\"\"\n    if not isinstance(port, int):\n        raise TypeError(\"port must be an integer\")\n\n    if static_files:\n        from .middleware.shared_data import SharedDataMiddleware\n\n        application = SharedDataMiddleware(application, static_files)\n\n    if use_debugger:\n        from .debug import DebuggedApplication\n\n        application = DebuggedApplication(application, evalex=use_evalex)\n        # Allow the specified hostname to use the debugger, in addition to\n        # localhost domains.\n        application.trusted_hosts.append(hostname)\n\n    if not is_running_from_reloader():\n        fd = None\n    else:\n        fd = int(os.environ[\"WERKZEUG_SERVER_FD\"])\n\n    srv = make_server(\n        hostname,\n        port,\n        application,\n        threaded,\n        processes,\n        request_handler,\n        passthrough_errors,\n        ssl_context,\n        fd=fd,\n    )\n    srv.socket.set_inheritable(True)\n    os.environ[\"WERKZEUG_SERVER_FD\"] = str(srv.fileno())\n\n    if not is_running_from_reloader():\n        srv.log_startup()\n        _log(\"info\", _ansi_style(\"Press CTRL+C to quit\", \"yellow\"))\n\n    if use_reloader:\n        from ._reloader import run_with_reloader\n\n        try:\n            run_with_reloader(\n                srv.serve_forever,\n                extra_files=extra_files,\n                exclude_patterns=exclude_patterns,\n                interval=reloader_interval,\n                reloader_type=reloader_type,\n            )\n        finally:\n            srv.server_close()\n    else:\n        srv.serve_forever()\n", 1125], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py": ["from __future__ import annotations\n\nimport codecs\nimport collections.abc as cabc\nimport io\nimport os\nimport re\nimport sys\nimport typing as t\nfrom types import TracebackType\nfrom weakref import WeakKeyDictionary\n\nCYGWIN = sys.platform.startswith(\"cygwin\")\nWIN = sys.platform.startswith(\"win\")\nauto_wrap_for_ansi: t.Callable[[t.TextIO], t.TextIO] | None = None\n_ansi_re = re.compile(r\"\\033\\[[;?0-9]*[a-zA-Z]\")\n\n\ndef _make_text_stream(\n    stream: t.BinaryIO,\n    encoding: str | None,\n    errors: str | None,\n    force_readable: bool = False,\n    force_writable: bool = False,\n) -> t.TextIO:\n    if encoding is None:\n        encoding = get_best_encoding(stream)\n    if errors is None:\n        errors = \"replace\"\n    return _NonClosingTextIOWrapper(\n        stream,\n        encoding,\n        errors,\n        line_buffering=True,\n        force_readable=force_readable,\n        force_writable=force_writable,\n    )\n\n\ndef is_ascii_encoding(encoding: str) -> bool:\n    \"\"\"Checks if a given encoding is ascii.\"\"\"\n    try:\n        return codecs.lookup(encoding).name == \"ascii\"\n    except LookupError:\n        return False\n\n\ndef get_best_encoding(stream: t.IO[t.Any]) -> str:\n    \"\"\"Returns the default stream encoding if not found.\"\"\"\n    rv = getattr(stream, \"encoding\", None) or sys.getdefaultencoding()\n    if is_ascii_encoding(rv):\n        return \"utf-8\"\n    return rv\n\n\nclass _NonClosingTextIOWrapper(io.TextIOWrapper):\n    def __init__(\n        self,\n        stream: t.BinaryIO,\n        encoding: str | None,\n        errors: str | None,\n        force_readable: bool = False,\n        force_writable: bool = False,\n        **extra: t.Any,\n    ) -> None:\n        self._stream = stream = t.cast(\n            t.BinaryIO, _FixupStream(stream, force_readable, force_writable)\n        )\n        super().__init__(stream, encoding, errors, **extra)\n\n    def __del__(self) -> None:\n        try:\n            self.detach()\n        except Exception:\n            pass\n\n    def isatty(self) -> bool:\n        # https://bitbucket.org/pypy/pypy/issue/1803\n        return self._stream.isatty()\n\n\nclass _FixupStream:\n    \"\"\"The new io interface needs more from streams than streams\n    traditionally implement.  As such, this fix-up code is necessary in\n    some circumstances.\n\n    The forcing of readable and writable flags are there because some tools\n    put badly patched objects on sys (one such offender are certain version\n    of jupyter notebook).\n    \"\"\"\n\n    def __init__(\n        self,\n        stream: t.BinaryIO,\n        force_readable: bool = False,\n        force_writable: bool = False,\n    ):\n        self._stream = stream\n        self._force_readable = force_readable\n        self._force_writable = force_writable\n\n    def __getattr__(self, name: str) -> t.Any:\n        return getattr(self._stream, name)\n\n    def read1(self, size: int) -> bytes:\n        f = getattr(self._stream, \"read1\", None)\n\n        if f is not None:\n            return t.cast(bytes, f(size))\n\n        return self._stream.read(size)\n\n    def readable(self) -> bool:\n        if self._force_readable:\n            return True\n        x = getattr(self._stream, \"readable\", None)\n        if x is not None:\n            return t.cast(bool, x())\n        try:\n            self._stream.read(0)\n        except Exception:\n            return False\n        return True\n\n    def writable(self) -> bool:\n        if self._force_writable:\n            return True\n        x = getattr(self._stream, \"writable\", None)\n        if x is not None:\n            return t.cast(bool, x())\n        try:\n            self._stream.write(b\"\")\n        except Exception:\n            try:\n                self._stream.write(b\"\")\n            except Exception:\n                return False\n        return True\n\n    def seekable(self) -> bool:\n        x = getattr(self._stream, \"seekable\", None)\n        if x is not None:\n            return t.cast(bool, x())\n        try:\n            self._stream.seek(self._stream.tell())\n        except Exception:\n            return False\n        return True\n\n\ndef _is_binary_reader(stream: t.IO[t.Any], default: bool = False) -> bool:\n    try:\n        return isinstance(stream.read(0), bytes)\n    except Exception:\n        return default\n        # This happens in some cases where the stream was already\n        # closed.  In this case, we assume the default.\n\n\ndef _is_binary_writer(stream: t.IO[t.Any], default: bool = False) -> bool:\n    try:\n        stream.write(b\"\")\n    except Exception:\n        try:\n            stream.write(\"\")\n            return False\n        except Exception:\n            pass\n        return default\n    return True\n\n\ndef _find_binary_reader(stream: t.IO[t.Any]) -> t.BinaryIO | None:\n    # We need to figure out if the given stream is already binary.\n    # This can happen because the official docs recommend detaching\n    # the streams to get binary streams.  Some code might do this, so\n    # we need to deal with this case explicitly.\n    if _is_binary_reader(stream, False):\n        return t.cast(t.BinaryIO, stream)\n\n    buf = getattr(stream, \"buffer\", None)\n\n    # Same situation here; this time we assume that the buffer is\n    # actually binary in case it's closed.\n    if buf is not None and _is_binary_reader(buf, True):\n        return t.cast(t.BinaryIO, buf)\n\n    return None\n\n\ndef _find_binary_writer(stream: t.IO[t.Any]) -> t.BinaryIO | None:\n    # We need to figure out if the given stream is already binary.\n    # This can happen because the official docs recommend detaching\n    # the streams to get binary streams.  Some code might do this, so\n    # we need to deal with this case explicitly.\n    if _is_binary_writer(stream, False):\n        return t.cast(t.BinaryIO, stream)\n\n    buf = getattr(stream, \"buffer\", None)\n\n    # Same situation here; this time we assume that the buffer is\n    # actually binary in case it's closed.\n    if buf is not None and _is_binary_writer(buf, True):\n        return t.cast(t.BinaryIO, buf)\n\n    return None\n\n\ndef _stream_is_misconfigured(stream: t.TextIO) -> bool:\n    \"\"\"A stream is misconfigured if its encoding is ASCII.\"\"\"\n    # If the stream does not have an encoding set, we assume it's set\n    # to ASCII.  This appears to happen in certain unittest\n    # environments.  It's not quite clear what the correct behavior is\n    # but this at least will force Click to recover somehow.\n    return is_ascii_encoding(getattr(stream, \"encoding\", None) or \"ascii\")\n\n\ndef _is_compat_stream_attr(stream: t.TextIO, attr: str, value: str | None) -> bool:\n    \"\"\"A stream attribute is compatible if it is equal to the\n    desired value or the desired value is unset and the attribute\n    has a value.\n    \"\"\"\n    stream_value = getattr(stream, attr, None)\n    return stream_value == value or (value is None and stream_value is not None)\n\n\ndef _is_compatible_text_stream(\n    stream: t.TextIO, encoding: str | None, errors: str | None\n) -> bool:\n    \"\"\"Check if a stream's encoding and errors attributes are\n    compatible with the desired values.\n    \"\"\"\n    return _is_compat_stream_attr(\n        stream, \"encoding\", encoding\n    ) and _is_compat_stream_attr(stream, \"errors\", errors)\n\n\ndef _force_correct_text_stream(\n    text_stream: t.IO[t.Any],\n    encoding: str | None,\n    errors: str | None,\n    is_binary: t.Callable[[t.IO[t.Any], bool], bool],\n    find_binary: t.Callable[[t.IO[t.Any]], t.BinaryIO | None],\n    force_readable: bool = False,\n    force_writable: bool = False,\n) -> t.TextIO:\n    if is_binary(text_stream, False):\n        binary_reader = t.cast(t.BinaryIO, text_stream)\n    else:\n        text_stream = t.cast(t.TextIO, text_stream)\n        # If the stream looks compatible, and won't default to a\n        # misconfigured ascii encoding, return it as-is.\n        if _is_compatible_text_stream(text_stream, encoding, errors) and not (\n            encoding is None and _stream_is_misconfigured(text_stream)\n        ):\n            return text_stream\n\n        # Otherwise, get the underlying binary reader.\n        possible_binary_reader = find_binary(text_stream)\n\n        # If that's not possible, silently use the original reader\n        # and get mojibake instead of exceptions.\n        if possible_binary_reader is None:\n            return text_stream\n\n        binary_reader = possible_binary_reader\n\n    # Default errors to replace instead of strict in order to get\n    # something that works.\n    if errors is None:\n        errors = \"replace\"\n\n    # Wrap the binary stream in a text stream with the correct\n    # encoding parameters.\n    return _make_text_stream(\n        binary_reader,\n        encoding,\n        errors,\n        force_readable=force_readable,\n        force_writable=force_writable,\n    )\n\n\ndef _force_correct_text_reader(\n    text_reader: t.IO[t.Any],\n    encoding: str | None,\n    errors: str | None,\n    force_readable: bool = False,\n) -> t.TextIO:\n    return _force_correct_text_stream(\n        text_reader,\n        encoding,\n        errors,\n        _is_binary_reader,\n        _find_binary_reader,\n        force_readable=force_readable,\n    )\n\n\ndef _force_correct_text_writer(\n    text_writer: t.IO[t.Any],\n    encoding: str | None,\n    errors: str | None,\n    force_writable: bool = False,\n) -> t.TextIO:\n    return _force_correct_text_stream(\n        text_writer,\n        encoding,\n        errors,\n        _is_binary_writer,\n        _find_binary_writer,\n        force_writable=force_writable,\n    )\n\n\ndef get_binary_stdin() -> t.BinaryIO:\n    reader = _find_binary_reader(sys.stdin)\n    if reader is None:\n        raise RuntimeError(\"Was not able to determine binary stream for sys.stdin.\")\n    return reader\n\n\ndef get_binary_stdout() -> t.BinaryIO:\n    writer = _find_binary_writer(sys.stdout)\n    if writer is None:\n        raise RuntimeError(\"Was not able to determine binary stream for sys.stdout.\")\n    return writer\n\n\ndef get_binary_stderr() -> t.BinaryIO:\n    writer = _find_binary_writer(sys.stderr)\n    if writer is None:\n        raise RuntimeError(\"Was not able to determine binary stream for sys.stderr.\")\n    return writer\n\n\ndef get_text_stdin(encoding: str | None = None, errors: str | None = None) -> t.TextIO:\n    rv = _get_windows_console_stream(sys.stdin, encoding, errors)\n    if rv is not None:\n        return rv\n    return _force_correct_text_reader(sys.stdin, encoding, errors, force_readable=True)\n\n\ndef get_text_stdout(encoding: str | None = None, errors: str | None = None) -> t.TextIO:\n    rv = _get_windows_console_stream(sys.stdout, encoding, errors)\n    if rv is not None:\n        return rv\n    return _force_correct_text_writer(sys.stdout, encoding, errors, force_writable=True)\n\n\ndef get_text_stderr(encoding: str | None = None, errors: str | None = None) -> t.TextIO:\n    rv = _get_windows_console_stream(sys.stderr, encoding, errors)\n    if rv is not None:\n        return rv\n    return _force_correct_text_writer(sys.stderr, encoding, errors, force_writable=True)\n\n\ndef _wrap_io_open(\n    file: str | os.PathLike[str] | int,\n    mode: str,\n    encoding: str | None,\n    errors: str | None,\n) -> t.IO[t.Any]:\n    \"\"\"Handles not passing ``encoding`` and ``errors`` in binary mode.\"\"\"\n    if \"b\" in mode:\n        return open(file, mode)\n\n    return open(file, mode, encoding=encoding, errors=errors)\n\n\ndef open_stream(\n    filename: str | os.PathLike[str],\n    mode: str = \"r\",\n    encoding: str | None = None,\n    errors: str | None = \"strict\",\n    atomic: bool = False,\n) -> tuple[t.IO[t.Any], bool]:\n    binary = \"b\" in mode\n    filename = os.fspath(filename)\n\n    # Standard streams first. These are simple because they ignore the\n    # atomic flag. Use fsdecode to handle Path(\"-\").\n    if os.fsdecode(filename) == \"-\":\n        if any(m in mode for m in [\"w\", \"a\", \"x\"]):\n            if binary:\n                return get_binary_stdout(), False\n            return get_text_stdout(encoding=encoding, errors=errors), False\n        if binary:\n            return get_binary_stdin(), False\n        return get_text_stdin(encoding=encoding, errors=errors), False\n\n    # Non-atomic writes directly go out through the regular open functions.\n    if not atomic:\n        return _wrap_io_open(filename, mode, encoding, errors), True\n\n    # Some usability stuff for atomic writes\n    if \"a\" in mode:\n        raise ValueError(\n            \"Appending to an existing file is not supported, because that\"\n            \" would involve an expensive `copy`-operation to a temporary\"\n            \" file. Open the file in normal `w`-mode and copy explicitly\"\n            \" if that's what you're after.\"\n        )\n    if \"x\" in mode:\n        raise ValueError(\"Use the `overwrite`-parameter instead.\")\n    if \"w\" not in mode:\n        raise ValueError(\"Atomic writes only make sense with `w`-mode.\")\n\n    # Atomic writes are more complicated.  They work by opening a file\n    # as a proxy in the same folder and then using the fdopen\n    # functionality to wrap it in a Python file.  Then we wrap it in an\n    # atomic file that moves the file over on close.\n    import errno\n    import random\n\n    try:\n        perm: int | None = os.stat(filename).st_mode\n    except OSError:\n        perm = None\n\n    flags = os.O_RDWR | os.O_CREAT | os.O_EXCL\n\n    if binary:\n        flags |= getattr(os, \"O_BINARY\", 0)\n\n    while True:\n        tmp_filename = os.path.join(\n            os.path.dirname(filename),\n            f\".__atomic-write{random.randrange(1 << 32):08x}\",\n        )\n        try:\n            fd = os.open(tmp_filename, flags, 0o666 if perm is None else perm)\n            break\n        except OSError as e:\n            if e.errno == errno.EEXIST or (\n                os.name == \"nt\"\n                and e.errno == errno.EACCES\n                and os.path.isdir(e.filename)\n                and os.access(e.filename, os.W_OK)\n            ):\n                continue\n            raise\n\n    if perm is not None:\n        os.chmod(tmp_filename, perm)  # in case perm includes bits in umask\n\n    f = _wrap_io_open(fd, mode, encoding, errors)\n    af = _AtomicFile(f, tmp_filename, os.path.realpath(filename))\n    return t.cast(t.IO[t.Any], af), True\n\n\nclass _AtomicFile:\n    def __init__(self, f: t.IO[t.Any], tmp_filename: str, real_filename: str) -> None:\n        self._f = f\n        self._tmp_filename = tmp_filename\n        self._real_filename = real_filename\n        self.closed = False\n\n    @property\n    def name(self) -> str:\n        return self._real_filename\n\n    def close(self, delete: bool = False) -> None:\n        if self.closed:\n            return\n        self._f.close()\n        os.replace(self._tmp_filename, self._real_filename)\n        self.closed = True\n\n    def __getattr__(self, name: str) -> t.Any:\n        return getattr(self._f, name)\n\n    def __enter__(self) -> _AtomicFile:\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.close(delete=exc_type is not None)\n\n    def __repr__(self) -> str:\n        return repr(self._f)\n\n\ndef strip_ansi(value: str) -> str:\n    return _ansi_re.sub(\"\", value)\n\n\ndef _is_jupyter_kernel_output(stream: t.IO[t.Any]) -> bool:\n    while isinstance(stream, (_FixupStream, _NonClosingTextIOWrapper)):\n        stream = stream._stream\n\n    return stream.__class__.__module__.startswith(\"ipykernel.\")\n\n\ndef should_strip_ansi(\n    stream: t.IO[t.Any] | None = None, color: bool | None = None\n) -> bool:\n    if color is None:\n        if stream is None:\n            stream = sys.stdin\n        return not isatty(stream) and not _is_jupyter_kernel_output(stream)\n    return not color\n\n\n# On Windows, wrap the output streams with colorama to support ANSI\n# color codes.\n# NOTE: double check is needed so mypy does not analyze this on Linux\nif sys.platform.startswith(\"win\") and WIN:\n    from ._winconsole import _get_windows_console_stream\n\n    def _get_argv_encoding() -> str:\n        import locale\n\n        return locale.getpreferredencoding()\n\n    _ansi_stream_wrappers: cabc.MutableMapping[t.TextIO, t.TextIO] = WeakKeyDictionary()\n\n    def auto_wrap_for_ansi(stream: t.TextIO, color: bool | None = None) -> t.TextIO:\n        \"\"\"Support ANSI color and style codes on Windows by wrapping a\n        stream with colorama.\n        \"\"\"\n        try:\n            cached = _ansi_stream_wrappers.get(stream)\n        except Exception:\n            cached = None\n\n        if cached is not None:\n            return cached\n\n        import colorama\n\n        strip = should_strip_ansi(stream, color)\n        ansi_wrapper = colorama.AnsiToWin32(stream, strip=strip)\n        rv = t.cast(t.TextIO, ansi_wrapper.stream)\n        _write = rv.write\n\n        def _safe_write(s: str) -> int:\n            try:\n                return _write(s)\n            except BaseException:\n                ansi_wrapper.reset_all()\n                raise\n\n        rv.write = _safe_write  # type: ignore[method-assign]\n\n        try:\n            _ansi_stream_wrappers[stream] = rv\n        except Exception:\n            pass\n\n        return rv\n\nelse:\n\n    def _get_argv_encoding() -> str:\n        return getattr(sys.stdin, \"encoding\", None) or sys.getfilesystemencoding()\n\n    def _get_windows_console_stream(\n        f: t.TextIO, encoding: str | None, errors: str | None\n    ) -> t.TextIO | None:\n        return None\n\n\ndef term_len(x: str) -> int:\n    return len(strip_ansi(x))\n\n\ndef isatty(stream: t.IO[t.Any]) -> bool:\n    try:\n        return stream.isatty()\n    except Exception:\n        return False\n\n\ndef _make_cached_stream_func(\n    src_func: t.Callable[[], t.TextIO | None],\n    wrapper_func: t.Callable[[], t.TextIO],\n) -> t.Callable[[], t.TextIO | None]:\n    cache: cabc.MutableMapping[t.TextIO, t.TextIO] = WeakKeyDictionary()\n\n    def func() -> t.TextIO | None:\n        stream = src_func()\n\n        if stream is None:\n            return None\n\n        try:\n            rv = cache.get(stream)\n        except Exception:\n            rv = None\n        if rv is not None:\n            return rv\n        rv = wrapper_func()\n        try:\n            cache[stream] = rv\n        except Exception:\n            pass\n        return rv\n\n    return func\n\n\n_default_text_stdin = _make_cached_stream_func(lambda: sys.stdin, get_text_stdin)\n_default_text_stdout = _make_cached_stream_func(lambda: sys.stdout, get_text_stdout)\n_default_text_stderr = _make_cached_stream_func(lambda: sys.stderr, get_text_stderr)\n\n\nbinary_streams: cabc.Mapping[str, t.Callable[[], t.BinaryIO]] = {\n    \"stdin\": get_binary_stdin,\n    \"stdout\": get_binary_stdout,\n    \"stderr\": get_binary_stderr,\n}\n\ntext_streams: cabc.Mapping[str, t.Callable[[str | None, str | None], t.TextIO]] = {\n    \"stdin\": get_text_stdin,\n    \"stdout\": get_text_stdout,\n    \"stderr\": get_text_stderr,\n}\n", 622], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py": ["from __future__ import annotations\n\nimport typing as t\nfrom threading import local\n\nif t.TYPE_CHECKING:\n    from .core import Context\n\n_local = local()\n\n\n@t.overload\ndef get_current_context(silent: t.Literal[False] = False) -> Context: ...\n\n\n@t.overload\ndef get_current_context(silent: bool = ...) -> Context | None: ...\n\n\ndef get_current_context(silent: bool = False) -> Context | None:\n    \"\"\"Returns the current click context.  This can be used as a way to\n    access the current context object from anywhere.  This is a more implicit\n    alternative to the :func:`pass_context` decorator.  This function is\n    primarily useful for helpers such as :func:`echo` which might be\n    interested in changing its behavior based on the current context.\n\n    To push the current context, :meth:`Context.scope` can be used.\n\n    .. versionadded:: 5.0\n\n    :param silent: if set to `True` the return value is `None` if no context\n                   is available.  The default behavior is to raise a\n                   :exc:`RuntimeError`.\n    \"\"\"\n    try:\n        return t.cast(\"Context\", _local.stack[-1])\n    except (AttributeError, IndexError) as e:\n        if not silent:\n            raise RuntimeError(\"There is no active click context.\") from e\n\n    return None\n\n\ndef push_context(ctx: Context) -> None:\n    \"\"\"Pushes a new context to the current stack.\"\"\"\n    _local.__dict__.setdefault(\"stack\", []).append(ctx)\n\n\ndef pop_context() -> None:\n    \"\"\"Removes the top level from the stack.\"\"\"\n    _local.stack.pop()\n\n\ndef resolve_color_default(color: bool | None = None) -> bool | None:\n    \"\"\"Internal helper to get the default value of the color flag.  If a\n    value is passed it's returned unchanged, otherwise it's looked up from\n    the current context.\n    \"\"\"\n    if color is not None:\n        return color\n\n    ctx = get_current_context(silent=True)\n\n    if ctx is not None:\n        return ctx.color\n\n    return None\n", 67], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/utils.py": ["from __future__ import annotations\n\nimport collections.abc as cabc\nimport os\nimport re\nimport sys\nimport typing as t\nfrom functools import update_wrapper\nfrom types import ModuleType\nfrom types import TracebackType\n\nfrom ._compat import _default_text_stderr\nfrom ._compat import _default_text_stdout\nfrom ._compat import _find_binary_writer\nfrom ._compat import auto_wrap_for_ansi\nfrom ._compat import binary_streams\nfrom ._compat import open_stream\nfrom ._compat import should_strip_ansi\nfrom ._compat import strip_ansi\nfrom ._compat import text_streams\nfrom ._compat import WIN\nfrom .globals import resolve_color_default\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    P = te.ParamSpec(\"P\")\n\nR = t.TypeVar(\"R\")\n\n\ndef _posixify(name: str) -> str:\n    return \"-\".join(name.split()).lower()\n\n\ndef safecall(func: t.Callable[P, R]) -> t.Callable[P, R | None]:\n    \"\"\"Wraps a function so that it swallows exceptions.\"\"\"\n\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R | None:\n        try:\n            return func(*args, **kwargs)\n        except Exception:\n            pass\n        return None\n\n    return update_wrapper(wrapper, func)\n\n\ndef make_str(value: t.Any) -> str:\n    \"\"\"Converts a value into a valid string.\"\"\"\n    if isinstance(value, bytes):\n        try:\n            return value.decode(sys.getfilesystemencoding())\n        except UnicodeError:\n            return value.decode(\"utf-8\", \"replace\")\n    return str(value)\n\n\ndef make_default_short_help(help: str, max_length: int = 45) -> str:\n    \"\"\"Returns a condensed version of help string.\"\"\"\n    # Consider only the first paragraph.\n    paragraph_end = help.find(\"\\n\\n\")\n\n    if paragraph_end != -1:\n        help = help[:paragraph_end]\n\n    # Collapse newlines, tabs, and spaces.\n    words = help.split()\n\n    if not words:\n        return \"\"\n\n    # The first paragraph started with a \"no rewrap\" marker, ignore it.\n    if words[0] == \"\\b\":\n        words = words[1:]\n\n    total_length = 0\n    last_index = len(words) - 1\n\n    for i, word in enumerate(words):\n        total_length += len(word) + (i > 0)\n\n        if total_length > max_length:  # too long, truncate\n            break\n\n        if word[-1] == \".\":  # sentence end, truncate without \"...\"\n            return \" \".join(words[: i + 1])\n\n        if total_length == max_length and i != last_index:\n            break  # not at sentence end, truncate with \"...\"\n    else:\n        return \" \".join(words)  # no truncation needed\n\n    # Account for the length of the suffix.\n    total_length += len(\"...\")\n\n    # remove words until the length is short enough\n    while i > 0:\n        total_length -= len(words[i]) + (i > 0)\n\n        if total_length <= max_length:\n            break\n\n        i -= 1\n\n    return \" \".join(words[:i]) + \"...\"\n\n\nclass LazyFile:\n    \"\"\"A lazy file works like a regular file but it does not fully open\n    the file but it does perform some basic checks early to see if the\n    filename parameter does make sense.  This is useful for safely opening\n    files for writing.\n    \"\"\"\n\n    def __init__(\n        self,\n        filename: str | os.PathLike[str],\n        mode: str = \"r\",\n        encoding: str | None = None,\n        errors: str | None = \"strict\",\n        atomic: bool = False,\n    ):\n        self.name: str = os.fspath(filename)\n        self.mode = mode\n        self.encoding = encoding\n        self.errors = errors\n        self.atomic = atomic\n        self._f: t.IO[t.Any] | None\n        self.should_close: bool\n\n        if self.name == \"-\":\n            self._f, self.should_close = open_stream(filename, mode, encoding, errors)\n        else:\n            if \"r\" in mode:\n                # Open and close the file in case we're opening it for\n                # reading so that we can catch at least some errors in\n                # some cases early.\n                open(filename, mode).close()\n            self._f = None\n            self.should_close = True\n\n    def __getattr__(self, name: str) -> t.Any:\n        return getattr(self.open(), name)\n\n    def __repr__(self) -> str:\n        if self._f is not None:\n            return repr(self._f)\n        return f\"<unopened file '{format_filename(self.name)}' {self.mode}>\"\n\n    def open(self) -> t.IO[t.Any]:\n        \"\"\"Opens the file if it's not yet open.  This call might fail with\n        a :exc:`FileError`.  Not handling this error will produce an error\n        that Click shows.\n        \"\"\"\n        if self._f is not None:\n            return self._f\n        try:\n            rv, self.should_close = open_stream(\n                self.name, self.mode, self.encoding, self.errors, atomic=self.atomic\n            )\n        except OSError as e:\n            from .exceptions import FileError\n\n            raise FileError(self.name, hint=e.strerror) from e\n        self._f = rv\n        return rv\n\n    def close(self) -> None:\n        \"\"\"Closes the underlying file, no matter what.\"\"\"\n        if self._f is not None:\n            self._f.close()\n\n    def close_intelligently(self) -> None:\n        \"\"\"This function only closes the file if it was opened by the lazy\n        file wrapper.  For instance this will never close stdin.\n        \"\"\"\n        if self.should_close:\n            self.close()\n\n    def __enter__(self) -> LazyFile:\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.close_intelligently()\n\n    def __iter__(self) -> cabc.Iterator[t.AnyStr]:\n        self.open()\n        return iter(self._f)  # type: ignore\n\n\nclass KeepOpenFile:\n    def __init__(self, file: t.IO[t.Any]) -> None:\n        self._file: t.IO[t.Any] = file\n\n    def __getattr__(self, name: str) -> t.Any:\n        return getattr(self._file, name)\n\n    def __enter__(self) -> KeepOpenFile:\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        pass\n\n    def __repr__(self) -> str:\n        return repr(self._file)\n\n    def __iter__(self) -> cabc.Iterator[t.AnyStr]:\n        return iter(self._file)\n\n\ndef echo(\n    message: t.Any | None = None,\n    file: t.IO[t.Any] | None = None,\n    nl: bool = True,\n    err: bool = False,\n    color: bool | None = None,\n) -> None:\n    \"\"\"Print a message and newline to stdout or a file. This should be\n    used instead of :func:`print` because it provides better support\n    for different data, files, and environments.\n\n    Compared to :func:`print`, this does the following:\n\n    -   Ensures that the output encoding is not misconfigured on Linux.\n    -   Supports Unicode in the Windows console.\n    -   Supports writing to binary outputs, and supports writing bytes\n        to text outputs.\n    -   Supports colors and styles on Windows.\n    -   Removes ANSI color and style codes if the output does not look\n        like an interactive terminal.\n    -   Always flushes the output.\n\n    :param message: The string or bytes to output. Other objects are\n        converted to strings.\n    :param file: The file to write to. Defaults to ``stdout``.\n    :param err: Write to ``stderr`` instead of ``stdout``.\n    :param nl: Print a newline after the message. Enabled by default.\n    :param color: Force showing or hiding colors and other styles. By\n        default Click will remove color if the output does not look like\n        an interactive terminal.\n\n    .. versionchanged:: 6.0\n        Support Unicode output on the Windows console. Click does not\n        modify ``sys.stdout``, so ``sys.stdout.write()`` and ``print()``\n        will still not support Unicode.\n\n    .. versionchanged:: 4.0\n        Added the ``color`` parameter.\n\n    .. versionadded:: 3.0\n        Added the ``err`` parameter.\n\n    .. versionchanged:: 2.0\n        Support colors on Windows if colorama is installed.\n    \"\"\"\n    if file is None:\n        if err:\n            file = _default_text_stderr()\n        else:\n            file = _default_text_stdout()\n\n        # There are no standard streams attached to write to. For example,\n        # pythonw on Windows.\n        if file is None:\n            return\n\n    # Convert non bytes/text into the native string type.\n    if message is not None and not isinstance(message, (str, bytes, bytearray)):\n        out: str | bytes | None = str(message)\n    else:\n        out = message\n\n    if nl:\n        out = out or \"\"\n        if isinstance(out, str):\n            out += \"\\n\"\n        else:\n            out += b\"\\n\"\n\n    if not out:\n        file.flush()\n        return\n\n    # If there is a message and the value looks like bytes, we manually\n    # need to find the binary stream and write the message in there.\n    # This is done separately so that most stream types will work as you\n    # would expect. Eg: you can write to StringIO for other cases.\n    if isinstance(out, (bytes, bytearray)):\n        binary_file = _find_binary_writer(file)\n\n        if binary_file is not None:\n            file.flush()\n            binary_file.write(out)\n            binary_file.flush()\n            return\n\n    # ANSI style code support. For no message or bytes, nothing happens.\n    # When outputting to a file instead of a terminal, strip codes.\n    else:\n        color = resolve_color_default(color)\n\n        if should_strip_ansi(file, color):\n            out = strip_ansi(out)\n        elif WIN:\n            if auto_wrap_for_ansi is not None:\n                file = auto_wrap_for_ansi(file, color)  # type: ignore\n            elif not color:\n                out = strip_ansi(out)\n\n    file.write(out)  # type: ignore\n    file.flush()\n\n\ndef get_binary_stream(name: t.Literal[\"stdin\", \"stdout\", \"stderr\"]) -> t.BinaryIO:\n    \"\"\"Returns a system stream for byte processing.\n\n    :param name: the name of the stream to open.  Valid names are ``'stdin'``,\n                 ``'stdout'`` and ``'stderr'``\n    \"\"\"\n    opener = binary_streams.get(name)\n    if opener is None:\n        raise TypeError(f\"Unknown standard stream '{name}'\")\n    return opener()\n\n\ndef get_text_stream(\n    name: t.Literal[\"stdin\", \"stdout\", \"stderr\"],\n    encoding: str | None = None,\n    errors: str | None = \"strict\",\n) -> t.TextIO:\n    \"\"\"Returns a system stream for text processing.  This usually returns\n    a wrapped stream around a binary stream returned from\n    :func:`get_binary_stream` but it also can take shortcuts for already\n    correctly configured streams.\n\n    :param name: the name of the stream to open.  Valid names are ``'stdin'``,\n                 ``'stdout'`` and ``'stderr'``\n    :param encoding: overrides the detected default encoding.\n    :param errors: overrides the default error mode.\n    \"\"\"\n    opener = text_streams.get(name)\n    if opener is None:\n        raise TypeError(f\"Unknown standard stream '{name}'\")\n    return opener(encoding, errors)\n\n\ndef open_file(\n    filename: str | os.PathLike[str],\n    mode: str = \"r\",\n    encoding: str | None = None,\n    errors: str | None = \"strict\",\n    lazy: bool = False,\n    atomic: bool = False,\n) -> t.IO[t.Any]:\n    \"\"\"Open a file, with extra behavior to handle ``'-'`` to indicate\n    a standard stream, lazy open on write, and atomic write. Similar to\n    the behavior of the :class:`~click.File` param type.\n\n    If ``'-'`` is given to open ``stdout`` or ``stdin``, the stream is\n    wrapped so that using it in a context manager will not close it.\n    This makes it possible to use the function without accidentally\n    closing a standard stream:\n\n    .. code-block:: python\n\n        with open_file(filename) as f:\n            ...\n\n    :param filename: The name or Path of the file to open, or ``'-'`` for\n        ``stdin``/``stdout``.\n    :param mode: The mode in which to open the file.\n    :param encoding: The encoding to decode or encode a file opened in\n        text mode.\n    :param errors: The error handling mode.\n    :param lazy: Wait to open the file until it is accessed. For read\n        mode, the file is temporarily opened to raise access errors\n        early, then closed until it is read again.\n    :param atomic: Write to a temporary file and replace the given file\n        on close.\n\n    .. versionadded:: 3.0\n    \"\"\"\n    if lazy:\n        return t.cast(\n            \"t.IO[t.Any]\", LazyFile(filename, mode, encoding, errors, atomic=atomic)\n        )\n\n    f, should_close = open_stream(filename, mode, encoding, errors, atomic=atomic)\n\n    if not should_close:\n        f = t.cast(\"t.IO[t.Any]\", KeepOpenFile(f))\n\n    return f\n\n\ndef format_filename(\n    filename: str | bytes | os.PathLike[str] | os.PathLike[bytes],\n    shorten: bool = False,\n) -> str:\n    \"\"\"Format a filename as a string for display. Ensures the filename can be\n    displayed by replacing any invalid bytes or surrogate escapes in the name\n    with the replacement character ``\ufffd``.\n\n    Invalid bytes or surrogate escapes will raise an error when written to a\n    stream with ``errors=\"strict\"``. This will typically happen with ``stdout``\n    when the locale is something like ``en_GB.UTF-8``.\n\n    Many scenarios *are* safe to write surrogates though, due to PEP 538 and\n    PEP 540, including:\n\n    -   Writing to ``stderr``, which uses ``errors=\"backslashreplace\"``.\n    -   The system has ``LANG=C.UTF-8``, ``C``, or ``POSIX``. Python opens\n        stdout and stderr with ``errors=\"surrogateescape\"``.\n    -   None of ``LANG/LC_*`` are set. Python assumes ``LANG=C.UTF-8``.\n    -   Python is started in UTF-8 mode  with  ``PYTHONUTF8=1`` or ``-X utf8``.\n        Python opens stdout and stderr with ``errors=\"surrogateescape\"``.\n\n    :param filename: formats a filename for UI display.  This will also convert\n                     the filename into unicode without failing.\n    :param shorten: this optionally shortens the filename to strip of the\n                    path that leads up to it.\n    \"\"\"\n    if shorten:\n        filename = os.path.basename(filename)\n    else:\n        filename = os.fspath(filename)\n\n    if isinstance(filename, bytes):\n        filename = filename.decode(sys.getfilesystemencoding(), \"replace\")\n    else:\n        filename = filename.encode(\"utf-8\", \"surrogateescape\").decode(\n            \"utf-8\", \"replace\"\n        )\n\n    return filename\n\n\ndef get_app_dir(app_name: str, roaming: bool = True, force_posix: bool = False) -> str:\n    r\"\"\"Returns the config folder for the application.  The default behavior\n    is to return whatever is most appropriate for the operating system.\n\n    To give you an idea, for an app called ``\"Foo Bar\"``, something like\n    the following folders could be returned:\n\n    Mac OS X:\n      ``~/Library/Application Support/Foo Bar``\n    Mac OS X (POSIX):\n      ``~/.foo-bar``\n    Unix:\n      ``~/.config/foo-bar``\n    Unix (POSIX):\n      ``~/.foo-bar``\n    Windows (roaming):\n      ``C:\\Users\\<user>\\AppData\\Roaming\\Foo Bar``\n    Windows (not roaming):\n      ``C:\\Users\\<user>\\AppData\\Local\\Foo Bar``\n\n    .. versionadded:: 2.0\n\n    :param app_name: the application name.  This should be properly capitalized\n                     and can contain whitespace.\n    :param roaming: controls if the folder should be roaming or not on Windows.\n                    Has no effect otherwise.\n    :param force_posix: if this is set to `True` then on any POSIX system the\n                        folder will be stored in the home folder with a leading\n                        dot instead of the XDG config home or darwin's\n                        application support folder.\n    \"\"\"\n    if WIN:\n        key = \"APPDATA\" if roaming else \"LOCALAPPDATA\"\n        folder = os.environ.get(key)\n        if folder is None:\n            folder = os.path.expanduser(\"~\")\n        return os.path.join(folder, app_name)\n    if force_posix:\n        return os.path.join(os.path.expanduser(f\"~/.{_posixify(app_name)}\"))\n    if sys.platform == \"darwin\":\n        return os.path.join(\n            os.path.expanduser(\"~/Library/Application Support\"), app_name\n        )\n    return os.path.join(\n        os.environ.get(\"XDG_CONFIG_HOME\", os.path.expanduser(\"~/.config\")),\n        _posixify(app_name),\n    )\n\n\nclass PacifyFlushWrapper:\n    \"\"\"This wrapper is used to catch and suppress BrokenPipeErrors resulting\n    from ``.flush()`` being called on broken pipe during the shutdown/final-GC\n    of the Python interpreter. Notably ``.flush()`` is always called on\n    ``sys.stdout`` and ``sys.stderr``. So as to have minimal impact on any\n    other cleanup code, and the case where the underlying file is not a broken\n    pipe, all calls and attributes are proxied.\n    \"\"\"\n\n    def __init__(self, wrapped: t.IO[t.Any]) -> None:\n        self.wrapped = wrapped\n\n    def flush(self) -> None:\n        try:\n            self.wrapped.flush()\n        except OSError as e:\n            import errno\n\n            if e.errno != errno.EPIPE:\n                raise\n\n    def __getattr__(self, attr: str) -> t.Any:\n        return getattr(self.wrapped, attr)\n\n\ndef _detect_program_name(\n    path: str | None = None, _main: ModuleType | None = None\n) -> str:\n    \"\"\"Determine the command used to run the program, for use in help\n    text. If a file or entry point was executed, the file name is\n    returned. If ``python -m`` was used to execute a module or package,\n    ``python -m name`` is returned.\n\n    This doesn't try to be too precise, the goal is to give a concise\n    name for help text. Files are only shown as their name without the\n    path. ``python`` is only shown for modules, and the full path to\n    ``sys.executable`` is not shown.\n\n    :param path: The Python file being executed. Python puts this in\n        ``sys.argv[0]``, which is used by default.\n    :param _main: The ``__main__`` module. This should only be passed\n        during internal testing.\n\n    .. versionadded:: 8.0\n        Based on command args detection in the Werkzeug reloader.\n\n    :meta private:\n    \"\"\"\n    if _main is None:\n        _main = sys.modules[\"__main__\"]\n\n    if not path:\n        path = sys.argv[0]\n\n    # The value of __package__ indicates how Python was called. It may\n    # not exist if a setuptools script is installed as an egg. It may be\n    # set incorrectly for entry points created with pip on Windows.\n    # It is set to \"\" inside a Shiv or PEX zipapp.\n    if getattr(_main, \"__package__\", None) in {None, \"\"} or (\n        os.name == \"nt\"\n        and _main.__package__ == \"\"\n        and not os.path.exists(path)\n        and os.path.exists(f\"{path}.exe\")\n    ):\n        # Executed a file, like \"python app.py\".\n        return os.path.basename(path)\n\n    # Executed a module, like \"python -m example\".\n    # Rewritten by Python from \"-m script\" to \"/path/to/script.py\".\n    # Need to look at main module to determine how it was executed.\n    py_module = t.cast(str, _main.__package__)\n    name = os.path.splitext(os.path.basename(path))[0]\n\n    # A submodule like \"example.cli\".\n    if name != \"__main__\":\n        py_module = f\"{py_module}.{name}\"\n\n    return f\"python -m {py_module.lstrip('.')}\"\n\n\ndef _expand_args(\n    args: cabc.Iterable[str],\n    *,\n    user: bool = True,\n    env: bool = True,\n    glob_recursive: bool = True,\n) -> list[str]:\n    \"\"\"Simulate Unix shell expansion with Python functions.\n\n    See :func:`glob.glob`, :func:`os.path.expanduser`, and\n    :func:`os.path.expandvars`.\n\n    This is intended for use on Windows, where the shell does not do any\n    expansion. It may not exactly match what a Unix shell would do.\n\n    :param args: List of command line arguments to expand.\n    :param user: Expand user home directory.\n    :param env: Expand environment variables.\n    :param glob_recursive: ``**`` matches directories recursively.\n\n    .. versionchanged:: 8.1\n        Invalid glob patterns are treated as empty expansions rather\n        than raising an error.\n\n    .. versionadded:: 8.0\n\n    :meta private:\n    \"\"\"\n    from glob import glob\n\n    out = []\n\n    for arg in args:\n        if user:\n            arg = os.path.expanduser(arg)\n\n        if env:\n            arg = os.path.expandvars(arg)\n\n        try:\n            matches = glob(arg, recursive=glob_recursive)\n        except re.error:\n            matches = []\n\n        if not matches:\n            out.append(arg)\n        else:\n            out.extend(matches)\n\n    return out\n", 627], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py": ["from __future__ import annotations\n\nimport hashlib\nimport hmac\nimport os\nimport posixpath\nimport secrets\n\nSALT_CHARS = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\nDEFAULT_PBKDF2_ITERATIONS = 1_000_000\n\n_os_alt_seps: list[str] = list(\n    sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"\n)\n\n\ndef gen_salt(length: int) -> str:\n    \"\"\"Generate a random string of SALT_CHARS with specified ``length``.\"\"\"\n    if length <= 0:\n        raise ValueError(\"Salt length must be at least 1.\")\n\n    return \"\".join(secrets.choice(SALT_CHARS) for _ in range(length))\n\n\ndef _hash_internal(method: str, salt: str, password: str) -> tuple[str, str]:\n    method, *args = method.split(\":\")\n    salt_bytes = salt.encode()\n    password_bytes = password.encode()\n\n    if method == \"scrypt\":\n        if not args:\n            n = 2**15\n            r = 8\n            p = 1\n        else:\n            try:\n                n, r, p = map(int, args)\n            except ValueError:\n                raise ValueError(\"'scrypt' takes 3 arguments.\") from None\n\n        maxmem = 132 * n * r * p  # ideally 128, but some extra seems needed\n        return (\n            hashlib.scrypt(\n                password_bytes, salt=salt_bytes, n=n, r=r, p=p, maxmem=maxmem\n            ).hex(),\n            f\"scrypt:{n}:{r}:{p}\",\n        )\n    elif method == \"pbkdf2\":\n        len_args = len(args)\n\n        if len_args == 0:\n            hash_name = \"sha256\"\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 1:\n            hash_name = args[0]\n            iterations = DEFAULT_PBKDF2_ITERATIONS\n        elif len_args == 2:\n            hash_name = args[0]\n            iterations = int(args[1])\n        else:\n            raise ValueError(\"'pbkdf2' takes 2 arguments.\")\n\n        return (\n            hashlib.pbkdf2_hmac(\n                hash_name, password_bytes, salt_bytes, iterations\n            ).hex(),\n            f\"pbkdf2:{hash_name}:{iterations}\",\n        )\n    else:\n        raise ValueError(f\"Invalid hash method '{method}'.\")\n\n\ndef generate_password_hash(\n    password: str, method: str = \"scrypt\", salt_length: int = 16\n) -> str:\n    \"\"\"Securely hash a password for storage. A password can be compared to a stored hash\n    using :func:`check_password_hash`.\n\n    The following methods are supported:\n\n    -   ``scrypt``, the default. The parameters are ``n``, ``r``, and ``p``, the default\n        is ``scrypt:32768:8:1``. See :func:`hashlib.scrypt`.\n    -   ``pbkdf2``, less secure. The parameters are ``hash_method`` and ``iterations``,\n        the default is ``pbkdf2:sha256:600000``. See :func:`hashlib.pbkdf2_hmac`.\n\n    Default parameters may be updated to reflect current guidelines, and methods may be\n    deprecated and removed if they are no longer considered secure. To migrate old\n    hashes, you may generate a new hash when checking an old hash, or you may contact\n    users with a link to reset their password.\n\n    :param password: The plaintext password.\n    :param method: The key derivation function and parameters.\n    :param salt_length: The number of characters to generate for the salt.\n\n    .. versionchanged:: 3.1\n        The default iterations for pbkdf2 was increased to 1,000,000.\n\n    .. versionchanged:: 2.3\n        Scrypt support was added.\n\n    .. versionchanged:: 2.3\n        The default iterations for pbkdf2 was increased to 600,000.\n\n    .. versionchanged:: 2.3\n        All plain hashes are deprecated and will not be supported in Werkzeug 3.0.\n    \"\"\"\n    salt = gen_salt(salt_length)\n    h, actual_method = _hash_internal(method, salt, password)\n    return f\"{actual_method}${salt}${h}\"\n\n\ndef check_password_hash(pwhash: str, password: str) -> bool:\n    \"\"\"Securely check that the given stored password hash, previously generated using\n    :func:`generate_password_hash`, matches the given password.\n\n    Methods may be deprecated and removed if they are no longer considered secure. To\n    migrate old hashes, you may generate a new hash when checking an old hash, or you\n    may contact users with a link to reset their password.\n\n    :param pwhash: The hashed password.\n    :param password: The plaintext password.\n\n    .. versionchanged:: 2.3\n        All plain hashes are deprecated and will not be supported in Werkzeug 3.0.\n    \"\"\"\n    try:\n        method, salt, hashval = pwhash.split(\"$\", 2)\n    except ValueError:\n        return False\n\n    return hmac.compare_digest(_hash_internal(method, salt, password)[0], hashval)\n\n\ndef safe_join(directory: str, *pathnames: str) -> str | None:\n    \"\"\"Safely join zero or more untrusted path components to a base\n    directory to avoid escaping the base directory.\n\n    :param directory: The trusted base directory.\n    :param pathnames: The untrusted path components relative to the\n        base directory.\n    :return: A safe path, otherwise ``None``.\n    \"\"\"\n    if not directory:\n        # Ensure we end up with ./path if directory=\"\" is given,\n        # otherwise the first untrusted part could become trusted.\n        directory = \".\"\n\n    parts = [directory]\n\n    for filename in pathnames:\n        if filename != \"\":\n            filename = posixpath.normpath(filename)\n\n        if (\n            any(sep in filename for sep in _os_alt_seps)\n            or os.path.isabs(filename)\n            # ntpath.isabs doesn't catch this on Python < 3.11\n            or filename.startswith(\"/\")\n            or filename == \"..\"\n            or filename.startswith(\"../\")\n        ):\n            return None\n\n        parts.append(filename)\n\n    return posixpath.join(*parts)\n", 166], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/debug/__init__.py": ["from __future__ import annotations\n\nimport getpass\nimport hashlib\nimport json\nimport os\nimport pkgutil\nimport re\nimport sys\nimport time\nimport typing as t\nimport uuid\nfrom contextlib import ExitStack\nfrom io import BytesIO\nfrom itertools import chain\nfrom multiprocessing import Value\nfrom os.path import basename\nfrom os.path import join\nfrom zlib import adler32\n\nfrom .._internal import _log\nfrom ..exceptions import NotFound\nfrom ..exceptions import SecurityError\nfrom ..http import parse_cookie\nfrom ..sansio.utils import host_is_trusted\nfrom ..security import gen_salt\nfrom ..utils import send_file\nfrom ..wrappers.request import Request\nfrom ..wrappers.response import Response\nfrom .console import Console\nfrom .tbtools import DebugFrameSummary\nfrom .tbtools import DebugTraceback\nfrom .tbtools import render_console_html\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n# A week\nPIN_TIME = 60 * 60 * 24 * 7\n\n\ndef hash_pin(pin: str) -> str:\n    return hashlib.sha1(f\"{pin} added salt\".encode(\"utf-8\", \"replace\")).hexdigest()[:12]\n\n\n_machine_id: str | bytes | None = None\n\n\ndef get_machine_id() -> str | bytes | None:\n    global _machine_id\n\n    if _machine_id is not None:\n        return _machine_id\n\n    def _generate() -> str | bytes | None:\n        linux = b\"\"\n\n        # machine-id is stable across boots, boot_id is not.\n        for filename in \"/etc/machine-id\", \"/proc/sys/kernel/random/boot_id\":\n            try:\n                with open(filename, \"rb\") as f:\n                    value = f.readline().strip()\n            except OSError:\n                continue\n\n            if value:\n                linux += value\n                break\n\n        # Containers share the same machine id, add some cgroup\n        # information. This is used outside containers too but should be\n        # relatively stable across boots.\n        try:\n            with open(\"/proc/self/cgroup\", \"rb\") as f:\n                linux += f.readline().strip().rpartition(b\"/\")[2]\n        except OSError:\n            pass\n\n        if linux:\n            return linux\n\n        # On OS X, use ioreg to get the computer's serial number.\n        try:\n            # subprocess may not be available, e.g. Google App Engine\n            # https://github.com/pallets/werkzeug/issues/925\n            from subprocess import PIPE\n            from subprocess import Popen\n\n            dump = Popen(\n                [\"ioreg\", \"-c\", \"IOPlatformExpertDevice\", \"-d\", \"2\"], stdout=PIPE\n            ).communicate()[0]\n            match = re.search(b'\"serial-number\" = <([^>]+)', dump)\n\n            if match is not None:\n                return match.group(1)\n        except (OSError, ImportError):\n            pass\n\n        # On Windows, use winreg to get the machine guid.\n        if sys.platform == \"win32\":\n            import winreg\n\n            try:\n                with winreg.OpenKey(\n                    winreg.HKEY_LOCAL_MACHINE,\n                    \"SOFTWARE\\\\Microsoft\\\\Cryptography\",\n                    0,\n                    winreg.KEY_READ | winreg.KEY_WOW64_64KEY,\n                ) as rk:\n                    guid: str | bytes\n                    guid_type: int\n                    guid, guid_type = winreg.QueryValueEx(rk, \"MachineGuid\")\n\n                    if guid_type == winreg.REG_SZ:\n                        return guid.encode()\n\n                    return guid\n            except OSError:\n                pass\n\n        return None\n\n    _machine_id = _generate()\n    return _machine_id\n\n\nclass _ConsoleFrame:\n    \"\"\"Helper class so that we can reuse the frame console code for the\n    standalone console.\n    \"\"\"\n\n    def __init__(self, namespace: dict[str, t.Any]):\n        self.console = Console(namespace)\n        self.id = 0\n\n    def eval(self, code: str) -> t.Any:\n        return self.console.eval(code)\n\n\ndef get_pin_and_cookie_name(\n    app: WSGIApplication,\n) -> tuple[str, str] | tuple[None, None]:\n    \"\"\"Given an application object this returns a semi-stable 9 digit pin\n    code and a random key.  The hope is that this is stable between\n    restarts to not make debugging particularly frustrating.  If the pin\n    was forcefully disabled this returns `None`.\n\n    Second item in the resulting tuple is the cookie name for remembering.\n    \"\"\"\n    pin = os.environ.get(\"WERKZEUG_DEBUG_PIN\")\n    rv = None\n    num = None\n\n    # Pin was explicitly disabled\n    if pin == \"off\":\n        return None, None\n\n    # Pin was provided explicitly\n    if pin is not None and pin.replace(\"-\", \"\").isdecimal():\n        # If there are separators in the pin, return it directly\n        if \"-\" in pin:\n            rv = pin\n        else:\n            num = pin\n\n    modname = getattr(app, \"__module__\", t.cast(object, app).__class__.__module__)\n    username: str | None\n\n    try:\n        # getuser imports the pwd module, which does not exist in Google\n        # App Engine. It may also raise a KeyError if the UID does not\n        # have a username, such as in Docker.\n        username = getpass.getuser()\n    # Python >= 3.13 only raises OSError\n    except (ImportError, KeyError, OSError):\n        username = None\n\n    mod = sys.modules.get(modname)\n\n    # This information only exists to make the cookie unique on the\n    # computer, not as a security feature.\n    probably_public_bits = [\n        username,\n        modname,\n        getattr(app, \"__name__\", type(app).__name__),\n        getattr(mod, \"__file__\", None),\n    ]\n\n    # This information is here to make it harder for an attacker to\n    # guess the cookie name.  They are unlikely to be contained anywhere\n    # within the unauthenticated debug page.\n    private_bits = [str(uuid.getnode()), get_machine_id()]\n\n    h = hashlib.sha1()\n    for bit in chain(probably_public_bits, private_bits):\n        if not bit:\n            continue\n        if isinstance(bit, str):\n            bit = bit.encode()\n        h.update(bit)\n    h.update(b\"cookiesalt\")\n\n    cookie_name = f\"__wzd{h.hexdigest()[:20]}\"\n\n    # If we need to generate a pin we salt it a bit more so that we don't\n    # end up with the same value and generate out 9 digits\n    if num is None:\n        h.update(b\"pinsalt\")\n        num = f\"{int(h.hexdigest(), 16):09d}\"[:9]\n\n    # Format the pincode in groups of digits for easier remembering if\n    # we don't have a result yet.\n    if rv is None:\n        for group_size in 5, 4, 3:\n            if len(num) % group_size == 0:\n                rv = \"-\".join(\n                    num[x : x + group_size].rjust(group_size, \"0\")\n                    for x in range(0, len(num), group_size)\n                )\n                break\n        else:\n            rv = num\n\n    return rv, cookie_name\n\n\nclass DebuggedApplication:\n    \"\"\"Enables debugging support for a given application::\n\n        from werkzeug.debug import DebuggedApplication\n        from myapp import app\n        app = DebuggedApplication(app, evalex=True)\n\n    The ``evalex`` argument allows evaluating expressions in any frame\n    of a traceback. This works by preserving each frame with its local\n    state. Some state, such as context globals, cannot be restored with\n    the frame by default. When ``evalex`` is enabled,\n    ``environ[\"werkzeug.debug.preserve_context\"]`` will be a callable\n    that takes a context manager, and can be called multiple times.\n    Each context manager will be entered before evaluating code in the\n    frame, then exited again, so they can perform setup and cleanup for\n    each call.\n\n    :param app: the WSGI application to run debugged.\n    :param evalex: enable exception evaluation feature (interactive\n                   debugging).  This requires a non-forking server.\n    :param request_key: The key that points to the request object in this\n                        environment.  This parameter is ignored in current\n                        versions.\n    :param console_path: the URL for a general purpose console.\n    :param console_init_func: the function that is executed before starting\n                              the general purpose console.  The return value\n                              is used as initial namespace.\n    :param show_hidden_frames: by default hidden traceback frames are skipped.\n                               You can show them by setting this parameter\n                               to `True`.\n    :param pin_security: can be used to disable the pin based security system.\n    :param pin_logging: enables the logging of the pin system.\n\n    .. versionchanged:: 2.2\n        Added the ``werkzeug.debug.preserve_context`` environ key.\n    \"\"\"\n\n    _pin: str\n    _pin_cookie: str\n\n    def __init__(\n        self,\n        app: WSGIApplication,\n        evalex: bool = False,\n        request_key: str = \"werkzeug.request\",\n        console_path: str = \"/console\",\n        console_init_func: t.Callable[[], dict[str, t.Any]] | None = None,\n        show_hidden_frames: bool = False,\n        pin_security: bool = True,\n        pin_logging: bool = True,\n    ) -> None:\n        if not console_init_func:\n            console_init_func = None\n        self.app = app\n        self.evalex = evalex\n        self.frames: dict[int, DebugFrameSummary | _ConsoleFrame] = {}\n        self.frame_contexts: dict[int, list[t.ContextManager[None]]] = {}\n        self.request_key = request_key\n        self.console_path = console_path\n        self.console_init_func = console_init_func\n        self.show_hidden_frames = show_hidden_frames\n        self.secret = gen_salt(20)\n        self._failed_pin_auth = Value(\"B\")\n\n        self.pin_logging = pin_logging\n        if pin_security:\n            # Print out the pin for the debugger on standard out.\n            if os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\" and pin_logging:\n                _log(\"warning\", \" * Debugger is active!\")\n                if self.pin is None:\n                    _log(\"warning\", \" * Debugger PIN disabled. DEBUGGER UNSECURED!\")\n                else:\n                    _log(\"info\", \" * Debugger PIN: %s\", self.pin)\n        else:\n            self.pin = None\n\n        self.trusted_hosts: list[str] = [\".localhost\", \"127.0.0.1\"]\n        \"\"\"List of domains to allow requests to the debugger from. A leading dot\n        allows all subdomains. This only allows ``\".localhost\"`` domains by\n        default.\n\n        .. versionadded:: 3.0.3\n        \"\"\"\n\n    @property\n    def pin(self) -> str | None:\n        if not hasattr(self, \"_pin\"):\n            pin_cookie = get_pin_and_cookie_name(self.app)\n            self._pin, self._pin_cookie = pin_cookie  # type: ignore\n        return self._pin\n\n    @pin.setter\n    def pin(self, value: str) -> None:\n        self._pin = value\n\n    @property\n    def pin_cookie_name(self) -> str:\n        \"\"\"The name of the pin cookie.\"\"\"\n        if not hasattr(self, \"_pin_cookie\"):\n            pin_cookie = get_pin_and_cookie_name(self.app)\n            self._pin, self._pin_cookie = pin_cookie  # type: ignore\n        return self._pin_cookie\n\n    def debug_application(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterator[bytes]:\n        \"\"\"Run the application and conserve the traceback frames.\"\"\"\n        contexts: list[t.ContextManager[t.Any]] = []\n\n        if self.evalex:\n            environ[\"werkzeug.debug.preserve_context\"] = contexts.append\n\n        app_iter = None\n        try:\n            app_iter = self.app(environ, start_response)\n            yield from app_iter\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()\n        except Exception as e:\n            if hasattr(app_iter, \"close\"):\n                app_iter.close()  # type: ignore\n\n            tb = DebugTraceback(e, skip=1, hide=not self.show_hidden_frames)\n\n            for frame in tb.all_frames:\n                self.frames[id(frame)] = frame\n                self.frame_contexts[id(frame)] = contexts\n\n            is_trusted = bool(self.check_pin_trust(environ))\n            html = tb.render_debugger_html(\n                evalex=self.evalex and self.check_host_trust(environ),\n                secret=self.secret,\n                evalex_trusted=is_trusted,\n            )\n            response = Response(html, status=500, mimetype=\"text/html\")\n\n            try:\n                yield from response(environ, start_response)\n            except Exception:\n                # if we end up here there has been output but an error\n                # occurred.  in that situation we can do nothing fancy any\n                # more, better log something into the error log and fall\n                # back gracefully.\n                environ[\"wsgi.errors\"].write(\n                    \"Debugging middleware caught exception in streamed \"\n                    \"response at a point where response headers were already \"\n                    \"sent.\\n\"\n                )\n\n            environ[\"wsgi.errors\"].write(\"\".join(tb.render_traceback_text()))\n\n    def execute_command(\n        self,\n        request: Request,\n        command: str,\n        frame: DebugFrameSummary | _ConsoleFrame,\n    ) -> Response:\n        \"\"\"Execute a command in a console.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        contexts = self.frame_contexts.get(id(frame), [])\n\n        with ExitStack() as exit_stack:\n            for cm in contexts:\n                exit_stack.enter_context(cm)\n\n            return Response(frame.eval(command), mimetype=\"text/html\")\n\n    def display_console(self, request: Request) -> Response:\n        \"\"\"Display a standalone shell.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        if 0 not in self.frames:\n            if self.console_init_func is None:\n                ns = {}\n            else:\n                ns = dict(self.console_init_func())\n            ns.setdefault(\"app\", self.app)\n            self.frames[0] = _ConsoleFrame(ns)\n        is_trusted = bool(self.check_pin_trust(request.environ))\n        return Response(\n            render_console_html(secret=self.secret, evalex_trusted=is_trusted),\n            mimetype=\"text/html\",\n        )\n\n    def get_resource(self, request: Request, filename: str) -> Response:\n        \"\"\"Return a static resource from the shared folder.\"\"\"\n        path = join(\"shared\", basename(filename))\n\n        try:\n            data = pkgutil.get_data(__package__, path)\n        except OSError:\n            return NotFound()  # type: ignore[return-value]\n        else:\n            if data is None:\n                return NotFound()  # type: ignore[return-value]\n\n            etag = str(adler32(data) & 0xFFFFFFFF)\n            return send_file(\n                BytesIO(data), request.environ, download_name=filename, etag=etag\n            )\n\n    def check_pin_trust(self, environ: WSGIEnvironment) -> bool | None:\n        \"\"\"Checks if the request passed the pin test.  This returns `True` if the\n        request is trusted on a pin/cookie basis and returns `False` if not.\n        Additionally if the cookie's stored pin hash is wrong it will return\n        `None` so that appropriate action can be taken.\n        \"\"\"\n        if self.pin is None:\n            return True\n        val = parse_cookie(environ).get(self.pin_cookie_name)\n        if not val or \"|\" not in val:\n            return False\n        ts_str, pin_hash = val.split(\"|\", 1)\n\n        try:\n            ts = int(ts_str)\n        except ValueError:\n            return False\n\n        if pin_hash != hash_pin(self.pin):\n            return None\n        return (time.time() - PIN_TIME) < ts\n\n    def check_host_trust(self, environ: WSGIEnvironment) -> bool:\n        return host_is_trusted(environ.get(\"HTTP_HOST\"), self.trusted_hosts)\n\n    def _fail_pin_auth(self) -> None:\n        with self._failed_pin_auth.get_lock():\n            count = self._failed_pin_auth.value\n            self._failed_pin_auth.value = count + 1\n\n        time.sleep(5.0 if count > 5 else 0.5)\n\n    def pin_auth(self, request: Request) -> Response:\n        \"\"\"Authenticates with the pin.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        exhausted = False\n        auth = False\n        trust = self.check_pin_trust(request.environ)\n        pin = t.cast(str, self.pin)\n\n        # If the trust return value is `None` it means that the cookie is\n        # set but the stored pin hash value is bad.  This means that the\n        # pin was changed.  In this case we count a bad auth and unset the\n        # cookie.  This way it becomes harder to guess the cookie name\n        # instead of the pin as we still count up failures.\n        bad_cookie = False\n        if trust is None:\n            self._fail_pin_auth()\n            bad_cookie = True\n\n        # If we're trusted, we're authenticated.\n        elif trust:\n            auth = True\n\n        # If we failed too many times, then we're locked out.\n        elif self._failed_pin_auth.value > 10:\n            exhausted = True\n\n        # Otherwise go through pin based authentication\n        else:\n            entered_pin = request.args[\"pin\"]\n\n            if entered_pin.strip().replace(\"-\", \"\") == pin.replace(\"-\", \"\"):\n                self._failed_pin_auth.value = 0\n                auth = True\n            else:\n                self._fail_pin_auth()\n\n        rv = Response(\n            json.dumps({\"auth\": auth, \"exhausted\": exhausted}),\n            mimetype=\"application/json\",\n        )\n        if auth:\n            rv.set_cookie(\n                self.pin_cookie_name,\n                f\"{int(time.time())}|{hash_pin(pin)}\",\n                httponly=True,\n                samesite=\"Strict\",\n                secure=request.is_secure,\n            )\n        elif bad_cookie:\n            rv.delete_cookie(self.pin_cookie_name)\n        return rv\n\n    def log_pin_request(self, request: Request) -> Response:\n        \"\"\"Log the pin if needed.\"\"\"\n        if not self.check_host_trust(request.environ):\n            return SecurityError()  # type: ignore[return-value]\n\n        if self.pin_logging and self.pin is not None:\n            _log(\n                \"info\", \" * To enable the debugger you need to enter the security pin:\"\n            )\n            _log(\"info\", \" * Debugger pin code: %s\", self.pin)\n        return Response(\"\")\n\n    def __call__(\n        self, environ: WSGIEnvironment, start_response: StartResponse\n    ) -> t.Iterable[bytes]:\n        \"\"\"Dispatch the requests.\"\"\"\n        # important: don't ever access a function here that reads the incoming\n        # form data!  Otherwise the application won't have access to that data\n        # any more!\n        request = Request(environ)\n        response = self.debug_application\n        if request.args.get(\"__debugger__\") == \"yes\":\n            cmd = request.args.get(\"cmd\")\n            arg = request.args.get(\"f\")\n            secret = request.args.get(\"s\")\n            frame = self.frames.get(request.args.get(\"frm\", type=int))  # type: ignore\n            if cmd == \"resource\" and arg:\n                response = self.get_resource(request, arg)  # type: ignore\n            elif cmd == \"pinauth\" and secret == self.secret:\n                response = self.pin_auth(request)  # type: ignore\n            elif cmd == \"printpin\" and secret == self.secret:\n                response = self.log_pin_request(request)  # type: ignore\n            elif (\n                self.evalex\n                and cmd is not None\n                and frame is not None\n                and self.secret == secret\n                and self.check_pin_trust(environ)\n            ):\n                response = self.execute_command(request, cmd, frame)  # type: ignore\n        elif (\n            self.evalex\n            and self.console_path is not None\n            and request.path == self.console_path\n        ):\n            response = self.display_console(request)  # type: ignore\n        return response(environ, start_response)\n", 565], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py": ["from __future__ import annotations\n\nimport logging\nimport re\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom datetime import timezone\n\nif t.TYPE_CHECKING:\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .wrappers.request import Request\n\n_logger: logging.Logger | None = None\n\n\nclass _Missing:\n    def __repr__(self) -> str:\n        return \"no value\"\n\n    def __reduce__(self) -> str:\n        return \"_missing\"\n\n\n_missing = _Missing()\n\n\ndef _wsgi_decoding_dance(s: str) -> str:\n    return s.encode(\"latin1\").decode(errors=\"replace\")\n\n\ndef _wsgi_encoding_dance(s: str) -> str:\n    return s.encode().decode(\"latin1\")\n\n\ndef _get_environ(obj: WSGIEnvironment | Request) -> WSGIEnvironment:\n    env = getattr(obj, \"environ\", obj)\n    assert isinstance(\n        env, dict\n    ), f\"{type(obj).__name__!r} is not a WSGI environment (has to be a dict)\"\n    return env\n\n\ndef _has_level_handler(logger: logging.Logger) -> bool:\n    \"\"\"Check if there is a handler in the logging chain that will handle\n    the given logger's effective level.\n    \"\"\"\n    level = logger.getEffectiveLevel()\n    current = logger\n\n    while current:\n        if any(handler.level <= level for handler in current.handlers):\n            return True\n\n        if not current.propagate:\n            break\n\n        current = current.parent  # type: ignore\n\n    return False\n\n\nclass _ColorStreamHandler(logging.StreamHandler):  # type: ignore[type-arg]\n    \"\"\"On Windows, wrap stream with Colorama for ANSI style support.\"\"\"\n\n    def __init__(self) -> None:\n        try:\n            import colorama\n        except ImportError:\n            stream = None\n        else:\n            stream = colorama.AnsiToWin32(sys.stderr)\n\n        super().__init__(stream)\n\n\ndef _log(type: str, message: str, *args: t.Any, **kwargs: t.Any) -> None:\n    \"\"\"Log a message to the 'werkzeug' logger.\n\n    The logger is created the first time it is needed. If there is no\n    level set, it is set to :data:`logging.INFO`. If there is no handler\n    for the logger's effective level, a :class:`logging.StreamHandler`\n    is added.\n    \"\"\"\n    global _logger\n\n    if _logger is None:\n        _logger = logging.getLogger(\"werkzeug\")\n\n        if _logger.level == logging.NOTSET:\n            _logger.setLevel(logging.INFO)\n\n        if not _has_level_handler(_logger):\n            _logger.addHandler(_ColorStreamHandler())\n\n    getattr(_logger, type)(message.rstrip(), *args, **kwargs)\n\n\n@t.overload\ndef _dt_as_utc(dt: None) -> None: ...\n\n\n@t.overload\ndef _dt_as_utc(dt: datetime) -> datetime: ...\n\n\ndef _dt_as_utc(dt: datetime | None) -> datetime | None:\n    if dt is None:\n        return dt\n\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n    elif dt.tzinfo != timezone.utc:\n        return dt.astimezone(timezone.utc)\n\n    return dt\n\n\n_TAccessorValue = t.TypeVar(\"_TAccessorValue\")\n\n\nclass _DictAccessorProperty(t.Generic[_TAccessorValue]):\n    \"\"\"Baseclass for `environ_property` and `header_property`.\"\"\"\n\n    read_only = False\n\n    def __init__(\n        self,\n        name: str,\n        default: _TAccessorValue | None = None,\n        load_func: t.Callable[[str], _TAccessorValue] | None = None,\n        dump_func: t.Callable[[_TAccessorValue], str] | None = None,\n        read_only: bool | None = None,\n        doc: str | None = None,\n    ) -> None:\n        self.name = name\n        self.default = default\n        self.load_func = load_func\n        self.dump_func = dump_func\n        if read_only is not None:\n            self.read_only = read_only\n        self.__doc__ = doc\n\n    def lookup(self, instance: t.Any) -> t.MutableMapping[str, t.Any]:\n        raise NotImplementedError\n\n    @t.overload\n    def __get__(\n        self, instance: None, owner: type\n    ) -> _DictAccessorProperty[_TAccessorValue]: ...\n\n    @t.overload\n    def __get__(self, instance: t.Any, owner: type) -> _TAccessorValue: ...\n\n    def __get__(\n        self, instance: t.Any | None, owner: type\n    ) -> _TAccessorValue | _DictAccessorProperty[_TAccessorValue]:\n        if instance is None:\n            return self\n\n        storage = self.lookup(instance)\n\n        if self.name not in storage:\n            return self.default  # type: ignore\n\n        value = storage[self.name]\n\n        if self.load_func is not None:\n            try:\n                return self.load_func(value)\n            except (ValueError, TypeError):\n                return self.default  # type: ignore\n\n        return value  # type: ignore\n\n    def __set__(self, instance: t.Any, value: _TAccessorValue) -> None:\n        if self.read_only:\n            raise AttributeError(\"read only property\")\n\n        if self.dump_func is not None:\n            self.lookup(instance)[self.name] = self.dump_func(value)\n        else:\n            self.lookup(instance)[self.name] = value\n\n    def __delete__(self, instance: t.Any) -> None:\n        if self.read_only:\n            raise AttributeError(\"read only property\")\n\n        self.lookup(instance).pop(self.name, None)\n\n    def __repr__(self) -> str:\n        return f\"<{type(self).__name__} {self.name}>\"\n\n\n_plain_int_re = re.compile(r\"-?\\d+\", re.ASCII)\n\n\ndef _plain_int(value: str) -> int:\n    \"\"\"Parse an int only if it is only ASCII digits and ``-``.\n\n    This disallows ``+``, ``_``, and non-ASCII digits, which are accepted by ``int`` but\n    are not allowed in HTTP header values.\n\n    Any leading or trailing whitespace is stripped\n    \"\"\"\n    value = value.strip()\n    if _plain_int_re.fullmatch(value) is None:\n        raise ValueError\n\n    return int(value)\n", 211], "/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py": ["from __future__ import annotations\n\nimport fnmatch\nimport os\nimport subprocess\nimport sys\nimport threading\nimport time\nimport typing as t\nfrom itertools import chain\nfrom pathlib import PurePath\n\nfrom ._internal import _log\n\n# The various system prefixes where imports are found. Base values are\n# different when running in a virtualenv. All reloaders will ignore the\n# base paths (usually the system installation). The stat reloader won't\n# scan the virtualenv paths, it will only include modules that are\n# already imported.\n_ignore_always = tuple({sys.base_prefix, sys.base_exec_prefix})\nprefix = {*_ignore_always, sys.prefix, sys.exec_prefix}\n\nif hasattr(sys, \"real_prefix\"):\n    # virtualenv < 20\n    prefix.add(sys.real_prefix)\n\n_stat_ignore_scan = tuple(prefix)\ndel prefix\n_ignore_common_dirs = {\n    \"__pycache__\",\n    \".git\",\n    \".hg\",\n    \".tox\",\n    \".nox\",\n    \".pytest_cache\",\n    \".mypy_cache\",\n}\n\n\ndef _iter_module_paths() -> t.Iterator[str]:\n    \"\"\"Find the filesystem paths associated with imported modules.\"\"\"\n    # List is in case the value is modified by the app while updating.\n    for module in list(sys.modules.values()):\n        name = getattr(module, \"__file__\", None)\n\n        if name is None or name.startswith(_ignore_always):\n            continue\n\n        while not os.path.isfile(name):\n            # Zip file, find the base file without the module path.\n            old = name\n            name = os.path.dirname(name)\n\n            if name == old:  # skip if it was all directories somehow\n                break\n        else:\n            yield name\n\n\ndef _remove_by_pattern(paths: set[str], exclude_patterns: set[str]) -> None:\n    for pattern in exclude_patterns:\n        paths.difference_update(fnmatch.filter(paths, pattern))\n\n\ndef _find_stat_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n) -> t.Iterable[str]:\n    \"\"\"Find paths for the stat reloader to watch. Returns imported\n    module files, Python files under non-system paths. Extra files and\n    Python files under extra directories can also be scanned.\n\n    System paths have to be excluded for efficiency. Non-system paths,\n    such as a project root or ``sys.path.insert``, should be the paths\n    of interest to the user anyway.\n    \"\"\"\n    paths = set()\n\n    for path in chain(list(sys.path), extra_files):\n        path = os.path.abspath(path)\n\n        if os.path.isfile(path):\n            # zip file on sys.path, or extra file\n            paths.add(path)\n            continue\n\n        parent_has_py = {os.path.dirname(path): True}\n\n        for root, dirs, files in os.walk(path):\n            # Optimizations: ignore system prefixes, __pycache__ will\n            # have a py or pyc module at the import path, ignore some\n            # common known dirs such as version control and tool caches.\n            if (\n                root.startswith(_stat_ignore_scan)\n                or os.path.basename(root) in _ignore_common_dirs\n            ):\n                dirs.clear()\n                continue\n\n            has_py = False\n\n            for name in files:\n                if name.endswith((\".py\", \".pyc\")):\n                    has_py = True\n                    paths.add(os.path.join(root, name))\n\n            # Optimization: stop scanning a directory if neither it nor\n            # its parent contained Python files.\n            if not (has_py or parent_has_py[os.path.dirname(root)]):\n                dirs.clear()\n                continue\n\n            parent_has_py[root] = has_py\n\n    paths.update(_iter_module_paths())\n    _remove_by_pattern(paths, exclude_patterns)\n    return paths\n\n\ndef _find_watchdog_paths(\n    extra_files: set[str], exclude_patterns: set[str]\n) -> t.Iterable[str]:\n    \"\"\"Find paths for the stat reloader to watch. Looks at the same\n    sources as the stat reloader, but watches everything under\n    directories instead of individual files.\n    \"\"\"\n    dirs = set()\n\n    for name in chain(list(sys.path), extra_files):\n        name = os.path.abspath(name)\n\n        if os.path.isfile(name):\n            name = os.path.dirname(name)\n\n        dirs.add(name)\n\n    for name in _iter_module_paths():\n        dirs.add(os.path.dirname(name))\n\n    _remove_by_pattern(dirs, exclude_patterns)\n    return _find_common_roots(dirs)\n\n\ndef _find_common_roots(paths: t.Iterable[str]) -> t.Iterable[str]:\n    root: dict[str, dict[str, t.Any]] = {}\n\n    for chunks in sorted((PurePath(x).parts for x in paths), key=len, reverse=True):\n        node = root\n\n        for chunk in chunks:\n            node = node.setdefault(chunk, {})\n\n        node.clear()\n\n    rv = set()\n\n    def _walk(node: t.Mapping[str, dict[str, t.Any]], path: tuple[str, ...]) -> None:\n        for prefix, child in node.items():\n            _walk(child, path + (prefix,))\n\n        # If there are no more nodes, and a path has been accumulated, add it.\n        # Path may be empty if the \"\" entry is in sys.path.\n        if not node and path:\n            rv.add(os.path.join(*path))\n\n    _walk(root, ())\n    return rv\n\n\ndef _get_args_for_reloading() -> list[str]:\n    \"\"\"Determine how the script was executed, and return the args needed\n    to execute it again in a new process.\n    \"\"\"\n    if sys.version_info >= (3, 10):\n        # sys.orig_argv, added in Python 3.10, contains the exact args used to invoke\n        # Python. Still replace argv[0] with sys.executable for accuracy.\n        return [sys.executable, *sys.orig_argv[1:]]\n\n    rv = [sys.executable]\n    py_script = sys.argv[0]\n    args = sys.argv[1:]\n    # Need to look at main module to determine how it was executed.\n    __main__ = sys.modules[\"__main__\"]\n\n    # The value of __package__ indicates how Python was called. It may\n    # not exist if a setuptools script is installed as an egg. It may be\n    # set incorrectly for entry points created with pip on Windows.\n    if getattr(__main__, \"__package__\", None) is None or (\n        os.name == \"nt\"\n        and __main__.__package__ == \"\"\n        and not os.path.exists(py_script)\n        and os.path.exists(f\"{py_script}.exe\")\n    ):\n        # Executed a file, like \"python app.py\".\n        py_script = os.path.abspath(py_script)\n\n        if os.name == \"nt\":\n            # Windows entry points have \".exe\" extension and should be\n            # called directly.\n            if not os.path.exists(py_script) and os.path.exists(f\"{py_script}.exe\"):\n                py_script += \".exe\"\n\n            if (\n                os.path.splitext(sys.executable)[1] == \".exe\"\n                and os.path.splitext(py_script)[1] == \".exe\"\n            ):\n                rv.pop(0)\n\n        rv.append(py_script)\n    else:\n        # Executed a module, like \"python -m werkzeug.serving\".\n        if os.path.isfile(py_script):\n            # Rewritten by Python from \"-m script\" to \"/path/to/script.py\".\n            py_module = t.cast(str, __main__.__package__)\n            name = os.path.splitext(os.path.basename(py_script))[0]\n\n            if name != \"__main__\":\n                py_module += f\".{name}\"\n        else:\n            # Incorrectly rewritten by pydevd debugger from \"-m script\" to \"script\".\n            py_module = py_script\n\n        rv.extend((\"-m\", py_module.lstrip(\".\")))\n\n    rv.extend(args)\n    return rv\n\n\nclass ReloaderLoop:\n    name = \"\"\n\n    def __init__(\n        self,\n        extra_files: t.Iterable[str] | None = None,\n        exclude_patterns: t.Iterable[str] | None = None,\n        interval: int | float = 1,\n    ) -> None:\n        self.extra_files: set[str] = {os.path.abspath(x) for x in extra_files or ()}\n        self.exclude_patterns: set[str] = set(exclude_patterns or ())\n        self.interval = interval\n\n    def __enter__(self) -> ReloaderLoop:\n        \"\"\"Do any setup, then run one step of the watch to populate the\n        initial filesystem state.\n        \"\"\"\n        self.run_step()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # type: ignore\n        \"\"\"Clean up any resources associated with the reloader.\"\"\"\n        pass\n\n    def run(self) -> None:\n        \"\"\"Continually run the watch step, sleeping for the configured\n        interval after each step.\n        \"\"\"\n        while True:\n            self.run_step()\n            time.sleep(self.interval)\n\n    def run_step(self) -> None:\n        \"\"\"Run one step for watching the filesystem. Called once to set\n        up initial state, then repeatedly to update it.\n        \"\"\"\n        pass\n\n    def restart_with_reloader(self) -> int:\n        \"\"\"Spawn a new Python interpreter with the same arguments as the\n        current one, but running the reloader thread.\n        \"\"\"\n        while True:\n            _log(\"info\", f\" * Restarting with {self.name}\")\n            args = _get_args_for_reloading()\n            new_environ = os.environ.copy()\n            new_environ[\"WERKZEUG_RUN_MAIN\"] = \"true\"\n            exit_code = subprocess.call(args, env=new_environ, close_fds=False)\n\n            if exit_code != 3:\n                return exit_code\n\n    def trigger_reload(self, filename: str) -> None:\n        self.log_reload(filename)\n        sys.exit(3)\n\n    def log_reload(self, filename: str | bytes) -> None:\n        filename = os.path.abspath(filename)\n        _log(\"info\", f\" * Detected change in {filename!r}, reloading\")\n\n\nclass StatReloaderLoop(ReloaderLoop):\n    name = \"stat\"\n\n    def __enter__(self) -> ReloaderLoop:\n        self.mtimes: dict[str, float] = {}\n        return super().__enter__()\n\n    def run_step(self) -> None:\n        for name in _find_stat_paths(self.extra_files, self.exclude_patterns):\n            try:\n                mtime = os.stat(name).st_mtime\n            except OSError:\n                continue\n\n            old_time = self.mtimes.get(name)\n\n            if old_time is None:\n                self.mtimes[name] = mtime\n                continue\n\n            if mtime > old_time:\n                self.trigger_reload(name)\n\n\nclass WatchdogReloaderLoop(ReloaderLoop):\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        from watchdog.events import EVENT_TYPE_CLOSED\n        from watchdog.events import EVENT_TYPE_CREATED\n        from watchdog.events import EVENT_TYPE_DELETED\n        from watchdog.events import EVENT_TYPE_MODIFIED\n        from watchdog.events import EVENT_TYPE_MOVED\n        from watchdog.events import FileModifiedEvent\n        from watchdog.events import PatternMatchingEventHandler\n        from watchdog.observers import Observer\n\n        super().__init__(*args, **kwargs)\n        trigger_reload = self.trigger_reload\n\n        class EventHandler(PatternMatchingEventHandler):\n            def on_any_event(self, event: FileModifiedEvent):  # type: ignore\n                if event.event_type not in {\n                    EVENT_TYPE_CLOSED,\n                    EVENT_TYPE_CREATED,\n                    EVENT_TYPE_DELETED,\n                    EVENT_TYPE_MODIFIED,\n                    EVENT_TYPE_MOVED,\n                }:\n                    # skip events that don't involve changes to the file\n                    return\n\n                trigger_reload(event.src_path)\n\n        reloader_name = Observer.__name__.lower()  # type: ignore[attr-defined]\n\n        if reloader_name.endswith(\"observer\"):\n            reloader_name = reloader_name[:-8]\n\n        self.name = f\"watchdog ({reloader_name})\"\n        self.observer = Observer()\n        # Extra patterns can be non-Python files, match them in addition\n        # to all Python files in default and extra directories. Ignore\n        # __pycache__ since a change there will always have a change to\n        # the source file (or initial pyc file) as well. Ignore Git and\n        # Mercurial internal changes.\n        extra_patterns = [p for p in self.extra_files if not os.path.isdir(p)]\n        self.event_handler = EventHandler(\n            patterns=[\"*.py\", \"*.pyc\", \"*.zip\", *extra_patterns],\n            ignore_patterns=[\n                *[f\"*/{d}/*\" for d in _ignore_common_dirs],\n                *self.exclude_patterns,\n            ],\n        )\n        self.should_reload = False\n\n    def trigger_reload(self, filename: str | bytes) -> None:\n        # This is called inside an event handler, which means throwing\n        # SystemExit has no effect.\n        # https://github.com/gorakhargosh/watchdog/issues/294\n        self.should_reload = True\n        self.log_reload(filename)\n\n    def __enter__(self) -> ReloaderLoop:\n        self.watches: dict[str, t.Any] = {}\n        self.observer.start()\n        return super().__enter__()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):  # type: ignore\n        self.observer.stop()\n        self.observer.join()\n\n    def run(self) -> None:\n        while not self.should_reload:\n            self.run_step()\n            time.sleep(self.interval)\n\n        sys.exit(3)\n\n    def run_step(self) -> None:\n        to_delete = set(self.watches)\n\n        for path in _find_watchdog_paths(self.extra_files, self.exclude_patterns):\n            if path not in self.watches:\n                try:\n                    self.watches[path] = self.observer.schedule(\n                        self.event_handler, path, recursive=True\n                    )\n                except OSError:\n                    # Clear this path from list of watches We don't want\n                    # the same error message showing again in the next\n                    # iteration.\n                    self.watches[path] = None\n\n            to_delete.discard(path)\n\n        for path in to_delete:\n            watch = self.watches.pop(path, None)\n\n            if watch is not None:\n                self.observer.unschedule(watch)\n\n\nreloader_loops: dict[str, type[ReloaderLoop]] = {\n    \"stat\": StatReloaderLoop,\n    \"watchdog\": WatchdogReloaderLoop,\n}\n\ntry:\n    __import__(\"watchdog.observers\")\nexcept ImportError:\n    reloader_loops[\"auto\"] = reloader_loops[\"stat\"]\nelse:\n    reloader_loops[\"auto\"] = reloader_loops[\"watchdog\"]\n\n\ndef ensure_echo_on() -> None:\n    \"\"\"Ensure that echo mode is enabled. Some tools such as PDB disable\n    it which causes usability issues after a reload.\"\"\"\n    # tcgetattr will fail if stdin isn't a tty\n    if sys.stdin is None or not sys.stdin.isatty():\n        return\n\n    try:\n        import termios\n    except ImportError:\n        return\n\n    attributes = termios.tcgetattr(sys.stdin)\n\n    if not attributes[3] & termios.ECHO:\n        attributes[3] |= termios.ECHO\n        termios.tcsetattr(sys.stdin, termios.TCSANOW, attributes)\n\n\ndef run_with_reloader(\n    main_func: t.Callable[[], None],\n    extra_files: t.Iterable[str] | None = None,\n    exclude_patterns: t.Iterable[str] | None = None,\n    interval: int | float = 1,\n    reloader_type: str = \"auto\",\n) -> None:\n    \"\"\"Run the given function in an independent Python interpreter.\"\"\"\n    import signal\n\n    signal.signal(signal.SIGTERM, lambda *args: sys.exit(0))\n    reloader = reloader_loops[reloader_type](\n        extra_files=extra_files, exclude_patterns=exclude_patterns, interval=interval\n    )\n\n    try:\n        if os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\":\n            ensure_echo_on()\n            t = threading.Thread(target=main_func, args=())\n            t.daemon = True\n\n            # Enter the reloader to set up initial state, then start\n            # the app thread and reloader update loop.\n            with reloader:\n                t.start()\n                reloader.run()\n        else:\n            sys.exit(reloader.restart_with_reloader())\n    except KeyboardInterrupt:\n        pass\n", 471], "/home/justin/explainshell/runserver.py": ["from __future__ import absolute_import\nfrom explainshell import config\nfrom explainshell.web import app\n\nimport logging.config\nlogging.config.dictConfig(config.LOGGING_DICT)\n\nif __name__ == '__main__':\n    if config.HOST_IP:\n        app.run(debug=config.DEBUG, host=config.HOST_IP)\n    else:\n        app.run(debug=config.DEBUG)\n", 12]}, "functions": {"get_load_dotenv (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/helpers.py:35)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/helpers.py", 35], "load_dotenv (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/cli.py:706)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/cli.py", 706], "App.debug (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:549)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py", 549], "DispatchingJinjaLoader.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/templating.py:57)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/templating.py", 57], "App.create_global_jinja_loader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:523)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py", 523], "LRUCache._postinit (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/utils.py:445)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/utils.py", 445], "LRUCache.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/utils.py:439)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/utils.py", 439], "create_cache (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:82)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py", 82], "load_extensions (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:108)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py", 108], "_environment_config_check (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:126)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py", 126], "Environment.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py:294)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/jinja2/environment.py", 294], "Environment.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/templating.py:45)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/templating.py", 45], "Flask.create_jinja_environment (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/app.py:385)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/app.py", 385], "App.jinja_env (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:469)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py", 469], "cached_property.__get__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/utils.py:95)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/utils.py", 95], "App.debug (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py:562)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/sansio/app.py", 562], "is_running_from_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:951)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 951], "<lambda> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:608)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 608], "_get_windows_console_stream (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:562)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 562], "_is_binary_writer (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:160)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 160], "_is_compat_stream_attr (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:218)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 218], "_is_compatible_text_stream (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:227)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 227], "is_ascii_encoding (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:40)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 40], "_stream_is_misconfigured (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:209)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 209], "_force_correct_text_stream (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:238)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 238], "_force_correct_text_writer (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:300)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 300], "get_text_stdout (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:344)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 344], "_make_cached_stream_func.<locals>.func (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:585)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 585], "get_current_context (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py:20)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py", 20], "resolve_color_default (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py:54)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/globals.py", 54], "isatty (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:572)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 572], "should_strip_ansi (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py:499)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/_compat.py", 499], "echo (/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/utils.py:222)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/click/utils.py", 222], "show_server_banner (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/cli.py:774)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/cli.py", 774], "gen_salt.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:22)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py", 22], "gen_salt (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py:17)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/security.py", 17], "DebuggedApplication.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/debug/__init__.py:269)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/debug/__init__.py", 269], "select_address_family (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:655)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 655], "get_sockaddr (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:665)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 665], "BaseWSGIServer.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:711)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 711], "make_server (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:906)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 906], "_ansi_style (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:485)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 485], "_has_level_handler.<locals>.<genexpr> (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:53)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py", 53], "_has_level_handler (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:45)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py", 45], "_ColorStreamHandler.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:67)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py", 67], "_log (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py:78)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_internal.py", 78], "BaseWSGIServer.log_startup (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:833)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 833], "ReloaderLoop.__init__ (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:231)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py", 231], "_get_args_for_reloading (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:169)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py", 169], "ReloaderLoop.restart_with_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:266)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py", 266], "run_with_reloader (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py:442)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/_reloader.py", 442], "run_simple (/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py:960)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/werkzeug/serving.py", 960], "Flask.run (/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/app.py:546)": ["/home/justin/explainshell/.venv/lib/python3.12/site-packages/flask/app.py", 546], "<module> (/home/justin/explainshell/runserver.py:1)": ["/home/justin/explainshell/runserver.py", 1]}}}